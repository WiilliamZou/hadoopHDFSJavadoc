<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_80) on Wed Jun 10 23:40:44 EDT 2015 -->
<title>ClientNamenodeProtocolServerSideTranslatorPB</title>
<meta name="date" content="2015-06-10">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="ClientNamenodeProtocolServerSideTranslatorPB";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/ClientNamenodeProtocolServerSideTranslatorPB.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolPB.html" title="interface in org.apache.hadoop.hdfs.protocolPB"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.html" title="class in org.apache.hadoop.hdfs.protocolPB"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html" target="_top">Frames</a></li>
<li><a href="ClientNamenodeProtocolServerSideTranslatorPB.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.hadoop.hdfs.protocolPB</div>
<h2 title="Class ClientNamenodeProtocolServerSideTranslatorPB" class="title">Class ClientNamenodeProtocolServerSideTranslatorPB</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li><a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">java.lang.Object</a></li>
<li>
<ul class="inheritance">
<li>org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface, <a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolPB.html" title="interface in org.apache.hadoop.hdfs.protocolPB">ClientNamenodeProtocolPB</a></dd>
</dl>
<hr>
<br>
<pre>@InterfaceAudience.Private
@InterfaceStability.Stable
public class <span class="strong">ClientNamenodeProtocolServerSideTranslatorPB</span>
extends <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a>
implements <a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolPB.html" title="interface in org.apache.hadoop.hdfs.protocolPB">ClientNamenodeProtocolPB</a></pre>
<div class="block">This class is used on the server side. Calls come across the wire for the
 for protocol <a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolPB.html" title="interface in org.apache.hadoop.hdfs.protocolPB"><code>ClientNamenodeProtocolPB</code></a>.
 This class translates the PB data types
 to the native data types used inside the NN as specified in the generic
 ClientProtocol.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>(package private) static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#NULL_GET_SNAPSHOTTABLE_DIR_LISTING_RESPONSE">NULL_GET_SNAPSHOTTABLE_DIR_LISTING_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private <a href="../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="interface in org.apache.hadoop.hdfs.protocol">ClientProtocol</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#server">server</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_ADD_BLOCK_RESPONSE">VOID_ADD_BLOCK_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>(package private) static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_ALLOW_SNAPSHOT_RESPONSE">VOID_ALLOW_SNAPSHOT_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_CANCELDELEGATIONTOKEN_RESPONSE">VOID_CANCELDELEGATIONTOKEN_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_CHECKACCESS_RESPONSE">VOID_CHECKACCESS_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_CONCAT_RESPONSE">VOID_CONCAT_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_CREATE_RESPONSE">VOID_CREATE_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_CREATESYMLINK_RESPONSE">VOID_CREATESYMLINK_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>(package private) static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_DELETE_SNAPSHOT_RESPONSE">VOID_DELETE_SNAPSHOT_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>(package private) static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_DISALLOW_SNAPSHOT_RESPONSE">VOID_DISALLOW_SNAPSHOT_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_FINALIZEUPGRADE_RESPONSE">VOID_FINALIZEUPGRADE_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_FSYNC_RESPONSE">VOID_FSYNC_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_GETFILEINFO_RESPONSE">VOID_GETFILEINFO_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_GETFILELINKINFO_RESPONSE">VOID_GETFILELINKINFO_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_GETLISTING_RESPONSE">VOID_GETLISTING_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_METASAVE_RESPONSE">VOID_METASAVE_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_MODIFYACLENTRIES_RESPONSE">VOID_MODIFYACLENTRIES_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_REFRESHNODES_RESPONSE">VOID_REFRESHNODES_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_REMOVEACL_RESPONSE">VOID_REMOVEACL_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_REMOVEACLENTRIES_RESPONSE">VOID_REMOVEACLENTRIES_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_REMOVEDEFAULTACL_RESPONSE">VOID_REMOVEDEFAULTACL_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_REMOVEXATTR_RESPONSE">VOID_REMOVEXATTR_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>(package private) static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_RENAME_SNAPSHOT_RESPONSE">VOID_RENAME_SNAPSHOT_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2ResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_RENAME2_RESPONSE">VOID_RENAME2_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_RENEWLEASE_RESPONSE">VOID_RENEWLEASE_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_REP_BAD_BLOCK_RESPONSE">VOID_REP_BAD_BLOCK_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SAVENAMESPACE_RESPONSE">VOID_SAVENAMESPACE_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SET_OWNER_RESPONSE">VOID_SET_OWNER_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SET_PERM_RESPONSE">VOID_SET_PERM_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>(package private) static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SET_STORAGE_POLICY_RESPONSE">VOID_SET_STORAGE_POLICY_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SETACL_RESPONSE">VOID_SETACL_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SETBALANCERBANDWIDTH_RESPONSE">VOID_SETBALANCERBANDWIDTH_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SETQUOTA_RESPONSE">VOID_SETQUOTA_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SETTIMES_RESPONSE">VOID_SETTIMES_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_SETXATTR_RESPONSE">VOID_SETXATTR_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>private static org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#VOID_UPDATEPIPELINE_RESPONSE">VOID_UPDATEPIPELINE_RESPONSE</a></strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#ClientNamenodeProtocolServerSideTranslatorPB(org.apache.hadoop.hdfs.protocol.ClientProtocol)">ClientNamenodeProtocolServerSideTranslatorPB</a></strong>(<a href="../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="interface in org.apache.hadoop.hdfs.protocol">ClientProtocol</a>&nbsp;server)</code>
<div class="block">Constructor</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#abandonBlock(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockRequestProto)">abandonBlock</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddBlockResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#addBlock(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddBlockRequestProto)">addBlock</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddBlockRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCacheDirectiveResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#addCacheDirective(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCacheDirectiveRequestProto)">addCacheDirective</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCacheDirectiveRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCachePoolResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#addCachePool(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCachePoolRequestProto)">addCachePool</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCachePoolRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#allowSnapshot(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotRequestProto)">allowSnapshot</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
             org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AppendResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#append(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AppendRequestProto)">append</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AppendRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#cancelDelegationToken(com.google.protobuf.RpcController,%20org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenRequestProto)">cancelDelegationToken</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                     org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#checkAccess(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessRequestProto)">checkAccess</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
           org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CompleteResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#complete(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CompleteRequestProto)">complete</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CompleteRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#concat(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatRequestProto)">concat</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#create(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateRequestProto)">create</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.CreateEncryptionZoneResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#createEncryptionZone(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.CreateEncryptionZoneRequestProto)">createEncryptionZone</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.CreateEncryptionZoneRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#createSnapshot(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSnapshotRequestProto)">createSnapshot</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSnapshotRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#createSymlink(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkRequestProto)">createSymlink</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
             org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#delete(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteRequestProto)">delete</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#deleteSnapshot(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotRequestProto)">deleteSnapshot</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#disallowSnapshot(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotRequestProto)">disallowSnapshot</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#finalizeUpgrade(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeRequestProto)">finalizeUpgrade</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
               org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#fsync(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncRequestProto)">fsync</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
     org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getAclStatus(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusRequestProto)">getAclStatus</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetAdditionalDatanodeResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getAdditionalDatanode(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetAdditionalDatanodeRequestProto)">getAdditionalDatanode</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                     org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetAdditionalDatanodeRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getBlockLocations(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsRequestProto)">getBlockLocations</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetContentSummaryResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getContentSummary(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetContentSummaryRequestProto)">getContentSummary</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetContentSummaryRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetCurrentEditLogTxidResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getCurrentEditLogTxid(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetCurrentEditLogTxidRequestProto)">getCurrentEditLogTxid</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                     org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetCurrentEditLogTxidRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDataEncryptionKeyResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getDataEncryptionKey(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDataEncryptionKeyRequestProto)">getDataEncryptionKey</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDataEncryptionKeyRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeReportResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getDatanodeReport(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeReportRequestProto)">getDatanodeReport</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeReportRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeStorageReportResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getDatanodeStorageReport(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeStorageReportRequestProto)">getDatanodeStorageReport</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeStorageReportRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.security.proto.SecurityProtos.GetDelegationTokenResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getDelegationToken(com.google.protobuf.RpcController,%20org.apache.hadoop.security.proto.SecurityProtos.GetDelegationTokenRequestProto)">getDelegationToken</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                  org.apache.hadoop.security.proto.SecurityProtos.GetDelegationTokenRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetEditsFromTxidResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getEditsFromTxid(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetEditsFromTxidRequestProto)">getEditsFromTxid</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetEditsFromTxidRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.GetEZForPathResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getEZForPath(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.GetEZForPathRequestProto)">getEZForPath</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.GetEZForPathRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getFileInfo(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoRequestProto)">getFileInfo</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
           org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getFileLinkInfo(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoRequestProto)">getFileLinkInfo</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
               org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getFsStats(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatusRequestProto)">getFsStats</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatusRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetLinkTargetResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getLinkTarget(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetLinkTargetRequestProto)">getLinkTarget</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
             org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetLinkTargetRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getListing(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingRequestProto)">getListing</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetPreferredBlockSizeResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getPreferredBlockSize(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetPreferredBlockSizeRequestProto)">getPreferredBlockSize</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                     org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetPreferredBlockSizeRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetServerDefaultsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getServerDefaults(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetServerDefaultsRequestProto)">getServerDefaults</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                 org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetServerDefaultsRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshotDiffReportResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getSnapshotDiffReport(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshotDiffReportRequestProto)">getSnapshotDiffReport</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                     org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshotDiffReportRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getSnapshottableDirListing(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingRequestProto)">getSnapshottableDirListing</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetStoragePoliciesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getStoragePolicies(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetStoragePoliciesRequestProto)">getStoragePolicies</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetStoragePoliciesRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#getXAttrs(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsRequestProto)">getXAttrs</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
         org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.IsFileClosedResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#isFileClosed(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.IsFileClosedRequestProto)">isFileClosed</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.IsFileClosedRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCacheDirectivesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#listCacheDirectives(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCacheDirectivesRequestProto)">listCacheDirectives</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                   org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCacheDirectivesRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCachePoolsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#listCachePools(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCachePoolsRequestProto)">listCachePools</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCachePoolsRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCorruptFileBlocksResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#listCorruptFileBlocks(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCorruptFileBlocksRequestProto)">listCorruptFileBlocks</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                     org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCorruptFileBlocksRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.ListEncryptionZonesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#listEncryptionZones(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.ListEncryptionZonesRequestProto)">listEncryptionZones</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                   org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.ListEncryptionZonesRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#listXAttrs(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsRequestProto)">listXAttrs</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
          org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#metaSave(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveRequestProto)">metaSave</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MkdirsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#mkdirs(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MkdirsRequestProto)">mkdirs</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MkdirsRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#modifyAclEntries(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesRequestProto)">modifyAclEntries</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCacheDirectiveResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#modifyCacheDirective(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCacheDirectiveRequestProto)">modifyCacheDirective</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCacheDirectiveRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCachePoolResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#modifyCachePool(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCachePoolRequestProto)">modifyCachePool</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
               org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCachePoolRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RecoverLeaseResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#recoverLease(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RecoverLeaseRequestProto)">recoverLease</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RecoverLeaseRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#refreshNodes(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesRequestProto)">refreshNodes</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#removeAcl(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclRequestProto)">removeAcl</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
         org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#removeAclEntries(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesRequestProto)">removeAclEntries</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCacheDirectiveResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#removeCacheDirective(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCacheDirectiveRequestProto)">removeCacheDirective</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCacheDirectiveRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCachePoolResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#removeCachePool(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCachePoolRequestProto)">removeCachePool</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
               org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCachePoolRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#removeDefaultAcl(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclRequestProto)">removeDefaultAcl</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#removeXAttr(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrRequestProto)">removeXAttr</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
           org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#rename(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameRequestProto)">rename</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2ResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#rename2(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2RequestProto)">rename2</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
       org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2RequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#renameSnapshot(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotRequestProto)">renameSnapshot</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.security.proto.SecurityProtos.RenewDelegationTokenResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#renewDelegationToken(com.google.protobuf.RpcController,%20org.apache.hadoop.security.proto.SecurityProtos.RenewDelegationTokenRequestProto)">renewDelegationToken</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.security.proto.SecurityProtos.RenewDelegationTokenRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#renewLease(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseRequestProto)">renewLease</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#reportBadBlocks(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksRequestProto)">reportBadBlocks</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
               org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RestoreFailedStorageResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#restoreFailedStorage(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RestoreFailedStorageRequestProto)">restoreFailedStorage</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RestoreFailedStorageRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollEditsResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#rollEdits(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollEditsRequestProto)">rollEdits</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
         org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollEditsRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#rollingUpgrade(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeRequestProto)">rollingUpgrade</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#saveNamespace(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceRequestProto)">saveNamespace</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
             org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setAcl(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclRequestProto)">setAcl</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
      org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setBalancerBandwidth(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthRequestProto)">setBalancerBandwidth</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setOwner(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerRequestProto)">setOwner</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setPermission(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionRequestProto)">setPermission</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
             org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setQuota(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaRequestProto)">setQuota</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetReplicationResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setReplication(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetReplicationRequestProto)">setReplication</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetReplicationRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetSafeModeResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setSafeMode(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetSafeModeRequestProto)">setSafeMode</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
           org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetSafeModeRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setStoragePolicy(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyRequestProto)">setStoragePolicy</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyRequestProto&nbsp;request)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setTimes(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesRequestProto)">setTimes</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#setXAttr(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrRequestProto)">setXAttr</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.TruncateResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#truncate(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.TruncateRequestProto)">truncate</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.TruncateRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdateBlockForPipelineResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#updateBlockForPipeline(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdateBlockForPipelineRequestProto)">updateBlockForPipeline</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
                      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdateBlockForPipelineRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineResponseProto</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html#updatePipeline(com.google.protobuf.RpcController,%20org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineRequestProto)">updatePipeline</a></strong>(com.google.protobuf.RpcController&nbsp;controller,
              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineRequestProto&nbsp;req)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></h3>
<code><a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#clone()" title="class or interface in java.lang">clone</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#equals(java.lang.Object)" title="class or interface in java.lang">equals</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#finalize()" title="class or interface in java.lang">finalize</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#getClass()" title="class or interface in java.lang">getClass</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#hashCode()" title="class or interface in java.lang">hashCode</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#notify()" title="class or interface in java.lang">notify</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#notifyAll()" title="class or interface in java.lang">notifyAll</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#toString()" title="class or interface in java.lang">toString</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#wait()" title="class or interface in java.lang">wait</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#wait(long)" title="class or interface in java.lang">wait</a>, <a href="https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html?is-external=true#wait(long,%20int)" title="class or interface in java.lang">wait</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="server">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>server</h4>
<pre>private final&nbsp;<a href="../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="interface in org.apache.hadoop.hdfs.protocol">ClientProtocol</a> server</pre>
</li>
</ul>
<a name="VOID_DELETE_SNAPSHOT_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_DELETE_SNAPSHOT_RESPONSE</h4>
<pre>static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotResponseProto VOID_DELETE_SNAPSHOT_RESPONSE</pre>
</li>
</ul>
<a name="VOID_RENAME_SNAPSHOT_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_RENAME_SNAPSHOT_RESPONSE</h4>
<pre>static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotResponseProto VOID_RENAME_SNAPSHOT_RESPONSE</pre>
</li>
</ul>
<a name="VOID_ALLOW_SNAPSHOT_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_ALLOW_SNAPSHOT_RESPONSE</h4>
<pre>static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotResponseProto VOID_ALLOW_SNAPSHOT_RESPONSE</pre>
</li>
</ul>
<a name="VOID_DISALLOW_SNAPSHOT_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_DISALLOW_SNAPSHOT_RESPONSE</h4>
<pre>static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotResponseProto VOID_DISALLOW_SNAPSHOT_RESPONSE</pre>
</li>
</ul>
<a name="NULL_GET_SNAPSHOTTABLE_DIR_LISTING_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>NULL_GET_SNAPSHOTTABLE_DIR_LISTING_RESPONSE</h4>
<pre>static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingResponseProto NULL_GET_SNAPSHOTTABLE_DIR_LISTING_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SET_STORAGE_POLICY_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SET_STORAGE_POLICY_RESPONSE</h4>
<pre>static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyResponseProto VOID_SET_STORAGE_POLICY_RESPONSE</pre>
</li>
</ul>
<a name="VOID_CREATE_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_CREATE_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateResponseProto VOID_CREATE_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SET_PERM_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SET_PERM_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionResponseProto VOID_SET_PERM_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SET_OWNER_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SET_OWNER_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerResponseProto VOID_SET_OWNER_RESPONSE</pre>
</li>
</ul>
<a name="VOID_ADD_BLOCK_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_ADD_BLOCK_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockResponseProto VOID_ADD_BLOCK_RESPONSE</pre>
</li>
</ul>
<a name="VOID_REP_BAD_BLOCK_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_REP_BAD_BLOCK_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksResponseProto VOID_REP_BAD_BLOCK_RESPONSE</pre>
</li>
</ul>
<a name="VOID_CONCAT_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_CONCAT_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatResponseProto VOID_CONCAT_RESPONSE</pre>
</li>
</ul>
<a name="VOID_RENAME2_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_RENAME2_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2ResponseProto VOID_RENAME2_RESPONSE</pre>
</li>
</ul>
<a name="VOID_GETLISTING_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_GETLISTING_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingResponseProto VOID_GETLISTING_RESPONSE</pre>
</li>
</ul>
<a name="VOID_RENEWLEASE_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_RENEWLEASE_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseResponseProto VOID_RENEWLEASE_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SAVENAMESPACE_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SAVENAMESPACE_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceResponseProto VOID_SAVENAMESPACE_RESPONSE</pre>
</li>
</ul>
<a name="VOID_REFRESHNODES_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_REFRESHNODES_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesResponseProto VOID_REFRESHNODES_RESPONSE</pre>
</li>
</ul>
<a name="VOID_FINALIZEUPGRADE_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_FINALIZEUPGRADE_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeResponseProto VOID_FINALIZEUPGRADE_RESPONSE</pre>
</li>
</ul>
<a name="VOID_METASAVE_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_METASAVE_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveResponseProto VOID_METASAVE_RESPONSE</pre>
</li>
</ul>
<a name="VOID_GETFILEINFO_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_GETFILEINFO_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoResponseProto VOID_GETFILEINFO_RESPONSE</pre>
</li>
</ul>
<a name="VOID_GETFILELINKINFO_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_GETFILELINKINFO_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoResponseProto VOID_GETFILELINKINFO_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SETQUOTA_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SETQUOTA_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaResponseProto VOID_SETQUOTA_RESPONSE</pre>
</li>
</ul>
<a name="VOID_FSYNC_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_FSYNC_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncResponseProto VOID_FSYNC_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SETTIMES_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SETTIMES_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesResponseProto VOID_SETTIMES_RESPONSE</pre>
</li>
</ul>
<a name="VOID_CREATESYMLINK_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_CREATESYMLINK_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkResponseProto VOID_CREATESYMLINK_RESPONSE</pre>
</li>
</ul>
<a name="VOID_UPDATEPIPELINE_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_UPDATEPIPELINE_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineResponseProto VOID_UPDATEPIPELINE_RESPONSE</pre>
</li>
</ul>
<a name="VOID_CANCELDELEGATIONTOKEN_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_CANCELDELEGATIONTOKEN_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenResponseProto VOID_CANCELDELEGATIONTOKEN_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SETBALANCERBANDWIDTH_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SETBALANCERBANDWIDTH_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthResponseProto VOID_SETBALANCERBANDWIDTH_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SETACL_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SETACL_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclResponseProto VOID_SETACL_RESPONSE</pre>
</li>
</ul>
<a name="VOID_MODIFYACLENTRIES_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_MODIFYACLENTRIES_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesResponseProto VOID_MODIFYACLENTRIES_RESPONSE</pre>
</li>
</ul>
<a name="VOID_REMOVEACLENTRIES_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_REMOVEACLENTRIES_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesResponseProto VOID_REMOVEACLENTRIES_RESPONSE</pre>
</li>
</ul>
<a name="VOID_REMOVEDEFAULTACL_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_REMOVEDEFAULTACL_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclResponseProto VOID_REMOVEDEFAULTACL_RESPONSE</pre>
</li>
</ul>
<a name="VOID_REMOVEACL_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_REMOVEACL_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclResponseProto VOID_REMOVEACL_RESPONSE</pre>
</li>
</ul>
<a name="VOID_SETXATTR_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_SETXATTR_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrResponseProto VOID_SETXATTR_RESPONSE</pre>
</li>
</ul>
<a name="VOID_REMOVEXATTR_RESPONSE">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>VOID_REMOVEXATTR_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrResponseProto VOID_REMOVEXATTR_RESPONSE</pre>
</li>
</ul>
<a name="VOID_CHECKACCESS_RESPONSE">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>VOID_CHECKACCESS_RESPONSE</h4>
<pre>private static final&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessResponseProto VOID_CHECKACCESS_RESPONSE</pre>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="ClientNamenodeProtocolServerSideTranslatorPB(org.apache.hadoop.hdfs.protocol.ClientProtocol)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>ClientNamenodeProtocolServerSideTranslatorPB</h4>
<pre>public&nbsp;ClientNamenodeProtocolServerSideTranslatorPB(<a href="../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="interface in org.apache.hadoop.hdfs.protocol">ClientProtocol</a>&nbsp;server)
                                             throws <a href="https://docs.oracle.com/javase/7/docs/api/java/io/IOException.html?is-external=true" title="class or interface in java.io">IOException</a></pre>
<div class="block">Constructor</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>server</code> - - the NN server</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="https://docs.oracle.com/javase/7/docs/api/java/io/IOException.html?is-external=true" title="class or interface in java.io">IOException</a></code></dd></dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="getBlockLocations(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getBlockLocations</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsResponseProto&nbsp;getBlockLocations(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetBlockLocationsRequestProto&nbsp;req)
                                                                                                                    throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getBlockLocations</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getServerDefaults(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetServerDefaultsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getServerDefaults</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetServerDefaultsResponseProto&nbsp;getServerDefaults(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetServerDefaultsRequestProto&nbsp;req)
                                                                                                                    throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getServerDefaults</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="create(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>create</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateResponseProto&nbsp;create(com.google.protobuf.RpcController&nbsp;controller,
                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateRequestProto&nbsp;req)
                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>create</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="append(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AppendRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>append</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AppendResponseProto&nbsp;append(com.google.protobuf.RpcController&nbsp;controller,
                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AppendRequestProto&nbsp;req)
                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>append</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setReplication(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetReplicationRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setReplication</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetReplicationResponseProto&nbsp;setReplication(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetReplicationRequestProto&nbsp;req)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setReplication</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setPermission(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setPermission</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionResponseProto&nbsp;setPermission(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetPermissionRequestProto&nbsp;req)
                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setPermission</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setOwner(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setOwner</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerResponseProto&nbsp;setOwner(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetOwnerRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setOwner</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="abandonBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>abandonBlock</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockResponseProto&nbsp;abandonBlock(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AbandonBlockRequestProto&nbsp;req)
                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>abandonBlock</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="addBlock(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddBlockRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addBlock</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddBlockResponseProto&nbsp;addBlock(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddBlockRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>addBlock</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getAdditionalDatanode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetAdditionalDatanodeRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAdditionalDatanode</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetAdditionalDatanodeResponseProto&nbsp;getAdditionalDatanode(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetAdditionalDatanodeRequestProto&nbsp;req)
                                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getAdditionalDatanode</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="complete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CompleteRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>complete</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CompleteResponseProto&nbsp;complete(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CompleteRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>complete</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="reportBadBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reportBadBlocks</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksResponseProto&nbsp;reportBadBlocks(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ReportBadBlocksRequestProto&nbsp;req)
                                                                                                                throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>reportBadBlocks</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="concat(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>concat</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatResponseProto&nbsp;concat(com.google.protobuf.RpcController&nbsp;controller,
                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ConcatRequestProto&nbsp;req)
                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>concat</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="rename(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rename</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameResponseProto&nbsp;rename(com.google.protobuf.RpcController&nbsp;controller,
                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameRequestProto&nbsp;req)
                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>rename</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="rename2(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2RequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rename2</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2ResponseProto&nbsp;rename2(com.google.protobuf.RpcController&nbsp;controller,
                                                                                              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.Rename2RequestProto&nbsp;req)
                                                                                                throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>rename2</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="truncate(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.TruncateRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>truncate</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.TruncateResponseProto&nbsp;truncate(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.TruncateRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>truncate</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="delete(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>delete</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteResponseProto&nbsp;delete(com.google.protobuf.RpcController&nbsp;controller,
                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteRequestProto&nbsp;req)
                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>delete</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="mkdirs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MkdirsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mkdirs</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MkdirsResponseProto&nbsp;mkdirs(com.google.protobuf.RpcController&nbsp;controller,
                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MkdirsRequestProto&nbsp;req)
                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>mkdirs</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getListing</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingResponseProto&nbsp;getListing(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetListingRequestProto&nbsp;req)
                                                                                                      throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getListing</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="renewLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>renewLease</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseResponseProto&nbsp;renewLease(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenewLeaseRequestProto&nbsp;req)
                                                                                                      throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>renewLease</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="recoverLease(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RecoverLeaseRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>recoverLease</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RecoverLeaseResponseProto&nbsp;recoverLease(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RecoverLeaseRequestProto&nbsp;req)
                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>recoverLease</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="restoreFailedStorage(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RestoreFailedStorageRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>restoreFailedStorage</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RestoreFailedStorageResponseProto&nbsp;restoreFailedStorage(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RestoreFailedStorageRequestProto&nbsp;req)
                                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>restoreFailedStorage</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getFsStats(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatusRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFsStats</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatsResponseProto&nbsp;getFsStats(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFsStatusRequestProto&nbsp;req)
                                                                                                      throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getFsStats</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getDatanodeReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeReportRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDatanodeReport</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeReportResponseProto&nbsp;getDatanodeReport(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeReportRequestProto&nbsp;req)
                                                                                                                    throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getDatanodeReport</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getDatanodeStorageReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeStorageReportRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDatanodeStorageReport</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeStorageReportResponseProto&nbsp;getDatanodeStorageReport(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDatanodeStorageReportRequestProto&nbsp;req)
                                                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getDatanodeStorageReport</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getPreferredBlockSize(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetPreferredBlockSizeRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPreferredBlockSize</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetPreferredBlockSizeResponseProto&nbsp;getPreferredBlockSize(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetPreferredBlockSizeRequestProto&nbsp;req)
                                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getPreferredBlockSize</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setSafeMode(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetSafeModeRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setSafeMode</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetSafeModeResponseProto&nbsp;setSafeMode(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetSafeModeRequestProto&nbsp;req)
                                                                                                        throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setSafeMode</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="saveNamespace(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveNamespace</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceResponseProto&nbsp;saveNamespace(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SaveNamespaceRequestProto&nbsp;req)
                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>saveNamespace</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="rollEdits(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollEditsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rollEdits</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollEditsResponseProto&nbsp;rollEdits(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollEditsRequestProto&nbsp;request)
                                                                                                    throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>rollEdits</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="refreshNodes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>refreshNodes</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesResponseProto&nbsp;refreshNodes(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RefreshNodesRequestProto&nbsp;req)
                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>refreshNodes</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="finalizeUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>finalizeUpgrade</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeResponseProto&nbsp;finalizeUpgrade(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FinalizeUpgradeRequestProto&nbsp;req)
                                                                                                                throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>finalizeUpgrade</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="rollingUpgrade(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rollingUpgrade</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeResponseProto&nbsp;rollingUpgrade(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RollingUpgradeRequestProto&nbsp;req)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>rollingUpgrade</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="listCorruptFileBlocks(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCorruptFileBlocksRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listCorruptFileBlocks</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCorruptFileBlocksResponseProto&nbsp;listCorruptFileBlocks(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCorruptFileBlocksRequestProto&nbsp;req)
                                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>listCorruptFileBlocks</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="metaSave(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>metaSave</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveResponseProto&nbsp;metaSave(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.MetaSaveRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>metaSave</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getFileInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFileInfo</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoResponseProto&nbsp;getFileInfo(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileInfoRequestProto&nbsp;req)
                                                                                                        throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getFileInfo</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getFileLinkInfo(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFileLinkInfo</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoResponseProto&nbsp;getFileLinkInfo(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetFileLinkInfoRequestProto&nbsp;req)
                                                                                                                throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getFileLinkInfo</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getContentSummary(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetContentSummaryRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getContentSummary</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetContentSummaryResponseProto&nbsp;getContentSummary(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetContentSummaryRequestProto&nbsp;req)
                                                                                                                    throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getContentSummary</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setQuota(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setQuota</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaResponseProto&nbsp;setQuota(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetQuotaRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setQuota</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="fsync(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fsync</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncResponseProto&nbsp;fsync(com.google.protobuf.RpcController&nbsp;controller,
                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.FsyncRequestProto&nbsp;req)
                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>fsync</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setTimes(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setTimes</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesResponseProto&nbsp;setTimes(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetTimesRequestProto&nbsp;req)
                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setTimes</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="createSymlink(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createSymlink</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkResponseProto&nbsp;createSymlink(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSymlinkRequestProto&nbsp;req)
                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>createSymlink</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getLinkTarget(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetLinkTargetRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLinkTarget</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetLinkTargetResponseProto&nbsp;getLinkTarget(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetLinkTargetRequestProto&nbsp;req)
                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getLinkTarget</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="updateBlockForPipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdateBlockForPipelineRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateBlockForPipeline</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdateBlockForPipelineResponseProto&nbsp;updateBlockForPipeline(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdateBlockForPipelineRequestProto&nbsp;req)
                                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>updateBlockForPipeline</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="updatePipeline(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updatePipeline</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineResponseProto&nbsp;updatePipeline(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.UpdatePipelineRequestProto&nbsp;req)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>updatePipeline</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos.GetDelegationTokenRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDelegationToken</h4>
<pre>public&nbsp;org.apache.hadoop.security.proto.SecurityProtos.GetDelegationTokenResponseProto&nbsp;getDelegationToken(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                 org.apache.hadoop.security.proto.SecurityProtos.GetDelegationTokenRequestProto&nbsp;req)
                                                                                                   throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getDelegationToken</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="renewDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos.RenewDelegationTokenRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>renewDelegationToken</h4>
<pre>public&nbsp;org.apache.hadoop.security.proto.SecurityProtos.RenewDelegationTokenResponseProto&nbsp;renewDelegationToken(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                     org.apache.hadoop.security.proto.SecurityProtos.RenewDelegationTokenRequestProto&nbsp;req)
                                                                                                       throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>renewDelegationToken</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="cancelDelegationToken(com.google.protobuf.RpcController, org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cancelDelegationToken</h4>
<pre>public&nbsp;org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenResponseProto&nbsp;cancelDelegationToken(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                       org.apache.hadoop.security.proto.SecurityProtos.CancelDelegationTokenRequestProto&nbsp;req)
                                                                                                         throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>cancelDelegationToken</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setBalancerBandwidth(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setBalancerBandwidth</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthResponseProto&nbsp;setBalancerBandwidth(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetBalancerBandwidthRequestProto&nbsp;req)
                                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setBalancerBandwidth</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getDataEncryptionKey(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDataEncryptionKeyRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDataEncryptionKey</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDataEncryptionKeyResponseProto&nbsp;getDataEncryptionKey(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetDataEncryptionKeyRequestProto&nbsp;request)
                                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getDataEncryptionKey</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="createSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSnapshotRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createSnapshot</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSnapshotResponseProto&nbsp;createSnapshot(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CreateSnapshotRequestProto&nbsp;req)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>createSnapshot</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="deleteSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deleteSnapshot</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotResponseProto&nbsp;deleteSnapshot(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DeleteSnapshotRequestProto&nbsp;req)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>deleteSnapshot</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="allowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>allowSnapshot</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotResponseProto&nbsp;allowSnapshot(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AllowSnapshotRequestProto&nbsp;req)
                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>allowSnapshot</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="disallowSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>disallowSnapshot</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotResponseProto&nbsp;disallowSnapshot(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.DisallowSnapshotRequestProto&nbsp;req)
                                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>disallowSnapshot</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="renameSnapshot(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>renameSnapshot</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotResponseProto&nbsp;renameSnapshot(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RenameSnapshotRequestProto&nbsp;request)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>renameSnapshot</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getSnapshottableDirListing(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSnapshottableDirListing</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingResponseProto&nbsp;getSnapshottableDirListing(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshottableDirListingRequestProto&nbsp;request)
                                                                                                                                      throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getSnapshottableDirListing</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getSnapshotDiffReport(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshotDiffReportRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSnapshotDiffReport</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshotDiffReportResponseProto&nbsp;getSnapshotDiffReport(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetSnapshotDiffReportRequestProto&nbsp;request)
                                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getSnapshotDiffReport</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="isFileClosed(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.IsFileClosedRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isFileClosed</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.IsFileClosedResponseProto&nbsp;isFileClosed(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.IsFileClosedRequestProto&nbsp;request)
                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>isFileClosed</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="addCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCacheDirectiveRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addCacheDirective</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCacheDirectiveResponseProto&nbsp;addCacheDirective(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                  org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCacheDirectiveRequestProto&nbsp;request)
                                                                                                                    throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>addCacheDirective</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="modifyCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCacheDirectiveRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>modifyCacheDirective</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCacheDirectiveResponseProto&nbsp;modifyCacheDirective(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCacheDirectiveRequestProto&nbsp;request)
                                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>modifyCacheDirective</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="removeCacheDirective(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCacheDirectiveRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>removeCacheDirective</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCacheDirectiveResponseProto&nbsp;removeCacheDirective(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCacheDirectiveRequestProto&nbsp;request)
                                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>removeCacheDirective</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="listCacheDirectives(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCacheDirectivesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listCacheDirectives</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCacheDirectivesResponseProto&nbsp;listCacheDirectives(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCacheDirectivesRequestProto&nbsp;request)
                                                                                                                        throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>listCacheDirectives</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="addCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCachePoolRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addCachePool</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCachePoolResponseProto&nbsp;addCachePool(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                        org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.AddCachePoolRequestProto&nbsp;request)
                                                                                                          throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>addCachePool</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="modifyCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCachePoolRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>modifyCachePool</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCachePoolResponseProto&nbsp;modifyCachePool(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ModifyCachePoolRequestProto&nbsp;request)
                                                                                                                throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>modifyCachePool</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="removeCachePool(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCachePoolRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>removeCachePool</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCachePoolResponseProto&nbsp;removeCachePool(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                              org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.RemoveCachePoolRequestProto&nbsp;request)
                                                                                                                throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>removeCachePool</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="listCachePools(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCachePoolsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listCachePools</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCachePoolsResponseProto&nbsp;listCachePools(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                            org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ListCachePoolsRequestProto&nbsp;request)
                                                                                                              throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>listCachePools</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="modifyAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>modifyAclEntries</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesResponseProto&nbsp;modifyAclEntries(com.google.protobuf.RpcController&nbsp;controller,
                                                                                             org.apache.hadoop.hdfs.protocol.proto.AclProtos.ModifyAclEntriesRequestProto&nbsp;req)
                                                                                               throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>modifyAclEntries</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="removeAclEntries(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>removeAclEntries</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesResponseProto&nbsp;removeAclEntries(com.google.protobuf.RpcController&nbsp;controller,
                                                                                             org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclEntriesRequestProto&nbsp;req)
                                                                                               throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>removeAclEntries</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="removeDefaultAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>removeDefaultAcl</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclResponseProto&nbsp;removeDefaultAcl(com.google.protobuf.RpcController&nbsp;controller,
                                                                                             org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveDefaultAclRequestProto&nbsp;req)
                                                                                               throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>removeDefaultAcl</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="removeAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>removeAcl</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclResponseProto&nbsp;removeAcl(com.google.protobuf.RpcController&nbsp;controller,
                                                                               org.apache.hadoop.hdfs.protocol.proto.AclProtos.RemoveAclRequestProto&nbsp;req)
                                                                                 throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>removeAcl</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setAcl(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setAcl</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclResponseProto&nbsp;setAcl(com.google.protobuf.RpcController&nbsp;controller,
                                                                         org.apache.hadoop.hdfs.protocol.proto.AclProtos.SetAclRequestProto&nbsp;req)
                                                                           throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setAcl</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getAclStatus(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAclStatus</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusResponseProto&nbsp;getAclStatus(com.google.protobuf.RpcController&nbsp;controller,
                                                                                     org.apache.hadoop.hdfs.protocol.proto.AclProtos.GetAclStatusRequestProto&nbsp;req)
                                                                                       throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getAclStatus</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="createEncryptionZone(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.CreateEncryptionZoneRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createEncryptionZone</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.CreateEncryptionZoneResponseProto&nbsp;createEncryptionZone(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                 org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.CreateEncryptionZoneRequestProto&nbsp;req)
                                                                                                                   throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>createEncryptionZone</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getEZForPath(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.GetEZForPathRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getEZForPath</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.GetEZForPathResponseProto&nbsp;getEZForPath(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                 org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.GetEZForPathRequestProto&nbsp;req)
                                                                                                   throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getEZForPath</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="listEncryptionZones(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.ListEncryptionZonesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listEncryptionZones</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.ListEncryptionZonesResponseProto&nbsp;listEncryptionZones(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                               org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos.ListEncryptionZonesRequestProto&nbsp;req)
                                                                                                                 throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>listEncryptionZones</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setXAttr</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrResponseProto&nbsp;setXAttr(com.google.protobuf.RpcController&nbsp;controller,
                                                                               org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.SetXAttrRequestProto&nbsp;req)
                                                                                 throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setXAttr</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getXAttrs</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsResponseProto&nbsp;getXAttrs(com.google.protobuf.RpcController&nbsp;controller,
                                                                                 org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.GetXAttrsRequestProto&nbsp;req)
                                                                                   throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getXAttrs</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="listXAttrs(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listXAttrs</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsResponseProto&nbsp;listXAttrs(com.google.protobuf.RpcController&nbsp;controller,
                                                                                   org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.ListXAttrsRequestProto&nbsp;req)
                                                                                     throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>listXAttrs</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="removeXAttr(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>removeXAttr</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrResponseProto&nbsp;removeXAttr(com.google.protobuf.RpcController&nbsp;controller,
                                                                                     org.apache.hadoop.hdfs.protocol.proto.XAttrProtos.RemoveXAttrRequestProto&nbsp;req)
                                                                                       throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>removeXAttr</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="checkAccess(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>checkAccess</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessResponseProto&nbsp;checkAccess(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                      org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.CheckAccessRequestProto&nbsp;req)
                                                                                                        throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>checkAccess</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="setStoragePolicy(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setStoragePolicy</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyResponseProto&nbsp;setStoragePolicy(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.SetStoragePolicyRequestProto&nbsp;request)
                                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>setStoragePolicy</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getStoragePolicies(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetStoragePoliciesRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStoragePolicies</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetStoragePoliciesResponseProto&nbsp;getStoragePolicies(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetStoragePoliciesRequestProto&nbsp;request)
                                                                                                                      throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getStoragePolicies</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getCurrentEditLogTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetCurrentEditLogTxidRequestProto)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCurrentEditLogTxid</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetCurrentEditLogTxidResponseProto&nbsp;getCurrentEditLogTxid(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                          org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetCurrentEditLogTxidRequestProto&nbsp;req)
                                                                                                                            throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getCurrentEditLogTxid</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
<a name="getEditsFromTxid(com.google.protobuf.RpcController, org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetEditsFromTxidRequestProto)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>getEditsFromTxid</h4>
<pre>public&nbsp;org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetEditsFromTxidResponseProto&nbsp;getEditsFromTxid(com.google.protobuf.RpcController&nbsp;controller,
                                                                                                                org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.GetEditsFromTxidRequestProto&nbsp;req)
                                                                                                                  throws com.google.protobuf.ServiceException</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code>getEditsFromTxid</code>&nbsp;in interface&nbsp;<code>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.ClientNamenodeProtocol.BlockingInterface</code></dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>com.google.protobuf.ServiceException</code></dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="class-use/ClientNamenodeProtocolServerSideTranslatorPB.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolPB.html" title="interface in org.apache.hadoop.hdfs.protocolPB"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.html" title="class in org.apache.hadoop.hdfs.protocolPB"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolServerSideTranslatorPB.html" target="_top">Frames</a></li>
<li><a href="ClientNamenodeProtocolServerSideTranslatorPB.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
