<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<title>Source code</title>
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span>/**<a name="line.1"></a>
<span class="sourceLineNo">002</span> * Licensed to the Apache Software Foundation (ASF) under one<a name="line.2"></a>
<span class="sourceLineNo">003</span> * or more contributor license agreements.  See the NOTICE file<a name="line.3"></a>
<span class="sourceLineNo">004</span> * distributed with this work for additional information<a name="line.4"></a>
<span class="sourceLineNo">005</span> * regarding copyright ownership.  The ASF licenses this file<a name="line.5"></a>
<span class="sourceLineNo">006</span> * to you under the Apache License, Version 2.0 (the<a name="line.6"></a>
<span class="sourceLineNo">007</span> * "License"); you may not use this file except in compliance<a name="line.7"></a>
<span class="sourceLineNo">008</span> * with the License.  You may obtain a copy of the License at<a name="line.8"></a>
<span class="sourceLineNo">009</span> *<a name="line.9"></a>
<span class="sourceLineNo">010</span> *     http://www.apache.org/licenses/LICENSE-2.0<a name="line.10"></a>
<span class="sourceLineNo">011</span> *<a name="line.11"></a>
<span class="sourceLineNo">012</span> * Unless required by applicable law or agreed to in writing, software<a name="line.12"></a>
<span class="sourceLineNo">013</span> * distributed under the License is distributed on an "AS IS" BASIS,<a name="line.13"></a>
<span class="sourceLineNo">014</span> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<a name="line.14"></a>
<span class="sourceLineNo">015</span> * See the License for the specific language governing permissions and<a name="line.15"></a>
<span class="sourceLineNo">016</span> * limitations under the License.<a name="line.16"></a>
<span class="sourceLineNo">017</span> */<a name="line.17"></a>
<span class="sourceLineNo">018</span>package org.apache.hadoop.hdfs;<a name="line.18"></a>
<span class="sourceLineNo">019</span><a name="line.19"></a>
<span class="sourceLineNo">020</span>import static org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.Status.SUCCESS;<a name="line.20"></a>
<span class="sourceLineNo">021</span><a name="line.21"></a>
<span class="sourceLineNo">022</span>import java.io.BufferedOutputStream;<a name="line.22"></a>
<span class="sourceLineNo">023</span>import java.io.DataInputStream;<a name="line.23"></a>
<span class="sourceLineNo">024</span>import java.io.DataOutputStream;<a name="line.24"></a>
<span class="sourceLineNo">025</span>import java.io.FileNotFoundException;<a name="line.25"></a>
<span class="sourceLineNo">026</span>import java.io.IOException;<a name="line.26"></a>
<span class="sourceLineNo">027</span>import java.io.InputStream;<a name="line.27"></a>
<span class="sourceLineNo">028</span>import java.io.InterruptedIOException;<a name="line.28"></a>
<span class="sourceLineNo">029</span>import java.io.OutputStream;<a name="line.29"></a>
<span class="sourceLineNo">030</span>import java.net.InetAddress;<a name="line.30"></a>
<span class="sourceLineNo">031</span>import java.net.InetSocketAddress;<a name="line.31"></a>
<span class="sourceLineNo">032</span>import java.net.Socket;<a name="line.32"></a>
<span class="sourceLineNo">033</span>import java.nio.channels.ClosedChannelException;<a name="line.33"></a>
<span class="sourceLineNo">034</span>import java.util.ArrayList;<a name="line.34"></a>
<span class="sourceLineNo">035</span>import java.util.Arrays;<a name="line.35"></a>
<span class="sourceLineNo">036</span>import java.util.EnumSet;<a name="line.36"></a>
<span class="sourceLineNo">037</span>import java.util.HashSet;<a name="line.37"></a>
<span class="sourceLineNo">038</span>import java.util.LinkedList;<a name="line.38"></a>
<span class="sourceLineNo">039</span>import java.util.List;<a name="line.39"></a>
<span class="sourceLineNo">040</span>import java.util.concurrent.TimeUnit;<a name="line.40"></a>
<span class="sourceLineNo">041</span>import java.util.concurrent.atomic.AtomicBoolean;<a name="line.41"></a>
<span class="sourceLineNo">042</span>import java.util.concurrent.atomic.AtomicInteger;<a name="line.42"></a>
<span class="sourceLineNo">043</span>import java.util.concurrent.atomic.AtomicReference;<a name="line.43"></a>
<span class="sourceLineNo">044</span><a name="line.44"></a>
<span class="sourceLineNo">045</span>import org.apache.hadoop.HadoopIllegalArgumentException;<a name="line.45"></a>
<span class="sourceLineNo">046</span>import org.apache.hadoop.classification.InterfaceAudience;<a name="line.46"></a>
<span class="sourceLineNo">047</span>import org.apache.hadoop.crypto.CryptoProtocolVersion;<a name="line.47"></a>
<span class="sourceLineNo">048</span>import org.apache.hadoop.fs.CanSetDropBehind;<a name="line.48"></a>
<span class="sourceLineNo">049</span>import org.apache.hadoop.fs.CreateFlag;<a name="line.49"></a>
<span class="sourceLineNo">050</span>import org.apache.hadoop.fs.FSOutputSummer;<a name="line.50"></a>
<span class="sourceLineNo">051</span>import org.apache.hadoop.fs.FileAlreadyExistsException;<a name="line.51"></a>
<span class="sourceLineNo">052</span>import org.apache.hadoop.fs.FileEncryptionInfo;<a name="line.52"></a>
<span class="sourceLineNo">053</span>import org.apache.hadoop.fs.ParentNotDirectoryException;<a name="line.53"></a>
<span class="sourceLineNo">054</span>import org.apache.hadoop.fs.permission.FsPermission;<a name="line.54"></a>
<span class="sourceLineNo">055</span>import org.apache.hadoop.fs.StorageType;<a name="line.55"></a>
<span class="sourceLineNo">056</span>import org.apache.hadoop.fs.Syncable;<a name="line.56"></a>
<span class="sourceLineNo">057</span>import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;<a name="line.57"></a>
<span class="sourceLineNo">058</span>import org.apache.hadoop.hdfs.client.HdfsDataOutputStream.SyncFlag;<a name="line.58"></a>
<span class="sourceLineNo">059</span>import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;<a name="line.59"></a>
<span class="sourceLineNo">060</span>import org.apache.hadoop.hdfs.protocol.DSQuotaExceededException;<a name="line.60"></a>
<span class="sourceLineNo">061</span>import org.apache.hadoop.hdfs.protocol.DatanodeInfo;<a name="line.61"></a>
<span class="sourceLineNo">062</span>import org.apache.hadoop.hdfs.protocol.ExtendedBlock;<a name="line.62"></a>
<span class="sourceLineNo">063</span>import org.apache.hadoop.hdfs.protocol.HdfsConstants;<a name="line.63"></a>
<span class="sourceLineNo">064</span>import org.apache.hadoop.hdfs.protocol.HdfsFileStatus;<a name="line.64"></a>
<span class="sourceLineNo">065</span>import org.apache.hadoop.hdfs.protocol.LocatedBlock;<a name="line.65"></a>
<span class="sourceLineNo">066</span>import org.apache.hadoop.hdfs.protocol.NSQuotaExceededException;<a name="line.66"></a>
<span class="sourceLineNo">067</span>import org.apache.hadoop.hdfs.protocol.SnapshotAccessControlException;<a name="line.67"></a>
<span class="sourceLineNo">068</span>import org.apache.hadoop.hdfs.protocol.UnresolvedPathException;<a name="line.68"></a>
<span class="sourceLineNo">069</span>import org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage;<a name="line.69"></a>
<span class="sourceLineNo">070</span>import org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtocol;<a name="line.70"></a>
<span class="sourceLineNo">071</span>import org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil;<a name="line.71"></a>
<span class="sourceLineNo">072</span>import org.apache.hadoop.hdfs.protocol.datatransfer.IOStreamPair;<a name="line.72"></a>
<span class="sourceLineNo">073</span>import org.apache.hadoop.hdfs.protocol.datatransfer.InvalidEncryptionKeyException;<a name="line.73"></a>
<span class="sourceLineNo">074</span>import org.apache.hadoop.hdfs.protocol.datatransfer.PacketHeader;<a name="line.74"></a>
<span class="sourceLineNo">075</span>import org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck;<a name="line.75"></a>
<span class="sourceLineNo">076</span>import org.apache.hadoop.hdfs.protocol.datatransfer.Sender;<a name="line.76"></a>
<span class="sourceLineNo">077</span>import org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.BlockOpResponseProto;<a name="line.77"></a>
<span class="sourceLineNo">078</span>import org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos.Status;<a name="line.78"></a>
<span class="sourceLineNo">079</span>import org.apache.hadoop.hdfs.protocolPB.PBHelper;<a name="line.79"></a>
<span class="sourceLineNo">080</span>import org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier;<a name="line.80"></a>
<span class="sourceLineNo">081</span>import org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite;<a name="line.81"></a>
<span class="sourceLineNo">082</span>import org.apache.hadoop.hdfs.server.datanode.CachingStrategy;<a name="line.82"></a>
<span class="sourceLineNo">083</span>import org.apache.hadoop.hdfs.server.namenode.NotReplicatedYetException;<a name="line.83"></a>
<span class="sourceLineNo">084</span>import org.apache.hadoop.hdfs.server.namenode.RetryStartFileException;<a name="line.84"></a>
<span class="sourceLineNo">085</span>import org.apache.hadoop.hdfs.server.namenode.SafeModeException;<a name="line.85"></a>
<span class="sourceLineNo">086</span>import org.apache.hadoop.hdfs.util.ByteArrayManager;<a name="line.86"></a>
<span class="sourceLineNo">087</span>import org.apache.hadoop.io.EnumSetWritable;<a name="line.87"></a>
<span class="sourceLineNo">088</span>import org.apache.hadoop.io.IOUtils;<a name="line.88"></a>
<span class="sourceLineNo">089</span>import org.apache.hadoop.ipc.RemoteException;<a name="line.89"></a>
<span class="sourceLineNo">090</span>import org.apache.hadoop.net.NetUtils;<a name="line.90"></a>
<span class="sourceLineNo">091</span>import org.apache.hadoop.security.AccessControlException;<a name="line.91"></a>
<span class="sourceLineNo">092</span>import org.apache.hadoop.security.token.Token;<a name="line.92"></a>
<span class="sourceLineNo">093</span>import org.apache.hadoop.util.Daemon;<a name="line.93"></a>
<span class="sourceLineNo">094</span>import org.apache.hadoop.util.DataChecksum;<a name="line.94"></a>
<span class="sourceLineNo">095</span>import org.apache.hadoop.util.DataChecksum.Type;<a name="line.95"></a>
<span class="sourceLineNo">096</span>import org.apache.hadoop.util.Progressable;<a name="line.96"></a>
<span class="sourceLineNo">097</span>import org.apache.hadoop.util.Time;<a name="line.97"></a>
<span class="sourceLineNo">098</span>import org.apache.htrace.NullScope;<a name="line.98"></a>
<span class="sourceLineNo">099</span>import org.apache.htrace.Sampler;<a name="line.99"></a>
<span class="sourceLineNo">100</span>import org.apache.htrace.Span;<a name="line.100"></a>
<span class="sourceLineNo">101</span>import org.apache.htrace.Trace;<a name="line.101"></a>
<span class="sourceLineNo">102</span>import org.apache.htrace.TraceInfo;<a name="line.102"></a>
<span class="sourceLineNo">103</span>import org.apache.htrace.TraceScope;<a name="line.103"></a>
<span class="sourceLineNo">104</span><a name="line.104"></a>
<span class="sourceLineNo">105</span>import com.google.common.annotations.VisibleForTesting;<a name="line.105"></a>
<span class="sourceLineNo">106</span>import com.google.common.base.Preconditions;<a name="line.106"></a>
<span class="sourceLineNo">107</span>import com.google.common.cache.CacheBuilder;<a name="line.107"></a>
<span class="sourceLineNo">108</span>import com.google.common.cache.CacheLoader;<a name="line.108"></a>
<span class="sourceLineNo">109</span>import com.google.common.cache.LoadingCache;<a name="line.109"></a>
<span class="sourceLineNo">110</span>import com.google.common.cache.RemovalListener;<a name="line.110"></a>
<span class="sourceLineNo">111</span>import com.google.common.cache.RemovalNotification;<a name="line.111"></a>
<span class="sourceLineNo">112</span><a name="line.112"></a>
<span class="sourceLineNo">113</span><a name="line.113"></a>
<span class="sourceLineNo">114</span>/****************************************************************<a name="line.114"></a>
<span class="sourceLineNo">115</span> * DFSOutputStream creates files from a stream of bytes.<a name="line.115"></a>
<span class="sourceLineNo">116</span> *<a name="line.116"></a>
<span class="sourceLineNo">117</span> * The client application writes data that is cached internally by<a name="line.117"></a>
<span class="sourceLineNo">118</span> * this stream. Data is broken up into packets, each packet is<a name="line.118"></a>
<span class="sourceLineNo">119</span> * typically 64K in size. A packet comprises of chunks. Each chunk<a name="line.119"></a>
<span class="sourceLineNo">120</span> * is typically 512 bytes and has an associated checksum with it.<a name="line.120"></a>
<span class="sourceLineNo">121</span> *<a name="line.121"></a>
<span class="sourceLineNo">122</span> * When a client application fills up the currentPacket, it is<a name="line.122"></a>
<span class="sourceLineNo">123</span> * enqueued into dataQueue.  The DataStreamer thread picks up<a name="line.123"></a>
<span class="sourceLineNo">124</span> * packets from the dataQueue, sends it to the first datanode in<a name="line.124"></a>
<span class="sourceLineNo">125</span> * the pipeline and moves it from the dataQueue to the ackQueue.<a name="line.125"></a>
<span class="sourceLineNo">126</span> * The ResponseProcessor receives acks from the datanodes. When an<a name="line.126"></a>
<span class="sourceLineNo">127</span> * successful ack for a packet is received from all datanodes, the<a name="line.127"></a>
<span class="sourceLineNo">128</span> * ResponseProcessor removes the corresponding packet from the<a name="line.128"></a>
<span class="sourceLineNo">129</span> * ackQueue.<a name="line.129"></a>
<span class="sourceLineNo">130</span> *<a name="line.130"></a>
<span class="sourceLineNo">131</span> * In case of error, all outstanding packets and moved from<a name="line.131"></a>
<span class="sourceLineNo">132</span> * ackQueue. A new pipeline is setup by eliminating the bad<a name="line.132"></a>
<span class="sourceLineNo">133</span> * datanode from the original pipeline. The DataStreamer now<a name="line.133"></a>
<span class="sourceLineNo">134</span> * starts sending packets from the dataQueue.<a name="line.134"></a>
<span class="sourceLineNo">135</span>****************************************************************/<a name="line.135"></a>
<span class="sourceLineNo">136</span>@InterfaceAudience.Private<a name="line.136"></a>
<span class="sourceLineNo">137</span>public class DFSOutputStream extends FSOutputSummer<a name="line.137"></a>
<span class="sourceLineNo">138</span>    implements Syncable, CanSetDropBehind {<a name="line.138"></a>
<span class="sourceLineNo">139</span>  private final long dfsclientSlowLogThresholdMs;<a name="line.139"></a>
<span class="sourceLineNo">140</span>  /**<a name="line.140"></a>
<span class="sourceLineNo">141</span>   * Number of times to retry creating a file when there are transient <a name="line.141"></a>
<span class="sourceLineNo">142</span>   * errors (typically related to encryption zones and KeyProvider operations).<a name="line.142"></a>
<span class="sourceLineNo">143</span>   */<a name="line.143"></a>
<span class="sourceLineNo">144</span>  @VisibleForTesting<a name="line.144"></a>
<span class="sourceLineNo">145</span>  static final int CREATE_RETRY_COUNT = 10;<a name="line.145"></a>
<span class="sourceLineNo">146</span>  @VisibleForTesting<a name="line.146"></a>
<span class="sourceLineNo">147</span>  static CryptoProtocolVersion[] SUPPORTED_CRYPTO_VERSIONS =<a name="line.147"></a>
<span class="sourceLineNo">148</span>      CryptoProtocolVersion.supported();<a name="line.148"></a>
<span class="sourceLineNo">149</span><a name="line.149"></a>
<span class="sourceLineNo">150</span>  private final DFSClient dfsClient;<a name="line.150"></a>
<span class="sourceLineNo">151</span>  private final ByteArrayManager byteArrayManager;<a name="line.151"></a>
<span class="sourceLineNo">152</span>  private Socket s;<a name="line.152"></a>
<span class="sourceLineNo">153</span>  // closed is accessed by different threads under different locks.<a name="line.153"></a>
<span class="sourceLineNo">154</span>  private volatile boolean closed = false;<a name="line.154"></a>
<span class="sourceLineNo">155</span><a name="line.155"></a>
<span class="sourceLineNo">156</span>  private String src;<a name="line.156"></a>
<span class="sourceLineNo">157</span>  private final long fileId;<a name="line.157"></a>
<span class="sourceLineNo">158</span>  private final long blockSize;<a name="line.158"></a>
<span class="sourceLineNo">159</span>  /** Only for DataTransferProtocol.writeBlock(..) */<a name="line.159"></a>
<span class="sourceLineNo">160</span>  private final DataChecksum checksum4WriteBlock;<a name="line.160"></a>
<span class="sourceLineNo">161</span>  private final int bytesPerChecksum; <a name="line.161"></a>
<span class="sourceLineNo">162</span><a name="line.162"></a>
<span class="sourceLineNo">163</span>  // both dataQueue and ackQueue are protected by dataQueue lock<a name="line.163"></a>
<span class="sourceLineNo">164</span>  private final LinkedList&lt;DFSPacket&gt; dataQueue = new LinkedList&lt;DFSPacket&gt;();<a name="line.164"></a>
<span class="sourceLineNo">165</span>  private final LinkedList&lt;DFSPacket&gt; ackQueue = new LinkedList&lt;DFSPacket&gt;();<a name="line.165"></a>
<span class="sourceLineNo">166</span>  private DFSPacket currentPacket = null;<a name="line.166"></a>
<span class="sourceLineNo">167</span>  private DataStreamer streamer;<a name="line.167"></a>
<span class="sourceLineNo">168</span>  private long currentSeqno = 0;<a name="line.168"></a>
<span class="sourceLineNo">169</span>  private long lastQueuedSeqno = -1;<a name="line.169"></a>
<span class="sourceLineNo">170</span>  private long lastAckedSeqno = -1;<a name="line.170"></a>
<span class="sourceLineNo">171</span>  private long bytesCurBlock = 0; // bytes written in current block<a name="line.171"></a>
<span class="sourceLineNo">172</span>  private int packetSize = 0; // write packet size, not including the header.<a name="line.172"></a>
<span class="sourceLineNo">173</span>  private int chunksPerPacket = 0;<a name="line.173"></a>
<span class="sourceLineNo">174</span>  private final AtomicReference&lt;IOException&gt; lastException = new AtomicReference&lt;IOException&gt;();<a name="line.174"></a>
<span class="sourceLineNo">175</span>  private long artificialSlowdown = 0;<a name="line.175"></a>
<span class="sourceLineNo">176</span>  private long lastFlushOffset = 0; // offset when flush was invoked<a name="line.176"></a>
<span class="sourceLineNo">177</span>  //persist blocks on namenode<a name="line.177"></a>
<span class="sourceLineNo">178</span>  private final AtomicBoolean persistBlocks = new AtomicBoolean(false);<a name="line.178"></a>
<span class="sourceLineNo">179</span>  private volatile boolean appendChunk = false;   // appending to existing partial block<a name="line.179"></a>
<span class="sourceLineNo">180</span>  private long initialFileSize = 0; // at time of file open<a name="line.180"></a>
<span class="sourceLineNo">181</span>  private final Progressable progress;<a name="line.181"></a>
<span class="sourceLineNo">182</span>  private final short blockReplication; // replication factor of file<a name="line.182"></a>
<span class="sourceLineNo">183</span>  private boolean shouldSyncBlock = false; // force blocks to disk upon close<a name="line.183"></a>
<span class="sourceLineNo">184</span>  private final AtomicReference&lt;CachingStrategy&gt; cachingStrategy;<a name="line.184"></a>
<span class="sourceLineNo">185</span>  private boolean failPacket = false;<a name="line.185"></a>
<span class="sourceLineNo">186</span>  private FileEncryptionInfo fileEncryptionInfo;<a name="line.186"></a>
<span class="sourceLineNo">187</span>  private static final BlockStoragePolicySuite blockStoragePolicySuite =<a name="line.187"></a>
<span class="sourceLineNo">188</span>      BlockStoragePolicySuite.createDefaultSuite();<a name="line.188"></a>
<span class="sourceLineNo">189</span><a name="line.189"></a>
<span class="sourceLineNo">190</span>  /** Use {@link ByteArrayManager} to create buffer for non-heartbeat packets.*/<a name="line.190"></a>
<span class="sourceLineNo">191</span>  private DFSPacket createPacket(int packetSize, int chunksPerPkt, long offsetInBlock,<a name="line.191"></a>
<span class="sourceLineNo">192</span>      long seqno, boolean lastPacketInBlock) throws InterruptedIOException {<a name="line.192"></a>
<span class="sourceLineNo">193</span>    final byte[] buf;<a name="line.193"></a>
<span class="sourceLineNo">194</span>    final int bufferSize = PacketHeader.PKT_MAX_HEADER_LEN + packetSize;<a name="line.194"></a>
<span class="sourceLineNo">195</span><a name="line.195"></a>
<span class="sourceLineNo">196</span>    try {<a name="line.196"></a>
<span class="sourceLineNo">197</span>      buf = byteArrayManager.newByteArray(bufferSize);<a name="line.197"></a>
<span class="sourceLineNo">198</span>    } catch (InterruptedException ie) {<a name="line.198"></a>
<span class="sourceLineNo">199</span>      final InterruptedIOException iioe = new InterruptedIOException(<a name="line.199"></a>
<span class="sourceLineNo">200</span>          "seqno=" + seqno);<a name="line.200"></a>
<span class="sourceLineNo">201</span>      iioe.initCause(ie);<a name="line.201"></a>
<span class="sourceLineNo">202</span>      throw iioe;<a name="line.202"></a>
<span class="sourceLineNo">203</span>    }<a name="line.203"></a>
<span class="sourceLineNo">204</span><a name="line.204"></a>
<span class="sourceLineNo">205</span>    return new DFSPacket(buf, chunksPerPkt, offsetInBlock, seqno,<a name="line.205"></a>
<span class="sourceLineNo">206</span>                         getChecksumSize(), lastPacketInBlock);<a name="line.206"></a>
<span class="sourceLineNo">207</span>  }<a name="line.207"></a>
<span class="sourceLineNo">208</span><a name="line.208"></a>
<span class="sourceLineNo">209</span>  /**<a name="line.209"></a>
<span class="sourceLineNo">210</span>   * For heartbeat packets, create buffer directly by new byte[]<a name="line.210"></a>
<span class="sourceLineNo">211</span>   * since heartbeats should not be blocked.<a name="line.211"></a>
<span class="sourceLineNo">212</span>   */<a name="line.212"></a>
<span class="sourceLineNo">213</span>  private DFSPacket createHeartbeatPacket() throws InterruptedIOException {<a name="line.213"></a>
<span class="sourceLineNo">214</span>    final byte[] buf = new byte[PacketHeader.PKT_MAX_HEADER_LEN];<a name="line.214"></a>
<span class="sourceLineNo">215</span>    return new DFSPacket(buf, 0, 0, DFSPacket.HEART_BEAT_SEQNO,<a name="line.215"></a>
<span class="sourceLineNo">216</span>                         getChecksumSize(), false);<a name="line.216"></a>
<span class="sourceLineNo">217</span>  }<a name="line.217"></a>
<span class="sourceLineNo">218</span><a name="line.218"></a>
<span class="sourceLineNo">219</span>  //<a name="line.219"></a>
<span class="sourceLineNo">220</span>  // The DataStreamer class is responsible for sending data packets to the<a name="line.220"></a>
<span class="sourceLineNo">221</span>  // datanodes in the pipeline. It retrieves a new blockid and block locations<a name="line.221"></a>
<span class="sourceLineNo">222</span>  // from the namenode, and starts streaming packets to the pipeline of<a name="line.222"></a>
<span class="sourceLineNo">223</span>  // Datanodes. Every packet has a sequence number associated with<a name="line.223"></a>
<span class="sourceLineNo">224</span>  // it. When all the packets for a block are sent out and acks for each<a name="line.224"></a>
<span class="sourceLineNo">225</span>  // if them are received, the DataStreamer closes the current block.<a name="line.225"></a>
<span class="sourceLineNo">226</span>  //<a name="line.226"></a>
<span class="sourceLineNo">227</span>  class DataStreamer extends Daemon {<a name="line.227"></a>
<span class="sourceLineNo">228</span>    private volatile boolean streamerClosed = false;<a name="line.228"></a>
<span class="sourceLineNo">229</span>    private ExtendedBlock block; // its length is number of bytes acked<a name="line.229"></a>
<span class="sourceLineNo">230</span>    private Token&lt;BlockTokenIdentifier&gt; accessToken;<a name="line.230"></a>
<span class="sourceLineNo">231</span>    private DataOutputStream blockStream;<a name="line.231"></a>
<span class="sourceLineNo">232</span>    private DataInputStream blockReplyStream;<a name="line.232"></a>
<span class="sourceLineNo">233</span>    private ResponseProcessor response = null;<a name="line.233"></a>
<span class="sourceLineNo">234</span>    private volatile DatanodeInfo[] nodes = null; // list of targets for current block<a name="line.234"></a>
<span class="sourceLineNo">235</span>    private volatile StorageType[] storageTypes = null;<a name="line.235"></a>
<span class="sourceLineNo">236</span>    private volatile String[] storageIDs = null;<a name="line.236"></a>
<span class="sourceLineNo">237</span>    private final LoadingCache&lt;DatanodeInfo, DatanodeInfo&gt; excludedNodes =<a name="line.237"></a>
<span class="sourceLineNo">238</span>        CacheBuilder.newBuilder()<a name="line.238"></a>
<span class="sourceLineNo">239</span>        .expireAfterWrite(<a name="line.239"></a>
<span class="sourceLineNo">240</span>            dfsClient.getConf().excludedNodesCacheExpiry,<a name="line.240"></a>
<span class="sourceLineNo">241</span>            TimeUnit.MILLISECONDS)<a name="line.241"></a>
<span class="sourceLineNo">242</span>        .removalListener(new RemovalListener&lt;DatanodeInfo, DatanodeInfo&gt;() {<a name="line.242"></a>
<span class="sourceLineNo">243</span>          @Override<a name="line.243"></a>
<span class="sourceLineNo">244</span>          public void onRemoval(<a name="line.244"></a>
<span class="sourceLineNo">245</span>              RemovalNotification&lt;DatanodeInfo, DatanodeInfo&gt; notification) {<a name="line.245"></a>
<span class="sourceLineNo">246</span>            DFSClient.LOG.info("Removing node " +<a name="line.246"></a>
<span class="sourceLineNo">247</span>                notification.getKey() + " from the excluded nodes list");<a name="line.247"></a>
<span class="sourceLineNo">248</span>          }<a name="line.248"></a>
<span class="sourceLineNo">249</span>        })<a name="line.249"></a>
<span class="sourceLineNo">250</span>        .build(new CacheLoader&lt;DatanodeInfo, DatanodeInfo&gt;() {<a name="line.250"></a>
<span class="sourceLineNo">251</span>          @Override<a name="line.251"></a>
<span class="sourceLineNo">252</span>          public DatanodeInfo load(DatanodeInfo key) throws Exception {<a name="line.252"></a>
<span class="sourceLineNo">253</span>            return key;<a name="line.253"></a>
<span class="sourceLineNo">254</span>          }<a name="line.254"></a>
<span class="sourceLineNo">255</span>        });<a name="line.255"></a>
<span class="sourceLineNo">256</span>    private String[] favoredNodes;<a name="line.256"></a>
<span class="sourceLineNo">257</span>    volatile boolean hasError = false;<a name="line.257"></a>
<span class="sourceLineNo">258</span>    volatile int errorIndex = -1;<a name="line.258"></a>
<span class="sourceLineNo">259</span>    // Restarting node index<a name="line.259"></a>
<span class="sourceLineNo">260</span>    AtomicInteger restartingNodeIndex = new AtomicInteger(-1);<a name="line.260"></a>
<span class="sourceLineNo">261</span>    private long restartDeadline = 0; // Deadline of DN restart<a name="line.261"></a>
<span class="sourceLineNo">262</span>    private BlockConstructionStage stage;  // block construction stage<a name="line.262"></a>
<span class="sourceLineNo">263</span>    private long bytesSent = 0; // number of bytes that've been sent<a name="line.263"></a>
<span class="sourceLineNo">264</span>    private final boolean isLazyPersistFile;<a name="line.264"></a>
<span class="sourceLineNo">265</span><a name="line.265"></a>
<span class="sourceLineNo">266</span>    /** Nodes have been used in the pipeline before and have failed. */<a name="line.266"></a>
<span class="sourceLineNo">267</span>    private final List&lt;DatanodeInfo&gt; failed = new ArrayList&lt;DatanodeInfo&gt;();<a name="line.267"></a>
<span class="sourceLineNo">268</span>    /** The last ack sequence number before pipeline failure. */<a name="line.268"></a>
<span class="sourceLineNo">269</span>    private long lastAckedSeqnoBeforeFailure = -1;<a name="line.269"></a>
<span class="sourceLineNo">270</span>    private int pipelineRecoveryCount = 0;<a name="line.270"></a>
<span class="sourceLineNo">271</span>    /** Has the current block been hflushed? */<a name="line.271"></a>
<span class="sourceLineNo">272</span>    private boolean isHflushed = false;<a name="line.272"></a>
<span class="sourceLineNo">273</span>    /** Append on an existing block? */<a name="line.273"></a>
<span class="sourceLineNo">274</span>    private final boolean isAppend;<a name="line.274"></a>
<span class="sourceLineNo">275</span><a name="line.275"></a>
<span class="sourceLineNo">276</span>    private DataStreamer(HdfsFileStatus stat, ExtendedBlock block) {<a name="line.276"></a>
<span class="sourceLineNo">277</span>      isAppend = false;<a name="line.277"></a>
<span class="sourceLineNo">278</span>      isLazyPersistFile = isLazyPersist(stat);<a name="line.278"></a>
<span class="sourceLineNo">279</span>      this.block = block;<a name="line.279"></a>
<span class="sourceLineNo">280</span>      stage = BlockConstructionStage.PIPELINE_SETUP_CREATE;<a name="line.280"></a>
<span class="sourceLineNo">281</span>    }<a name="line.281"></a>
<span class="sourceLineNo">282</span>    <a name="line.282"></a>
<span class="sourceLineNo">283</span>    /**<a name="line.283"></a>
<span class="sourceLineNo">284</span>     * Construct a data streamer for appending to the last partial block<a name="line.284"></a>
<span class="sourceLineNo">285</span>     * @param lastBlock last block of the file to be appended<a name="line.285"></a>
<span class="sourceLineNo">286</span>     * @param stat status of the file to be appended<a name="line.286"></a>
<span class="sourceLineNo">287</span>     * @param bytesPerChecksum number of bytes per checksum<a name="line.287"></a>
<span class="sourceLineNo">288</span>     * @throws IOException if error occurs<a name="line.288"></a>
<span class="sourceLineNo">289</span>     */<a name="line.289"></a>
<span class="sourceLineNo">290</span>    private DataStreamer(LocatedBlock lastBlock, HdfsFileStatus stat,<a name="line.290"></a>
<span class="sourceLineNo">291</span>        int bytesPerChecksum) throws IOException {<a name="line.291"></a>
<span class="sourceLineNo">292</span>      isAppend = true;<a name="line.292"></a>
<span class="sourceLineNo">293</span>      stage = BlockConstructionStage.PIPELINE_SETUP_APPEND;<a name="line.293"></a>
<span class="sourceLineNo">294</span>      block = lastBlock.getBlock();<a name="line.294"></a>
<span class="sourceLineNo">295</span>      bytesSent = block.getNumBytes();<a name="line.295"></a>
<span class="sourceLineNo">296</span>      accessToken = lastBlock.getBlockToken();<a name="line.296"></a>
<span class="sourceLineNo">297</span>      isLazyPersistFile = isLazyPersist(stat);<a name="line.297"></a>
<span class="sourceLineNo">298</span>      long usedInLastBlock = stat.getLen() % blockSize;<a name="line.298"></a>
<span class="sourceLineNo">299</span>      int freeInLastBlock = (int)(blockSize - usedInLastBlock);<a name="line.299"></a>
<span class="sourceLineNo">300</span><a name="line.300"></a>
<span class="sourceLineNo">301</span>      // calculate the amount of free space in the pre-existing <a name="line.301"></a>
<span class="sourceLineNo">302</span>      // last crc chunk<a name="line.302"></a>
<span class="sourceLineNo">303</span>      int usedInCksum = (int)(stat.getLen() % bytesPerChecksum);<a name="line.303"></a>
<span class="sourceLineNo">304</span>      int freeInCksum = bytesPerChecksum - usedInCksum;<a name="line.304"></a>
<span class="sourceLineNo">305</span><a name="line.305"></a>
<span class="sourceLineNo">306</span>      // if there is space in the last block, then we have to <a name="line.306"></a>
<span class="sourceLineNo">307</span>      // append to that block<a name="line.307"></a>
<span class="sourceLineNo">308</span>      if (freeInLastBlock == blockSize) {<a name="line.308"></a>
<span class="sourceLineNo">309</span>        throw new IOException("The last block for file " + <a name="line.309"></a>
<span class="sourceLineNo">310</span>            src + " is full.");<a name="line.310"></a>
<span class="sourceLineNo">311</span>      }<a name="line.311"></a>
<span class="sourceLineNo">312</span><a name="line.312"></a>
<span class="sourceLineNo">313</span>      if (usedInCksum &gt; 0 &amp;&amp; freeInCksum &gt; 0) {<a name="line.313"></a>
<span class="sourceLineNo">314</span>        // if there is space in the last partial chunk, then <a name="line.314"></a>
<span class="sourceLineNo">315</span>        // setup in such a way that the next packet will have only <a name="line.315"></a>
<span class="sourceLineNo">316</span>        // one chunk that fills up the partial chunk.<a name="line.316"></a>
<span class="sourceLineNo">317</span>        //<a name="line.317"></a>
<span class="sourceLineNo">318</span>        computePacketChunkSize(0, freeInCksum);<a name="line.318"></a>
<span class="sourceLineNo">319</span>        setChecksumBufSize(freeInCksum);<a name="line.319"></a>
<span class="sourceLineNo">320</span>        appendChunk = true;<a name="line.320"></a>
<span class="sourceLineNo">321</span>      } else {<a name="line.321"></a>
<span class="sourceLineNo">322</span>        // if the remaining space in the block is smaller than <a name="line.322"></a>
<span class="sourceLineNo">323</span>        // that expected size of of a packet, then create <a name="line.323"></a>
<span class="sourceLineNo">324</span>        // smaller size packet.<a name="line.324"></a>
<span class="sourceLineNo">325</span>        //<a name="line.325"></a>
<span class="sourceLineNo">326</span>        computePacketChunkSize(Math.min(dfsClient.getConf().writePacketSize, freeInLastBlock), <a name="line.326"></a>
<span class="sourceLineNo">327</span>            bytesPerChecksum);<a name="line.327"></a>
<span class="sourceLineNo">328</span>      }<a name="line.328"></a>
<span class="sourceLineNo">329</span><a name="line.329"></a>
<span class="sourceLineNo">330</span>      // setup pipeline to append to the last block XXX retries??<a name="line.330"></a>
<span class="sourceLineNo">331</span>      setPipeline(lastBlock);<a name="line.331"></a>
<span class="sourceLineNo">332</span>      errorIndex = -1;   // no errors yet.<a name="line.332"></a>
<span class="sourceLineNo">333</span>      if (nodes.length &lt; 1) {<a name="line.333"></a>
<span class="sourceLineNo">334</span>        throw new IOException("Unable to retrieve blocks locations " +<a name="line.334"></a>
<span class="sourceLineNo">335</span>            " for last block " + block +<a name="line.335"></a>
<span class="sourceLineNo">336</span>            "of file " + src);<a name="line.336"></a>
<span class="sourceLineNo">337</span><a name="line.337"></a>
<span class="sourceLineNo">338</span>      }<a name="line.338"></a>
<span class="sourceLineNo">339</span>    }<a name="line.339"></a>
<span class="sourceLineNo">340</span><a name="line.340"></a>
<span class="sourceLineNo">341</span>    private void setPipeline(LocatedBlock lb) {<a name="line.341"></a>
<span class="sourceLineNo">342</span>      setPipeline(lb.getLocations(), lb.getStorageTypes(), lb.getStorageIDs());<a name="line.342"></a>
<span class="sourceLineNo">343</span>    }<a name="line.343"></a>
<span class="sourceLineNo">344</span>    private void setPipeline(DatanodeInfo[] nodes, StorageType[] storageTypes,<a name="line.344"></a>
<span class="sourceLineNo">345</span>        String[] storageIDs) {<a name="line.345"></a>
<span class="sourceLineNo">346</span>      this.nodes = nodes;<a name="line.346"></a>
<span class="sourceLineNo">347</span>      this.storageTypes = storageTypes;<a name="line.347"></a>
<span class="sourceLineNo">348</span>      this.storageIDs = storageIDs;<a name="line.348"></a>
<span class="sourceLineNo">349</span>    }<a name="line.349"></a>
<span class="sourceLineNo">350</span><a name="line.350"></a>
<span class="sourceLineNo">351</span>    private void setFavoredNodes(String[] favoredNodes) {<a name="line.351"></a>
<span class="sourceLineNo">352</span>      this.favoredNodes = favoredNodes;<a name="line.352"></a>
<span class="sourceLineNo">353</span>    }<a name="line.353"></a>
<span class="sourceLineNo">354</span><a name="line.354"></a>
<span class="sourceLineNo">355</span>    /**<a name="line.355"></a>
<span class="sourceLineNo">356</span>     * Initialize for data streaming<a name="line.356"></a>
<span class="sourceLineNo">357</span>     */<a name="line.357"></a>
<span class="sourceLineNo">358</span>    private void initDataStreaming() {<a name="line.358"></a>
<span class="sourceLineNo">359</span>      this.setName("DataStreamer for file " + src +<a name="line.359"></a>
<span class="sourceLineNo">360</span>          " block " + block);<a name="line.360"></a>
<span class="sourceLineNo">361</span>      response = new ResponseProcessor(nodes);<a name="line.361"></a>
<span class="sourceLineNo">362</span>      response.start();<a name="line.362"></a>
<span class="sourceLineNo">363</span>      stage = BlockConstructionStage.DATA_STREAMING;<a name="line.363"></a>
<span class="sourceLineNo">364</span>    }<a name="line.364"></a>
<span class="sourceLineNo">365</span>    <a name="line.365"></a>
<span class="sourceLineNo">366</span>    private void endBlock() {<a name="line.366"></a>
<span class="sourceLineNo">367</span>      if(DFSClient.LOG.isDebugEnabled()) {<a name="line.367"></a>
<span class="sourceLineNo">368</span>        DFSClient.LOG.debug("Closing old block " + block);<a name="line.368"></a>
<span class="sourceLineNo">369</span>      }<a name="line.369"></a>
<span class="sourceLineNo">370</span>      this.setName("DataStreamer for file " + src);<a name="line.370"></a>
<span class="sourceLineNo">371</span>      closeResponder();<a name="line.371"></a>
<span class="sourceLineNo">372</span>      closeStream();<a name="line.372"></a>
<span class="sourceLineNo">373</span>      setPipeline(null, null, null);<a name="line.373"></a>
<span class="sourceLineNo">374</span>      stage = BlockConstructionStage.PIPELINE_SETUP_CREATE;<a name="line.374"></a>
<span class="sourceLineNo">375</span>    }<a name="line.375"></a>
<span class="sourceLineNo">376</span>    <a name="line.376"></a>
<span class="sourceLineNo">377</span>    /*<a name="line.377"></a>
<span class="sourceLineNo">378</span>     * streamer thread is the only thread that opens streams to datanode, <a name="line.378"></a>
<span class="sourceLineNo">379</span>     * and closes them. Any error recovery is also done by this thread.<a name="line.379"></a>
<span class="sourceLineNo">380</span>     */<a name="line.380"></a>
<span class="sourceLineNo">381</span>    @Override<a name="line.381"></a>
<span class="sourceLineNo">382</span>    public void run() {<a name="line.382"></a>
<span class="sourceLineNo">383</span>      long lastPacket = Time.monotonicNow();<a name="line.383"></a>
<span class="sourceLineNo">384</span>      TraceScope scope = NullScope.INSTANCE;<a name="line.384"></a>
<span class="sourceLineNo">385</span>      while (!streamerClosed &amp;&amp; dfsClient.clientRunning) {<a name="line.385"></a>
<span class="sourceLineNo">386</span>        // if the Responder encountered an error, shutdown Responder<a name="line.386"></a>
<span class="sourceLineNo">387</span>        if (hasError &amp;&amp; response != null) {<a name="line.387"></a>
<span class="sourceLineNo">388</span>          try {<a name="line.388"></a>
<span class="sourceLineNo">389</span>            response.close();<a name="line.389"></a>
<span class="sourceLineNo">390</span>            response.join();<a name="line.390"></a>
<span class="sourceLineNo">391</span>            response = null;<a name="line.391"></a>
<span class="sourceLineNo">392</span>          } catch (InterruptedException  e) {<a name="line.392"></a>
<span class="sourceLineNo">393</span>            DFSClient.LOG.warn("Caught exception ", e);<a name="line.393"></a>
<span class="sourceLineNo">394</span>          }<a name="line.394"></a>
<span class="sourceLineNo">395</span>        }<a name="line.395"></a>
<span class="sourceLineNo">396</span><a name="line.396"></a>
<span class="sourceLineNo">397</span>        DFSPacket one;<a name="line.397"></a>
<span class="sourceLineNo">398</span>        try {<a name="line.398"></a>
<span class="sourceLineNo">399</span>          // process datanode IO errors if any<a name="line.399"></a>
<span class="sourceLineNo">400</span>          boolean doSleep = false;<a name="line.400"></a>
<span class="sourceLineNo">401</span>          if (hasError &amp;&amp; (errorIndex &gt;= 0 || restartingNodeIndex.get() &gt;= 0)) {<a name="line.401"></a>
<span class="sourceLineNo">402</span>            doSleep = processDatanodeError();<a name="line.402"></a>
<span class="sourceLineNo">403</span>          }<a name="line.403"></a>
<span class="sourceLineNo">404</span><a name="line.404"></a>
<span class="sourceLineNo">405</span>          synchronized (dataQueue) {<a name="line.405"></a>
<span class="sourceLineNo">406</span>            // wait for a packet to be sent.<a name="line.406"></a>
<span class="sourceLineNo">407</span>            long now = Time.monotonicNow();<a name="line.407"></a>
<span class="sourceLineNo">408</span>            while ((!streamerClosed &amp;&amp; !hasError &amp;&amp; dfsClient.clientRunning <a name="line.408"></a>
<span class="sourceLineNo">409</span>                &amp;&amp; dataQueue.size() == 0 &amp;&amp; <a name="line.409"></a>
<span class="sourceLineNo">410</span>                (stage != BlockConstructionStage.DATA_STREAMING || <a name="line.410"></a>
<span class="sourceLineNo">411</span>                 stage == BlockConstructionStage.DATA_STREAMING &amp;&amp; <a name="line.411"></a>
<span class="sourceLineNo">412</span>                 now - lastPacket &lt; dfsClient.getConf().socketTimeout/2)) || doSleep ) {<a name="line.412"></a>
<span class="sourceLineNo">413</span>              long timeout = dfsClient.getConf().socketTimeout/2 - (now-lastPacket);<a name="line.413"></a>
<span class="sourceLineNo">414</span>              timeout = timeout &lt;= 0 ? 1000 : timeout;<a name="line.414"></a>
<span class="sourceLineNo">415</span>              timeout = (stage == BlockConstructionStage.DATA_STREAMING)?<a name="line.415"></a>
<span class="sourceLineNo">416</span>                 timeout : 1000;<a name="line.416"></a>
<span class="sourceLineNo">417</span>              try {<a name="line.417"></a>
<span class="sourceLineNo">418</span>                dataQueue.wait(timeout);<a name="line.418"></a>
<span class="sourceLineNo">419</span>              } catch (InterruptedException  e) {<a name="line.419"></a>
<span class="sourceLineNo">420</span>                DFSClient.LOG.warn("Caught exception ", e);<a name="line.420"></a>
<span class="sourceLineNo">421</span>              }<a name="line.421"></a>
<span class="sourceLineNo">422</span>              doSleep = false;<a name="line.422"></a>
<span class="sourceLineNo">423</span>              now = Time.monotonicNow();<a name="line.423"></a>
<span class="sourceLineNo">424</span>            }<a name="line.424"></a>
<span class="sourceLineNo">425</span>            if (streamerClosed || hasError || !dfsClient.clientRunning) {<a name="line.425"></a>
<span class="sourceLineNo">426</span>              continue;<a name="line.426"></a>
<span class="sourceLineNo">427</span>            }<a name="line.427"></a>
<span class="sourceLineNo">428</span>            // get packet to be sent.<a name="line.428"></a>
<span class="sourceLineNo">429</span>            if (dataQueue.isEmpty()) {<a name="line.429"></a>
<span class="sourceLineNo">430</span>              one = createHeartbeatPacket();<a name="line.430"></a>
<span class="sourceLineNo">431</span>              assert one != null;<a name="line.431"></a>
<span class="sourceLineNo">432</span>            } else {<a name="line.432"></a>
<span class="sourceLineNo">433</span>              one = dataQueue.getFirst(); // regular data packet<a name="line.433"></a>
<span class="sourceLineNo">434</span>              long parents[] = one.getTraceParents();<a name="line.434"></a>
<span class="sourceLineNo">435</span>              if (parents.length &gt; 0) {<a name="line.435"></a>
<span class="sourceLineNo">436</span>                scope = Trace.startSpan("dataStreamer", new TraceInfo(0, parents[0]));<a name="line.436"></a>
<span class="sourceLineNo">437</span>                // TODO: use setParents API once it's available from HTrace 3.2<a name="line.437"></a>
<span class="sourceLineNo">438</span>//                scope = Trace.startSpan("dataStreamer", Sampler.ALWAYS);<a name="line.438"></a>
<span class="sourceLineNo">439</span>//                scope.getSpan().setParents(parents);<a name="line.439"></a>
<span class="sourceLineNo">440</span>              }<a name="line.440"></a>
<span class="sourceLineNo">441</span>            }<a name="line.441"></a>
<span class="sourceLineNo">442</span>          }<a name="line.442"></a>
<span class="sourceLineNo">443</span><a name="line.443"></a>
<span class="sourceLineNo">444</span>          // get new block from namenode.<a name="line.444"></a>
<span class="sourceLineNo">445</span>          if (stage == BlockConstructionStage.PIPELINE_SETUP_CREATE) {<a name="line.445"></a>
<span class="sourceLineNo">446</span>            if(DFSClient.LOG.isDebugEnabled()) {<a name="line.446"></a>
<span class="sourceLineNo">447</span>              DFSClient.LOG.debug("Allocating new block");<a name="line.447"></a>
<span class="sourceLineNo">448</span>            }<a name="line.448"></a>
<span class="sourceLineNo">449</span>            setPipeline(nextBlockOutputStream());<a name="line.449"></a>
<span class="sourceLineNo">450</span>            initDataStreaming();<a name="line.450"></a>
<span class="sourceLineNo">451</span>          } else if (stage == BlockConstructionStage.PIPELINE_SETUP_APPEND) {<a name="line.451"></a>
<span class="sourceLineNo">452</span>            if(DFSClient.LOG.isDebugEnabled()) {<a name="line.452"></a>
<span class="sourceLineNo">453</span>              DFSClient.LOG.debug("Append to block " + block);<a name="line.453"></a>
<span class="sourceLineNo">454</span>            }<a name="line.454"></a>
<span class="sourceLineNo">455</span>            setupPipelineForAppendOrRecovery();<a name="line.455"></a>
<span class="sourceLineNo">456</span>            initDataStreaming();<a name="line.456"></a>
<span class="sourceLineNo">457</span>          }<a name="line.457"></a>
<span class="sourceLineNo">458</span><a name="line.458"></a>
<span class="sourceLineNo">459</span>          long lastByteOffsetInBlock = one.getLastByteOffsetBlock();<a name="line.459"></a>
<span class="sourceLineNo">460</span>          if (lastByteOffsetInBlock &gt; blockSize) {<a name="line.460"></a>
<span class="sourceLineNo">461</span>            throw new IOException("BlockSize " + blockSize +<a name="line.461"></a>
<span class="sourceLineNo">462</span>                " is smaller than data size. " +<a name="line.462"></a>
<span class="sourceLineNo">463</span>                " Offset of packet in block " + <a name="line.463"></a>
<span class="sourceLineNo">464</span>                lastByteOffsetInBlock +<a name="line.464"></a>
<span class="sourceLineNo">465</span>                " Aborting file " + src);<a name="line.465"></a>
<span class="sourceLineNo">466</span>          }<a name="line.466"></a>
<span class="sourceLineNo">467</span><a name="line.467"></a>
<span class="sourceLineNo">468</span>          if (one.isLastPacketInBlock()) {<a name="line.468"></a>
<span class="sourceLineNo">469</span>            // wait for all data packets have been successfully acked<a name="line.469"></a>
<span class="sourceLineNo">470</span>            synchronized (dataQueue) {<a name="line.470"></a>
<span class="sourceLineNo">471</span>              while (!streamerClosed &amp;&amp; !hasError &amp;&amp; <a name="line.471"></a>
<span class="sourceLineNo">472</span>                  ackQueue.size() != 0 &amp;&amp; dfsClient.clientRunning) {<a name="line.472"></a>
<span class="sourceLineNo">473</span>                try {<a name="line.473"></a>
<span class="sourceLineNo">474</span>                  // wait for acks to arrive from datanodes<a name="line.474"></a>
<span class="sourceLineNo">475</span>                  dataQueue.wait(1000);<a name="line.475"></a>
<span class="sourceLineNo">476</span>                } catch (InterruptedException  e) {<a name="line.476"></a>
<span class="sourceLineNo">477</span>                  DFSClient.LOG.warn("Caught exception ", e);<a name="line.477"></a>
<span class="sourceLineNo">478</span>                }<a name="line.478"></a>
<span class="sourceLineNo">479</span>              }<a name="line.479"></a>
<span class="sourceLineNo">480</span>            }<a name="line.480"></a>
<span class="sourceLineNo">481</span>            if (streamerClosed || hasError || !dfsClient.clientRunning) {<a name="line.481"></a>
<span class="sourceLineNo">482</span>              continue;<a name="line.482"></a>
<span class="sourceLineNo">483</span>            }<a name="line.483"></a>
<span class="sourceLineNo">484</span>            stage = BlockConstructionStage.PIPELINE_CLOSE;<a name="line.484"></a>
<span class="sourceLineNo">485</span>          }<a name="line.485"></a>
<span class="sourceLineNo">486</span>          <a name="line.486"></a>
<span class="sourceLineNo">487</span>          // send the packet<a name="line.487"></a>
<span class="sourceLineNo">488</span>          Span span = null;<a name="line.488"></a>
<span class="sourceLineNo">489</span>          synchronized (dataQueue) {<a name="line.489"></a>
<span class="sourceLineNo">490</span>            // move packet from dataQueue to ackQueue<a name="line.490"></a>
<span class="sourceLineNo">491</span>            if (!one.isHeartbeatPacket()) {<a name="line.491"></a>
<span class="sourceLineNo">492</span>              span = scope.detach();<a name="line.492"></a>
<span class="sourceLineNo">493</span>              one.setTraceSpan(span);<a name="line.493"></a>
<span class="sourceLineNo">494</span>              dataQueue.removeFirst();<a name="line.494"></a>
<span class="sourceLineNo">495</span>              ackQueue.addLast(one);<a name="line.495"></a>
<span class="sourceLineNo">496</span>              dataQueue.notifyAll();<a name="line.496"></a>
<span class="sourceLineNo">497</span>            }<a name="line.497"></a>
<span class="sourceLineNo">498</span>          }<a name="line.498"></a>
<span class="sourceLineNo">499</span><a name="line.499"></a>
<span class="sourceLineNo">500</span>          if (DFSClient.LOG.isDebugEnabled()) {<a name="line.500"></a>
<span class="sourceLineNo">501</span>            DFSClient.LOG.debug("DataStreamer block " + block +<a name="line.501"></a>
<span class="sourceLineNo">502</span>                " sending packet " + one);<a name="line.502"></a>
<span class="sourceLineNo">503</span>          }<a name="line.503"></a>
<span class="sourceLineNo">504</span><a name="line.504"></a>
<span class="sourceLineNo">505</span>          // write out data to remote datanode<a name="line.505"></a>
<span class="sourceLineNo">506</span>          TraceScope writeScope = Trace.startSpan("writeTo", span);<a name="line.506"></a>
<span class="sourceLineNo">507</span>          try {<a name="line.507"></a>
<span class="sourceLineNo">508</span>            one.writeTo(blockStream);<a name="line.508"></a>
<span class="sourceLineNo">509</span>            blockStream.flush();   <a name="line.509"></a>
<span class="sourceLineNo">510</span>          } catch (IOException e) {<a name="line.510"></a>
<span class="sourceLineNo">511</span>            // HDFS-3398 treat primary DN is down since client is unable to <a name="line.511"></a>
<span class="sourceLineNo">512</span>            // write to primary DN. If a failed or restarting node has already<a name="line.512"></a>
<span class="sourceLineNo">513</span>            // been recorded by the responder, the following call will have no <a name="line.513"></a>
<span class="sourceLineNo">514</span>            // effect. Pipeline recovery can handle only one node error at a<a name="line.514"></a>
<span class="sourceLineNo">515</span>            // time. If the primary node fails again during the recovery, it<a name="line.515"></a>
<span class="sourceLineNo">516</span>            // will be taken out then.<a name="line.516"></a>
<span class="sourceLineNo">517</span>            tryMarkPrimaryDatanodeFailed();<a name="line.517"></a>
<span class="sourceLineNo">518</span>            throw e;<a name="line.518"></a>
<span class="sourceLineNo">519</span>          } finally {<a name="line.519"></a>
<span class="sourceLineNo">520</span>            writeScope.close();<a name="line.520"></a>
<span class="sourceLineNo">521</span>          }<a name="line.521"></a>
<span class="sourceLineNo">522</span>          lastPacket = Time.monotonicNow();<a name="line.522"></a>
<span class="sourceLineNo">523</span>          <a name="line.523"></a>
<span class="sourceLineNo">524</span>          // update bytesSent<a name="line.524"></a>
<span class="sourceLineNo">525</span>          long tmpBytesSent = one.getLastByteOffsetBlock();<a name="line.525"></a>
<span class="sourceLineNo">526</span>          if (bytesSent &lt; tmpBytesSent) {<a name="line.526"></a>
<span class="sourceLineNo">527</span>            bytesSent = tmpBytesSent;<a name="line.527"></a>
<span class="sourceLineNo">528</span>          }<a name="line.528"></a>
<span class="sourceLineNo">529</span><a name="line.529"></a>
<span class="sourceLineNo">530</span>          if (streamerClosed || hasError || !dfsClient.clientRunning) {<a name="line.530"></a>
<span class="sourceLineNo">531</span>            continue;<a name="line.531"></a>
<span class="sourceLineNo">532</span>          }<a name="line.532"></a>
<span class="sourceLineNo">533</span><a name="line.533"></a>
<span class="sourceLineNo">534</span>          // Is this block full?<a name="line.534"></a>
<span class="sourceLineNo">535</span>          if (one.isLastPacketInBlock()) {<a name="line.535"></a>
<span class="sourceLineNo">536</span>            // wait for the close packet has been acked<a name="line.536"></a>
<span class="sourceLineNo">537</span>            synchronized (dataQueue) {<a name="line.537"></a>
<span class="sourceLineNo">538</span>              while (!streamerClosed &amp;&amp; !hasError &amp;&amp; <a name="line.538"></a>
<span class="sourceLineNo">539</span>                  ackQueue.size() != 0 &amp;&amp; dfsClient.clientRunning) {<a name="line.539"></a>
<span class="sourceLineNo">540</span>                dataQueue.wait(1000);// wait for acks to arrive from datanodes<a name="line.540"></a>
<span class="sourceLineNo">541</span>              }<a name="line.541"></a>
<span class="sourceLineNo">542</span>            }<a name="line.542"></a>
<span class="sourceLineNo">543</span>            if (streamerClosed || hasError || !dfsClient.clientRunning) {<a name="line.543"></a>
<span class="sourceLineNo">544</span>              continue;<a name="line.544"></a>
<span class="sourceLineNo">545</span>            }<a name="line.545"></a>
<span class="sourceLineNo">546</span><a name="line.546"></a>
<span class="sourceLineNo">547</span>            endBlock();<a name="line.547"></a>
<span class="sourceLineNo">548</span>          }<a name="line.548"></a>
<span class="sourceLineNo">549</span>          if (progress != null) { progress.progress(); }<a name="line.549"></a>
<span class="sourceLineNo">550</span><a name="line.550"></a>
<span class="sourceLineNo">551</span>          // This is used by unit test to trigger race conditions.<a name="line.551"></a>
<span class="sourceLineNo">552</span>          if (artificialSlowdown != 0 &amp;&amp; dfsClient.clientRunning) {<a name="line.552"></a>
<span class="sourceLineNo">553</span>            Thread.sleep(artificialSlowdown); <a name="line.553"></a>
<span class="sourceLineNo">554</span>          }<a name="line.554"></a>
<span class="sourceLineNo">555</span>        } catch (Throwable e) {<a name="line.555"></a>
<span class="sourceLineNo">556</span>          // Log warning if there was a real error.<a name="line.556"></a>
<span class="sourceLineNo">557</span>          if (restartingNodeIndex.get() == -1) {<a name="line.557"></a>
<span class="sourceLineNo">558</span>            DFSClient.LOG.warn("DataStreamer Exception", e);<a name="line.558"></a>
<span class="sourceLineNo">559</span>          }<a name="line.559"></a>
<span class="sourceLineNo">560</span>          if (e instanceof IOException) {<a name="line.560"></a>
<span class="sourceLineNo">561</span>            setLastException((IOException)e);<a name="line.561"></a>
<span class="sourceLineNo">562</span>          } else {<a name="line.562"></a>
<span class="sourceLineNo">563</span>            setLastException(new IOException("DataStreamer Exception: ",e));<a name="line.563"></a>
<span class="sourceLineNo">564</span>          }<a name="line.564"></a>
<span class="sourceLineNo">565</span>          hasError = true;<a name="line.565"></a>
<span class="sourceLineNo">566</span>          if (errorIndex == -1 &amp;&amp; restartingNodeIndex.get() == -1) {<a name="line.566"></a>
<span class="sourceLineNo">567</span>            // Not a datanode issue<a name="line.567"></a>
<span class="sourceLineNo">568</span>            streamerClosed = true;<a name="line.568"></a>
<span class="sourceLineNo">569</span>          }<a name="line.569"></a>
<span class="sourceLineNo">570</span>        } finally {<a name="line.570"></a>
<span class="sourceLineNo">571</span>          scope.close();<a name="line.571"></a>
<span class="sourceLineNo">572</span>        }<a name="line.572"></a>
<span class="sourceLineNo">573</span>      }<a name="line.573"></a>
<span class="sourceLineNo">574</span>      closeInternal();<a name="line.574"></a>
<span class="sourceLineNo">575</span>    }<a name="line.575"></a>
<span class="sourceLineNo">576</span><a name="line.576"></a>
<span class="sourceLineNo">577</span>    private void closeInternal() {<a name="line.577"></a>
<span class="sourceLineNo">578</span>      closeResponder();       // close and join<a name="line.578"></a>
<span class="sourceLineNo">579</span>      closeStream();<a name="line.579"></a>
<span class="sourceLineNo">580</span>      streamerClosed = true;<a name="line.580"></a>
<span class="sourceLineNo">581</span>      setClosed();<a name="line.581"></a>
<span class="sourceLineNo">582</span>      synchronized (dataQueue) {<a name="line.582"></a>
<span class="sourceLineNo">583</span>        dataQueue.notifyAll();<a name="line.583"></a>
<span class="sourceLineNo">584</span>      }<a name="line.584"></a>
<span class="sourceLineNo">585</span>    }<a name="line.585"></a>
<span class="sourceLineNo">586</span><a name="line.586"></a>
<span class="sourceLineNo">587</span>    /*<a name="line.587"></a>
<span class="sourceLineNo">588</span>     * close both streamer and DFSOutputStream, should be called only <a name="line.588"></a>
<span class="sourceLineNo">589</span>     * by an external thread and only after all data to be sent has <a name="line.589"></a>
<span class="sourceLineNo">590</span>     * been flushed to datanode.<a name="line.590"></a>
<span class="sourceLineNo">591</span>     * <a name="line.591"></a>
<span class="sourceLineNo">592</span>     * Interrupt this data streamer if force is true<a name="line.592"></a>
<span class="sourceLineNo">593</span>     * <a name="line.593"></a>
<span class="sourceLineNo">594</span>     * @param force if this data stream is forced to be closed <a name="line.594"></a>
<span class="sourceLineNo">595</span>     */<a name="line.595"></a>
<span class="sourceLineNo">596</span>    void close(boolean force) {<a name="line.596"></a>
<span class="sourceLineNo">597</span>      streamerClosed = true;<a name="line.597"></a>
<span class="sourceLineNo">598</span>      synchronized (dataQueue) {<a name="line.598"></a>
<span class="sourceLineNo">599</span>        dataQueue.notifyAll();<a name="line.599"></a>
<span class="sourceLineNo">600</span>      }<a name="line.600"></a>
<span class="sourceLineNo">601</span>      if (force) {<a name="line.601"></a>
<span class="sourceLineNo">602</span>        this.interrupt();<a name="line.602"></a>
<span class="sourceLineNo">603</span>      }<a name="line.603"></a>
<span class="sourceLineNo">604</span>    }<a name="line.604"></a>
<span class="sourceLineNo">605</span><a name="line.605"></a>
<span class="sourceLineNo">606</span>    private void closeResponder() {<a name="line.606"></a>
<span class="sourceLineNo">607</span>      if (response != null) {<a name="line.607"></a>
<span class="sourceLineNo">608</span>        try {<a name="line.608"></a>
<span class="sourceLineNo">609</span>          response.close();<a name="line.609"></a>
<span class="sourceLineNo">610</span>          response.join();<a name="line.610"></a>
<span class="sourceLineNo">611</span>        } catch (InterruptedException  e) {<a name="line.611"></a>
<span class="sourceLineNo">612</span>          DFSClient.LOG.warn("Caught exception ", e);<a name="line.612"></a>
<span class="sourceLineNo">613</span>        } finally {<a name="line.613"></a>
<span class="sourceLineNo">614</span>          response = null;<a name="line.614"></a>
<span class="sourceLineNo">615</span>        }<a name="line.615"></a>
<span class="sourceLineNo">616</span>      }<a name="line.616"></a>
<span class="sourceLineNo">617</span>    }<a name="line.617"></a>
<span class="sourceLineNo">618</span><a name="line.618"></a>
<span class="sourceLineNo">619</span>    private void closeStream() {<a name="line.619"></a>
<span class="sourceLineNo">620</span>      if (blockStream != null) {<a name="line.620"></a>
<span class="sourceLineNo">621</span>        try {<a name="line.621"></a>
<span class="sourceLineNo">622</span>          blockStream.close();<a name="line.622"></a>
<span class="sourceLineNo">623</span>        } catch (IOException e) {<a name="line.623"></a>
<span class="sourceLineNo">624</span>          setLastException(e);<a name="line.624"></a>
<span class="sourceLineNo">625</span>        } finally {<a name="line.625"></a>
<span class="sourceLineNo">626</span>          blockStream = null;<a name="line.626"></a>
<span class="sourceLineNo">627</span>        }<a name="line.627"></a>
<span class="sourceLineNo">628</span>      }<a name="line.628"></a>
<span class="sourceLineNo">629</span>      if (blockReplyStream != null) {<a name="line.629"></a>
<span class="sourceLineNo">630</span>        try {<a name="line.630"></a>
<span class="sourceLineNo">631</span>          blockReplyStream.close();<a name="line.631"></a>
<span class="sourceLineNo">632</span>        } catch (IOException e) {<a name="line.632"></a>
<span class="sourceLineNo">633</span>          setLastException(e);<a name="line.633"></a>
<span class="sourceLineNo">634</span>        } finally {<a name="line.634"></a>
<span class="sourceLineNo">635</span>          blockReplyStream = null;<a name="line.635"></a>
<span class="sourceLineNo">636</span>        }<a name="line.636"></a>
<span class="sourceLineNo">637</span>      }<a name="line.637"></a>
<span class="sourceLineNo">638</span>      if (null != s) {<a name="line.638"></a>
<span class="sourceLineNo">639</span>        try {<a name="line.639"></a>
<span class="sourceLineNo">640</span>          s.close();<a name="line.640"></a>
<span class="sourceLineNo">641</span>        } catch (IOException e) {<a name="line.641"></a>
<span class="sourceLineNo">642</span>          setLastException(e);<a name="line.642"></a>
<span class="sourceLineNo">643</span>        } finally {<a name="line.643"></a>
<span class="sourceLineNo">644</span>          s = null;<a name="line.644"></a>
<span class="sourceLineNo">645</span>        }<a name="line.645"></a>
<span class="sourceLineNo">646</span>      }<a name="line.646"></a>
<span class="sourceLineNo">647</span>    }<a name="line.647"></a>
<span class="sourceLineNo">648</span><a name="line.648"></a>
<span class="sourceLineNo">649</span>    // The following synchronized methods are used whenever <a name="line.649"></a>
<span class="sourceLineNo">650</span>    // errorIndex or restartingNodeIndex is set. This is because<a name="line.650"></a>
<span class="sourceLineNo">651</span>    // check &amp; set needs to be atomic. Simply reading variables<a name="line.651"></a>
<span class="sourceLineNo">652</span>    // does not require a synchronization. When responder is<a name="line.652"></a>
<span class="sourceLineNo">653</span>    // not running (e.g. during pipeline recovery), there is no<a name="line.653"></a>
<span class="sourceLineNo">654</span>    // need to use these methods.<a name="line.654"></a>
<span class="sourceLineNo">655</span><a name="line.655"></a>
<span class="sourceLineNo">656</span>    /** Set the error node index. Called by responder */<a name="line.656"></a>
<span class="sourceLineNo">657</span>    synchronized void setErrorIndex(int idx) {<a name="line.657"></a>
<span class="sourceLineNo">658</span>      errorIndex = idx;<a name="line.658"></a>
<span class="sourceLineNo">659</span>    }<a name="line.659"></a>
<span class="sourceLineNo">660</span><a name="line.660"></a>
<span class="sourceLineNo">661</span>    /** Set the restarting node index. Called by responder */<a name="line.661"></a>
<span class="sourceLineNo">662</span>    synchronized void setRestartingNodeIndex(int idx) {<a name="line.662"></a>
<span class="sourceLineNo">663</span>      restartingNodeIndex.set(idx);<a name="line.663"></a>
<span class="sourceLineNo">664</span>      // If the data streamer has already set the primary node<a name="line.664"></a>
<span class="sourceLineNo">665</span>      // bad, clear it. It is likely that the write failed due to<a name="line.665"></a>
<span class="sourceLineNo">666</span>      // the DN shutdown. Even if it was a real failure, the pipeline<a name="line.666"></a>
<span class="sourceLineNo">667</span>      // recovery will take care of it.<a name="line.667"></a>
<span class="sourceLineNo">668</span>      errorIndex = -1;      <a name="line.668"></a>
<span class="sourceLineNo">669</span>    }<a name="line.669"></a>
<span class="sourceLineNo">670</span><a name="line.670"></a>
<span class="sourceLineNo">671</span>    /**<a name="line.671"></a>
<span class="sourceLineNo">672</span>     * This method is used when no explicit error report was received,<a name="line.672"></a>
<span class="sourceLineNo">673</span>     * but something failed. When the primary node is a suspect or<a name="line.673"></a>
<span class="sourceLineNo">674</span>     * unsure about the cause, the primary node is marked as failed.<a name="line.674"></a>
<span class="sourceLineNo">675</span>     */<a name="line.675"></a>
<span class="sourceLineNo">676</span>    synchronized void tryMarkPrimaryDatanodeFailed() {<a name="line.676"></a>
<span class="sourceLineNo">677</span>      // There should be no existing error and no ongoing restart.<a name="line.677"></a>
<span class="sourceLineNo">678</span>      if ((errorIndex == -1) &amp;&amp; (restartingNodeIndex.get() == -1)) {<a name="line.678"></a>
<span class="sourceLineNo">679</span>        errorIndex = 0;<a name="line.679"></a>
<span class="sourceLineNo">680</span>      }<a name="line.680"></a>
<span class="sourceLineNo">681</span>    }<a name="line.681"></a>
<span class="sourceLineNo">682</span><a name="line.682"></a>
<span class="sourceLineNo">683</span>    /**<a name="line.683"></a>
<span class="sourceLineNo">684</span>     * Examine whether it is worth waiting for a node to restart.<a name="line.684"></a>
<span class="sourceLineNo">685</span>     * @param index the node index<a name="line.685"></a>
<span class="sourceLineNo">686</span>     */<a name="line.686"></a>
<span class="sourceLineNo">687</span>    boolean shouldWaitForRestart(int index) {<a name="line.687"></a>
<span class="sourceLineNo">688</span>      // Only one node in the pipeline.<a name="line.688"></a>
<span class="sourceLineNo">689</span>      if (nodes.length == 1) {<a name="line.689"></a>
<span class="sourceLineNo">690</span>        return true;<a name="line.690"></a>
<span class="sourceLineNo">691</span>      }<a name="line.691"></a>
<span class="sourceLineNo">692</span><a name="line.692"></a>
<span class="sourceLineNo">693</span>      // Is it a local node?<a name="line.693"></a>
<span class="sourceLineNo">694</span>      InetAddress addr = null;<a name="line.694"></a>
<span class="sourceLineNo">695</span>      try {<a name="line.695"></a>
<span class="sourceLineNo">696</span>        addr = InetAddress.getByName(nodes[index].getIpAddr());<a name="line.696"></a>
<span class="sourceLineNo">697</span>      } catch (java.net.UnknownHostException e) {<a name="line.697"></a>
<span class="sourceLineNo">698</span>        // we are passing an ip address. this should not happen.<a name="line.698"></a>
<span class="sourceLineNo">699</span>        assert false;<a name="line.699"></a>
<span class="sourceLineNo">700</span>      }<a name="line.700"></a>
<span class="sourceLineNo">701</span><a name="line.701"></a>
<span class="sourceLineNo">702</span>      if (addr != null &amp;&amp; NetUtils.isLocalAddress(addr)) {<a name="line.702"></a>
<span class="sourceLineNo">703</span>        return true;<a name="line.703"></a>
<span class="sourceLineNo">704</span>      }<a name="line.704"></a>
<span class="sourceLineNo">705</span>      return false;<a name="line.705"></a>
<span class="sourceLineNo">706</span>    }<a name="line.706"></a>
<span class="sourceLineNo">707</span><a name="line.707"></a>
<span class="sourceLineNo">708</span>    //<a name="line.708"></a>
<span class="sourceLineNo">709</span>    // Processes responses from the datanodes.  A packet is removed<a name="line.709"></a>
<span class="sourceLineNo">710</span>    // from the ackQueue when its response arrives.<a name="line.710"></a>
<span class="sourceLineNo">711</span>    //<a name="line.711"></a>
<span class="sourceLineNo">712</span>    private class ResponseProcessor extends Daemon {<a name="line.712"></a>
<span class="sourceLineNo">713</span><a name="line.713"></a>
<span class="sourceLineNo">714</span>      private volatile boolean responderClosed = false;<a name="line.714"></a>
<span class="sourceLineNo">715</span>      private DatanodeInfo[] targets = null;<a name="line.715"></a>
<span class="sourceLineNo">716</span>      private boolean isLastPacketInBlock = false;<a name="line.716"></a>
<span class="sourceLineNo">717</span><a name="line.717"></a>
<span class="sourceLineNo">718</span>      ResponseProcessor (DatanodeInfo[] targets) {<a name="line.718"></a>
<span class="sourceLineNo">719</span>        this.targets = targets;<a name="line.719"></a>
<span class="sourceLineNo">720</span>      }<a name="line.720"></a>
<span class="sourceLineNo">721</span><a name="line.721"></a>
<span class="sourceLineNo">722</span>      @Override<a name="line.722"></a>
<span class="sourceLineNo">723</span>      public void run() {<a name="line.723"></a>
<span class="sourceLineNo">724</span><a name="line.724"></a>
<span class="sourceLineNo">725</span>        setName("ResponseProcessor for block " + block);<a name="line.725"></a>
<span class="sourceLineNo">726</span>        PipelineAck ack = new PipelineAck();<a name="line.726"></a>
<span class="sourceLineNo">727</span><a name="line.727"></a>
<span class="sourceLineNo">728</span>        TraceScope scope = NullScope.INSTANCE;<a name="line.728"></a>
<span class="sourceLineNo">729</span>        while (!responderClosed &amp;&amp; dfsClient.clientRunning &amp;&amp; !isLastPacketInBlock) {<a name="line.729"></a>
<span class="sourceLineNo">730</span>          // process responses from datanodes.<a name="line.730"></a>
<span class="sourceLineNo">731</span>          try {<a name="line.731"></a>
<span class="sourceLineNo">732</span>            // read an ack from the pipeline<a name="line.732"></a>
<span class="sourceLineNo">733</span>            long begin = Time.monotonicNow();<a name="line.733"></a>
<span class="sourceLineNo">734</span>            ack.readFields(blockReplyStream);<a name="line.734"></a>
<span class="sourceLineNo">735</span>            long duration = Time.monotonicNow() - begin;<a name="line.735"></a>
<span class="sourceLineNo">736</span>            if (duration &gt; dfsclientSlowLogThresholdMs<a name="line.736"></a>
<span class="sourceLineNo">737</span>                &amp;&amp; ack.getSeqno() != DFSPacket.HEART_BEAT_SEQNO) {<a name="line.737"></a>
<span class="sourceLineNo">738</span>              DFSClient.LOG<a name="line.738"></a>
<span class="sourceLineNo">739</span>                  .warn("Slow ReadProcessor read fields took " + duration<a name="line.739"></a>
<span class="sourceLineNo">740</span>                      + "ms (threshold=" + dfsclientSlowLogThresholdMs + "ms); ack: "<a name="line.740"></a>
<span class="sourceLineNo">741</span>                      + ack + ", targets: " + Arrays.asList(targets));<a name="line.741"></a>
<span class="sourceLineNo">742</span>            } else if (DFSClient.LOG.isDebugEnabled()) {<a name="line.742"></a>
<span class="sourceLineNo">743</span>              DFSClient.LOG.debug("DFSClient " + ack);<a name="line.743"></a>
<span class="sourceLineNo">744</span>            }<a name="line.744"></a>
<span class="sourceLineNo">745</span><a name="line.745"></a>
<span class="sourceLineNo">746</span>            long seqno = ack.getSeqno();<a name="line.746"></a>
<span class="sourceLineNo">747</span>            // processes response status from datanodes.<a name="line.747"></a>
<span class="sourceLineNo">748</span>            for (int i = ack.getNumOfReplies()-1; i &gt;=0  &amp;&amp; dfsClient.clientRunning; i--) {<a name="line.748"></a>
<span class="sourceLineNo">749</span>              final Status reply = PipelineAck.getStatusFromHeader(ack<a name="line.749"></a>
<span class="sourceLineNo">750</span>                .getHeaderFlag(i));<a name="line.750"></a>
<span class="sourceLineNo">751</span>              // Restart will not be treated differently unless it is<a name="line.751"></a>
<span class="sourceLineNo">752</span>              // the local node or the only one in the pipeline.<a name="line.752"></a>
<span class="sourceLineNo">753</span>              if (PipelineAck.isRestartOOBStatus(reply) &amp;&amp;<a name="line.753"></a>
<span class="sourceLineNo">754</span>                  shouldWaitForRestart(i)) {<a name="line.754"></a>
<span class="sourceLineNo">755</span>                restartDeadline = dfsClient.getConf().datanodeRestartTimeout<a name="line.755"></a>
<span class="sourceLineNo">756</span>                    + Time.monotonicNow();<a name="line.756"></a>
<span class="sourceLineNo">757</span>                setRestartingNodeIndex(i);<a name="line.757"></a>
<span class="sourceLineNo">758</span>                String message = "A datanode is restarting: " + targets[i];<a name="line.758"></a>
<span class="sourceLineNo">759</span>                DFSClient.LOG.info(message);<a name="line.759"></a>
<span class="sourceLineNo">760</span>               throw new IOException(message);<a name="line.760"></a>
<span class="sourceLineNo">761</span>              }<a name="line.761"></a>
<span class="sourceLineNo">762</span>              // node error<a name="line.762"></a>
<span class="sourceLineNo">763</span>              if (reply != SUCCESS) {<a name="line.763"></a>
<span class="sourceLineNo">764</span>                setErrorIndex(i); // first bad datanode<a name="line.764"></a>
<span class="sourceLineNo">765</span>                throw new IOException("Bad response " + reply +<a name="line.765"></a>
<span class="sourceLineNo">766</span>                    " for block " + block +<a name="line.766"></a>
<span class="sourceLineNo">767</span>                    " from datanode " + <a name="line.767"></a>
<span class="sourceLineNo">768</span>                    targets[i]);<a name="line.768"></a>
<span class="sourceLineNo">769</span>              }<a name="line.769"></a>
<span class="sourceLineNo">770</span>            }<a name="line.770"></a>
<span class="sourceLineNo">771</span>            <a name="line.771"></a>
<span class="sourceLineNo">772</span>            assert seqno != PipelineAck.UNKOWN_SEQNO : <a name="line.772"></a>
<span class="sourceLineNo">773</span>              "Ack for unknown seqno should be a failed ack: " + ack;<a name="line.773"></a>
<span class="sourceLineNo">774</span>            if (seqno == DFSPacket.HEART_BEAT_SEQNO) {  // a heartbeat ack<a name="line.774"></a>
<span class="sourceLineNo">775</span>              continue;<a name="line.775"></a>
<span class="sourceLineNo">776</span>            }<a name="line.776"></a>
<span class="sourceLineNo">777</span><a name="line.777"></a>
<span class="sourceLineNo">778</span>            // a success ack for a data packet<a name="line.778"></a>
<span class="sourceLineNo">779</span>            DFSPacket one;<a name="line.779"></a>
<span class="sourceLineNo">780</span>            synchronized (dataQueue) {<a name="line.780"></a>
<span class="sourceLineNo">781</span>              one = ackQueue.getFirst();<a name="line.781"></a>
<span class="sourceLineNo">782</span>            }<a name="line.782"></a>
<span class="sourceLineNo">783</span>            if (one.getSeqno() != seqno) {<a name="line.783"></a>
<span class="sourceLineNo">784</span>              throw new IOException("ResponseProcessor: Expecting seqno " +<a name="line.784"></a>
<span class="sourceLineNo">785</span>                                    " for block " + block +<a name="line.785"></a>
<span class="sourceLineNo">786</span>                                    one.getSeqno() + " but received " + seqno);<a name="line.786"></a>
<span class="sourceLineNo">787</span>            }<a name="line.787"></a>
<span class="sourceLineNo">788</span>            isLastPacketInBlock = one.isLastPacketInBlock();<a name="line.788"></a>
<span class="sourceLineNo">789</span><a name="line.789"></a>
<span class="sourceLineNo">790</span>            // Fail the packet write for testing in order to force a<a name="line.790"></a>
<span class="sourceLineNo">791</span>            // pipeline recovery.<a name="line.791"></a>
<span class="sourceLineNo">792</span>            if (DFSClientFaultInjector.get().failPacket() &amp;&amp;<a name="line.792"></a>
<span class="sourceLineNo">793</span>                isLastPacketInBlock) {<a name="line.793"></a>
<span class="sourceLineNo">794</span>              failPacket = true;<a name="line.794"></a>
<span class="sourceLineNo">795</span>              throw new IOException(<a name="line.795"></a>
<span class="sourceLineNo">796</span>                    "Failing the last packet for testing.");<a name="line.796"></a>
<span class="sourceLineNo">797</span>            }<a name="line.797"></a>
<span class="sourceLineNo">798</span>              <a name="line.798"></a>
<span class="sourceLineNo">799</span>            // update bytesAcked<a name="line.799"></a>
<span class="sourceLineNo">800</span>            block.setNumBytes(one.getLastByteOffsetBlock());<a name="line.800"></a>
<span class="sourceLineNo">801</span><a name="line.801"></a>
<span class="sourceLineNo">802</span>            synchronized (dataQueue) {<a name="line.802"></a>
<span class="sourceLineNo">803</span>              scope = Trace.continueSpan(one.getTraceSpan());<a name="line.803"></a>
<span class="sourceLineNo">804</span>              one.setTraceSpan(null);<a name="line.804"></a>
<span class="sourceLineNo">805</span>              lastAckedSeqno = seqno;<a name="line.805"></a>
<span class="sourceLineNo">806</span>              ackQueue.removeFirst();<a name="line.806"></a>
<span class="sourceLineNo">807</span>              dataQueue.notifyAll();<a name="line.807"></a>
<span class="sourceLineNo">808</span><a name="line.808"></a>
<span class="sourceLineNo">809</span>              one.releaseBuffer(byteArrayManager);<a name="line.809"></a>
<span class="sourceLineNo">810</span>            }<a name="line.810"></a>
<span class="sourceLineNo">811</span>          } catch (Exception e) {<a name="line.811"></a>
<span class="sourceLineNo">812</span>            if (!responderClosed) {<a name="line.812"></a>
<span class="sourceLineNo">813</span>              if (e instanceof IOException) {<a name="line.813"></a>
<span class="sourceLineNo">814</span>                setLastException((IOException)e);<a name="line.814"></a>
<span class="sourceLineNo">815</span>              }<a name="line.815"></a>
<span class="sourceLineNo">816</span>              hasError = true;<a name="line.816"></a>
<span class="sourceLineNo">817</span>              // If no explicit error report was received, mark the primary<a name="line.817"></a>
<span class="sourceLineNo">818</span>              // node as failed.<a name="line.818"></a>
<span class="sourceLineNo">819</span>              tryMarkPrimaryDatanodeFailed();<a name="line.819"></a>
<span class="sourceLineNo">820</span>              synchronized (dataQueue) {<a name="line.820"></a>
<span class="sourceLineNo">821</span>                dataQueue.notifyAll();<a name="line.821"></a>
<span class="sourceLineNo">822</span>              }<a name="line.822"></a>
<span class="sourceLineNo">823</span>              if (restartingNodeIndex.get() == -1) {<a name="line.823"></a>
<span class="sourceLineNo">824</span>                DFSClient.LOG.warn("DFSOutputStream ResponseProcessor exception "<a name="line.824"></a>
<span class="sourceLineNo">825</span>                     + " for block " + block, e);<a name="line.825"></a>
<span class="sourceLineNo">826</span>              }<a name="line.826"></a>
<span class="sourceLineNo">827</span>              responderClosed = true;<a name="line.827"></a>
<span class="sourceLineNo">828</span>            }<a name="line.828"></a>
<span class="sourceLineNo">829</span>          } finally {<a name="line.829"></a>
<span class="sourceLineNo">830</span>            scope.close();<a name="line.830"></a>
<span class="sourceLineNo">831</span>          }<a name="line.831"></a>
<span class="sourceLineNo">832</span>        }<a name="line.832"></a>
<span class="sourceLineNo">833</span>      }<a name="line.833"></a>
<span class="sourceLineNo">834</span><a name="line.834"></a>
<span class="sourceLineNo">835</span>      void close() {<a name="line.835"></a>
<span class="sourceLineNo">836</span>        responderClosed = true;<a name="line.836"></a>
<span class="sourceLineNo">837</span>        this.interrupt();<a name="line.837"></a>
<span class="sourceLineNo">838</span>      }<a name="line.838"></a>
<span class="sourceLineNo">839</span>    }<a name="line.839"></a>
<span class="sourceLineNo">840</span><a name="line.840"></a>
<span class="sourceLineNo">841</span>    // If this stream has encountered any errors so far, shutdown <a name="line.841"></a>
<span class="sourceLineNo">842</span>    // threads and mark stream as closed. Returns true if we should<a name="line.842"></a>
<span class="sourceLineNo">843</span>    // sleep for a while after returning from this call.<a name="line.843"></a>
<span class="sourceLineNo">844</span>    //<a name="line.844"></a>
<span class="sourceLineNo">845</span>    private boolean processDatanodeError() throws IOException {<a name="line.845"></a>
<span class="sourceLineNo">846</span>      if (response != null) {<a name="line.846"></a>
<span class="sourceLineNo">847</span>        DFSClient.LOG.info("Error Recovery for " + block +<a name="line.847"></a>
<span class="sourceLineNo">848</span>        " waiting for responder to exit. ");<a name="line.848"></a>
<span class="sourceLineNo">849</span>        return true;<a name="line.849"></a>
<span class="sourceLineNo">850</span>      }<a name="line.850"></a>
<span class="sourceLineNo">851</span>      closeStream();<a name="line.851"></a>
<span class="sourceLineNo">852</span><a name="line.852"></a>
<span class="sourceLineNo">853</span>      // move packets from ack queue to front of the data queue<a name="line.853"></a>
<span class="sourceLineNo">854</span>      synchronized (dataQueue) {<a name="line.854"></a>
<span class="sourceLineNo">855</span>        dataQueue.addAll(0, ackQueue);<a name="line.855"></a>
<span class="sourceLineNo">856</span>        ackQueue.clear();<a name="line.856"></a>
<span class="sourceLineNo">857</span>      }<a name="line.857"></a>
<span class="sourceLineNo">858</span><a name="line.858"></a>
<span class="sourceLineNo">859</span>      // Record the new pipeline failure recovery.<a name="line.859"></a>
<span class="sourceLineNo">860</span>      if (lastAckedSeqnoBeforeFailure != lastAckedSeqno) {<a name="line.860"></a>
<span class="sourceLineNo">861</span>         lastAckedSeqnoBeforeFailure = lastAckedSeqno;<a name="line.861"></a>
<span class="sourceLineNo">862</span>         pipelineRecoveryCount = 1;<a name="line.862"></a>
<span class="sourceLineNo">863</span>      } else {<a name="line.863"></a>
<span class="sourceLineNo">864</span>        // If we had to recover the pipeline five times in a row for the<a name="line.864"></a>
<span class="sourceLineNo">865</span>        // same packet, this client likely has corrupt data or corrupting<a name="line.865"></a>
<span class="sourceLineNo">866</span>        // during transmission.<a name="line.866"></a>
<span class="sourceLineNo">867</span>        if (++pipelineRecoveryCount &gt; 5) {<a name="line.867"></a>
<span class="sourceLineNo">868</span>          DFSClient.LOG.warn("Error recovering pipeline for writing " +<a name="line.868"></a>
<span class="sourceLineNo">869</span>              block + ". Already retried 5 times for the same packet.");<a name="line.869"></a>
<span class="sourceLineNo">870</span>          lastException.set(new IOException("Failing write. Tried pipeline " +<a name="line.870"></a>
<span class="sourceLineNo">871</span>              "recovery 5 times without success."));<a name="line.871"></a>
<span class="sourceLineNo">872</span>          streamerClosed = true;<a name="line.872"></a>
<span class="sourceLineNo">873</span>          return false;<a name="line.873"></a>
<span class="sourceLineNo">874</span>        }<a name="line.874"></a>
<span class="sourceLineNo">875</span>      }<a name="line.875"></a>
<span class="sourceLineNo">876</span>      boolean doSleep = setupPipelineForAppendOrRecovery();<a name="line.876"></a>
<span class="sourceLineNo">877</span>      <a name="line.877"></a>
<span class="sourceLineNo">878</span>      if (!streamerClosed &amp;&amp; dfsClient.clientRunning) {<a name="line.878"></a>
<span class="sourceLineNo">879</span>        if (stage == BlockConstructionStage.PIPELINE_CLOSE) {<a name="line.879"></a>
<span class="sourceLineNo">880</span><a name="line.880"></a>
<span class="sourceLineNo">881</span>          // If we had an error while closing the pipeline, we go through a fast-path<a name="line.881"></a>
<span class="sourceLineNo">882</span>          // where the BlockReceiver does not run. Instead, the DataNode just finalizes<a name="line.882"></a>
<span class="sourceLineNo">883</span>          // the block immediately during the 'connect ack' process. So, we want to pull<a name="line.883"></a>
<span class="sourceLineNo">884</span>          // the end-of-block packet from the dataQueue, since we don't actually have<a name="line.884"></a>
<span class="sourceLineNo">885</span>          // a true pipeline to send it over.<a name="line.885"></a>
<span class="sourceLineNo">886</span>          //<a name="line.886"></a>
<span class="sourceLineNo">887</span>          // We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that<a name="line.887"></a>
<span class="sourceLineNo">888</span>          // a client waiting on close() will be aware that the flush finished.<a name="line.888"></a>
<span class="sourceLineNo">889</span>          synchronized (dataQueue) {<a name="line.889"></a>
<span class="sourceLineNo">890</span>            DFSPacket endOfBlockPacket = dataQueue.remove();  // remove the end of block packet<a name="line.890"></a>
<span class="sourceLineNo">891</span>            Span span = endOfBlockPacket.getTraceSpan();<a name="line.891"></a>
<span class="sourceLineNo">892</span>            if (span != null) {<a name="line.892"></a>
<span class="sourceLineNo">893</span>              // Close any trace span associated with this Packet<a name="line.893"></a>
<span class="sourceLineNo">894</span>              TraceScope scope = Trace.continueSpan(span);<a name="line.894"></a>
<span class="sourceLineNo">895</span>              scope.close();<a name="line.895"></a>
<span class="sourceLineNo">896</span>            }<a name="line.896"></a>
<span class="sourceLineNo">897</span>            assert endOfBlockPacket.isLastPacketInBlock();<a name="line.897"></a>
<span class="sourceLineNo">898</span>            assert lastAckedSeqno == endOfBlockPacket.getSeqno() - 1;<a name="line.898"></a>
<span class="sourceLineNo">899</span>            lastAckedSeqno = endOfBlockPacket.getSeqno();<a name="line.899"></a>
<span class="sourceLineNo">900</span>            dataQueue.notifyAll();<a name="line.900"></a>
<span class="sourceLineNo">901</span>          }<a name="line.901"></a>
<span class="sourceLineNo">902</span>          endBlock();<a name="line.902"></a>
<span class="sourceLineNo">903</span>        } else {<a name="line.903"></a>
<span class="sourceLineNo">904</span>          initDataStreaming();<a name="line.904"></a>
<span class="sourceLineNo">905</span>        }<a name="line.905"></a>
<span class="sourceLineNo">906</span>      }<a name="line.906"></a>
<span class="sourceLineNo">907</span>      <a name="line.907"></a>
<span class="sourceLineNo">908</span>      return doSleep;<a name="line.908"></a>
<span class="sourceLineNo">909</span>    }<a name="line.909"></a>
<span class="sourceLineNo">910</span><a name="line.910"></a>
<span class="sourceLineNo">911</span>    private void setHflush() {<a name="line.911"></a>
<span class="sourceLineNo">912</span>      isHflushed = true;<a name="line.912"></a>
<span class="sourceLineNo">913</span>    }<a name="line.913"></a>
<span class="sourceLineNo">914</span><a name="line.914"></a>
<span class="sourceLineNo">915</span>    private int findNewDatanode(final DatanodeInfo[] original<a name="line.915"></a>
<span class="sourceLineNo">916</span>        ) throws IOException {<a name="line.916"></a>
<span class="sourceLineNo">917</span>      if (nodes.length != original.length + 1) {<a name="line.917"></a>
<span class="sourceLineNo">918</span>        throw new IOException(<a name="line.918"></a>
<span class="sourceLineNo">919</span>            new StringBuilder()<a name="line.919"></a>
<span class="sourceLineNo">920</span>            .append("Failed to replace a bad datanode on the existing pipeline ")<a name="line.920"></a>
<span class="sourceLineNo">921</span>            .append("due to no more good datanodes being available to try. ")<a name="line.921"></a>
<span class="sourceLineNo">922</span>            .append("(Nodes: current=").append(Arrays.asList(nodes))<a name="line.922"></a>
<span class="sourceLineNo">923</span>            .append(", original=").append(Arrays.asList(original)).append("). ")<a name="line.923"></a>
<span class="sourceLineNo">924</span>            .append("The current failed datanode replacement policy is ")<a name="line.924"></a>
<span class="sourceLineNo">925</span>            .append(dfsClient.dtpReplaceDatanodeOnFailure).append(", and ")<a name="line.925"></a>
<span class="sourceLineNo">926</span>            .append("a client may configure this via '")<a name="line.926"></a>
<span class="sourceLineNo">927</span>            .append(DFSConfigKeys.DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_POLICY_KEY)<a name="line.927"></a>
<span class="sourceLineNo">928</span>            .append("' in its configuration.")<a name="line.928"></a>
<span class="sourceLineNo">929</span>            .toString());<a name="line.929"></a>
<span class="sourceLineNo">930</span>      }<a name="line.930"></a>
<span class="sourceLineNo">931</span>      for(int i = 0; i &lt; nodes.length; i++) {<a name="line.931"></a>
<span class="sourceLineNo">932</span>        int j = 0;<a name="line.932"></a>
<span class="sourceLineNo">933</span>        for(; j &lt; original.length &amp;&amp; !nodes[i].equals(original[j]); j++);<a name="line.933"></a>
<span class="sourceLineNo">934</span>        if (j == original.length) {<a name="line.934"></a>
<span class="sourceLineNo">935</span>          return i;<a name="line.935"></a>
<span class="sourceLineNo">936</span>        }<a name="line.936"></a>
<span class="sourceLineNo">937</span>      }<a name="line.937"></a>
<span class="sourceLineNo">938</span>      throw new IOException("Failed: new datanode not found: nodes="<a name="line.938"></a>
<span class="sourceLineNo">939</span>          + Arrays.asList(nodes) + ", original=" + Arrays.asList(original));<a name="line.939"></a>
<span class="sourceLineNo">940</span>    }<a name="line.940"></a>
<span class="sourceLineNo">941</span><a name="line.941"></a>
<span class="sourceLineNo">942</span>    private void addDatanode2ExistingPipeline() throws IOException {<a name="line.942"></a>
<span class="sourceLineNo">943</span>      if (DataTransferProtocol.LOG.isDebugEnabled()) {<a name="line.943"></a>
<span class="sourceLineNo">944</span>        DataTransferProtocol.LOG.debug("lastAckedSeqno = " + lastAckedSeqno);<a name="line.944"></a>
<span class="sourceLineNo">945</span>      }<a name="line.945"></a>
<span class="sourceLineNo">946</span>      /*<a name="line.946"></a>
<span class="sourceLineNo">947</span>       * Is data transfer necessary?  We have the following cases.<a name="line.947"></a>
<span class="sourceLineNo">948</span>       * <a name="line.948"></a>
<span class="sourceLineNo">949</span>       * Case 1: Failure in Pipeline Setup<a name="line.949"></a>
<span class="sourceLineNo">950</span>       * - Append<a name="line.950"></a>
<span class="sourceLineNo">951</span>       *    + Transfer the stored replica, which may be a RBW or a finalized.<a name="line.951"></a>
<span class="sourceLineNo">952</span>       * - Create<a name="line.952"></a>
<span class="sourceLineNo">953</span>       *    + If no data, then no transfer is required.<a name="line.953"></a>
<span class="sourceLineNo">954</span>       *    + If there are data written, transfer RBW. This case may happens <a name="line.954"></a>
<span class="sourceLineNo">955</span>       *      when there are streaming failure earlier in this pipeline.<a name="line.955"></a>
<span class="sourceLineNo">956</span>       *<a name="line.956"></a>
<span class="sourceLineNo">957</span>       * Case 2: Failure in Streaming<a name="line.957"></a>
<span class="sourceLineNo">958</span>       * - Append/Create:<a name="line.958"></a>
<span class="sourceLineNo">959</span>       *    + transfer RBW<a name="line.959"></a>
<span class="sourceLineNo">960</span>       * <a name="line.960"></a>
<span class="sourceLineNo">961</span>       * Case 3: Failure in Close<a name="line.961"></a>
<span class="sourceLineNo">962</span>       * - Append/Create:<a name="line.962"></a>
<span class="sourceLineNo">963</span>       *    + no transfer, let NameNode replicates the block.<a name="line.963"></a>
<span class="sourceLineNo">964</span>       */<a name="line.964"></a>
<span class="sourceLineNo">965</span>      if (!isAppend &amp;&amp; lastAckedSeqno &lt; 0<a name="line.965"></a>
<span class="sourceLineNo">966</span>          &amp;&amp; stage == BlockConstructionStage.PIPELINE_SETUP_CREATE) {<a name="line.966"></a>
<span class="sourceLineNo">967</span>        //no data have been written<a name="line.967"></a>
<span class="sourceLineNo">968</span>        return;<a name="line.968"></a>
<span class="sourceLineNo">969</span>      } else if (stage == BlockConstructionStage.PIPELINE_CLOSE<a name="line.969"></a>
<span class="sourceLineNo">970</span>          || stage == BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {<a name="line.970"></a>
<span class="sourceLineNo">971</span>        //pipeline is closing<a name="line.971"></a>
<span class="sourceLineNo">972</span>        return;<a name="line.972"></a>
<span class="sourceLineNo">973</span>      }<a name="line.973"></a>
<span class="sourceLineNo">974</span><a name="line.974"></a>
<span class="sourceLineNo">975</span>      //get a new datanode<a name="line.975"></a>
<span class="sourceLineNo">976</span>      final DatanodeInfo[] original = nodes;<a name="line.976"></a>
<span class="sourceLineNo">977</span>      final LocatedBlock lb = dfsClient.namenode.getAdditionalDatanode(<a name="line.977"></a>
<span class="sourceLineNo">978</span>          src, fileId, block, nodes, storageIDs,<a name="line.978"></a>
<span class="sourceLineNo">979</span>          failed.toArray(new DatanodeInfo[failed.size()]),<a name="line.979"></a>
<span class="sourceLineNo">980</span>          1, dfsClient.clientName);<a name="line.980"></a>
<span class="sourceLineNo">981</span>      setPipeline(lb);<a name="line.981"></a>
<span class="sourceLineNo">982</span><a name="line.982"></a>
<span class="sourceLineNo">983</span>      //find the new datanode<a name="line.983"></a>
<span class="sourceLineNo">984</span>      final int d = findNewDatanode(original);<a name="line.984"></a>
<span class="sourceLineNo">985</span><a name="line.985"></a>
<span class="sourceLineNo">986</span>      //transfer replica<a name="line.986"></a>
<span class="sourceLineNo">987</span>      final DatanodeInfo src = d == 0? nodes[1]: nodes[d - 1];<a name="line.987"></a>
<span class="sourceLineNo">988</span>      final DatanodeInfo[] targets = {nodes[d]};<a name="line.988"></a>
<span class="sourceLineNo">989</span>      final StorageType[] targetStorageTypes = {storageTypes[d]};<a name="line.989"></a>
<span class="sourceLineNo">990</span>      transfer(src, targets, targetStorageTypes, lb.getBlockToken());<a name="line.990"></a>
<span class="sourceLineNo">991</span>    }<a name="line.991"></a>
<span class="sourceLineNo">992</span><a name="line.992"></a>
<span class="sourceLineNo">993</span>    private void transfer(final DatanodeInfo src, final DatanodeInfo[] targets,<a name="line.993"></a>
<span class="sourceLineNo">994</span>        final StorageType[] targetStorageTypes,<a name="line.994"></a>
<span class="sourceLineNo">995</span>        final Token&lt;BlockTokenIdentifier&gt; blockToken) throws IOException {<a name="line.995"></a>
<span class="sourceLineNo">996</span>      //transfer replica to the new datanode<a name="line.996"></a>
<span class="sourceLineNo">997</span>      Socket sock = null;<a name="line.997"></a>
<span class="sourceLineNo">998</span>      DataOutputStream out = null;<a name="line.998"></a>
<span class="sourceLineNo">999</span>      DataInputStream in = null;<a name="line.999"></a>
<span class="sourceLineNo">1000</span>      try {<a name="line.1000"></a>
<span class="sourceLineNo">1001</span>        sock = createSocketForPipeline(src, 2, dfsClient);<a name="line.1001"></a>
<span class="sourceLineNo">1002</span>        final long writeTimeout = dfsClient.getDatanodeWriteTimeout(2);<a name="line.1002"></a>
<span class="sourceLineNo">1003</span>        <a name="line.1003"></a>
<span class="sourceLineNo">1004</span>        OutputStream unbufOut = NetUtils.getOutputStream(sock, writeTimeout);<a name="line.1004"></a>
<span class="sourceLineNo">1005</span>        InputStream unbufIn = NetUtils.getInputStream(sock);<a name="line.1005"></a>
<span class="sourceLineNo">1006</span>        IOStreamPair saslStreams = dfsClient.saslClient.socketSend(sock,<a name="line.1006"></a>
<span class="sourceLineNo">1007</span>          unbufOut, unbufIn, dfsClient, blockToken, src);<a name="line.1007"></a>
<span class="sourceLineNo">1008</span>        unbufOut = saslStreams.out;<a name="line.1008"></a>
<span class="sourceLineNo">1009</span>        unbufIn = saslStreams.in;<a name="line.1009"></a>
<span class="sourceLineNo">1010</span>        out = new DataOutputStream(new BufferedOutputStream(unbufOut,<a name="line.1010"></a>
<span class="sourceLineNo">1011</span>            HdfsConstants.SMALL_BUFFER_SIZE));<a name="line.1011"></a>
<span class="sourceLineNo">1012</span>        in = new DataInputStream(unbufIn);<a name="line.1012"></a>
<span class="sourceLineNo">1013</span><a name="line.1013"></a>
<span class="sourceLineNo">1014</span>        //send the TRANSFER_BLOCK request<a name="line.1014"></a>
<span class="sourceLineNo">1015</span>        new Sender(out).transferBlock(block, blockToken, dfsClient.clientName,<a name="line.1015"></a>
<span class="sourceLineNo">1016</span>            targets, targetStorageTypes);<a name="line.1016"></a>
<span class="sourceLineNo">1017</span>        out.flush();<a name="line.1017"></a>
<span class="sourceLineNo">1018</span><a name="line.1018"></a>
<span class="sourceLineNo">1019</span>        //ack<a name="line.1019"></a>
<span class="sourceLineNo">1020</span>        BlockOpResponseProto response =<a name="line.1020"></a>
<span class="sourceLineNo">1021</span>          BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(in));<a name="line.1021"></a>
<span class="sourceLineNo">1022</span>        if (SUCCESS != response.getStatus()) {<a name="line.1022"></a>
<span class="sourceLineNo">1023</span>          throw new IOException("Failed to add a datanode");<a name="line.1023"></a>
<span class="sourceLineNo">1024</span>        }<a name="line.1024"></a>
<span class="sourceLineNo">1025</span>      } finally {<a name="line.1025"></a>
<span class="sourceLineNo">1026</span>        IOUtils.closeStream(in);<a name="line.1026"></a>
<span class="sourceLineNo">1027</span>        IOUtils.closeStream(out);<a name="line.1027"></a>
<span class="sourceLineNo">1028</span>        IOUtils.closeSocket(sock);<a name="line.1028"></a>
<span class="sourceLineNo">1029</span>      }<a name="line.1029"></a>
<span class="sourceLineNo">1030</span>    }<a name="line.1030"></a>
<span class="sourceLineNo">1031</span><a name="line.1031"></a>
<span class="sourceLineNo">1032</span>    /**<a name="line.1032"></a>
<span class="sourceLineNo">1033</span>     * Open a DataOutputStream to a DataNode pipeline so that <a name="line.1033"></a>
<span class="sourceLineNo">1034</span>     * it can be written to.<a name="line.1034"></a>
<span class="sourceLineNo">1035</span>     * This happens when a file is appended or data streaming fails<a name="line.1035"></a>
<span class="sourceLineNo">1036</span>     * It keeps on trying until a pipeline is setup<a name="line.1036"></a>
<span class="sourceLineNo">1037</span>     */<a name="line.1037"></a>
<span class="sourceLineNo">1038</span>    private boolean setupPipelineForAppendOrRecovery() throws IOException {<a name="line.1038"></a>
<span class="sourceLineNo">1039</span>      // check number of datanodes<a name="line.1039"></a>
<span class="sourceLineNo">1040</span>      if (nodes == null || nodes.length == 0) {<a name="line.1040"></a>
<span class="sourceLineNo">1041</span>        String msg = "Could not get block locations. " + "Source file \""<a name="line.1041"></a>
<span class="sourceLineNo">1042</span>            + src + "\" - Aborting...";<a name="line.1042"></a>
<span class="sourceLineNo">1043</span>        DFSClient.LOG.warn(msg);<a name="line.1043"></a>
<span class="sourceLineNo">1044</span>        setLastException(new IOException(msg));<a name="line.1044"></a>
<span class="sourceLineNo">1045</span>        streamerClosed = true;<a name="line.1045"></a>
<span class="sourceLineNo">1046</span>        return false;<a name="line.1046"></a>
<span class="sourceLineNo">1047</span>      }<a name="line.1047"></a>
<span class="sourceLineNo">1048</span>      <a name="line.1048"></a>
<span class="sourceLineNo">1049</span>      boolean success = false;<a name="line.1049"></a>
<span class="sourceLineNo">1050</span>      long newGS = 0L;<a name="line.1050"></a>
<span class="sourceLineNo">1051</span>      while (!success &amp;&amp; !streamerClosed &amp;&amp; dfsClient.clientRunning) {<a name="line.1051"></a>
<span class="sourceLineNo">1052</span>        // Sleep before reconnect if a dn is restarting.<a name="line.1052"></a>
<span class="sourceLineNo">1053</span>        // This process will be repeated until the deadline or the datanode<a name="line.1053"></a>
<span class="sourceLineNo">1054</span>        // starts back up.<a name="line.1054"></a>
<span class="sourceLineNo">1055</span>        if (restartingNodeIndex.get() &gt;= 0) {<a name="line.1055"></a>
<span class="sourceLineNo">1056</span>          // 4 seconds or the configured deadline period, whichever is shorter.<a name="line.1056"></a>
<span class="sourceLineNo">1057</span>          // This is the retry interval and recovery will be retried in this<a name="line.1057"></a>
<span class="sourceLineNo">1058</span>          // interval until timeout or success.<a name="line.1058"></a>
<span class="sourceLineNo">1059</span>          long delay = Math.min(dfsClient.getConf().datanodeRestartTimeout,<a name="line.1059"></a>
<span class="sourceLineNo">1060</span>              4000L);<a name="line.1060"></a>
<span class="sourceLineNo">1061</span>          try {<a name="line.1061"></a>
<span class="sourceLineNo">1062</span>            Thread.sleep(delay);<a name="line.1062"></a>
<span class="sourceLineNo">1063</span>          } catch (InterruptedException ie) {<a name="line.1063"></a>
<span class="sourceLineNo">1064</span>            lastException.set(new IOException("Interrupted while waiting for " +<a name="line.1064"></a>
<span class="sourceLineNo">1065</span>                "datanode to restart. " + nodes[restartingNodeIndex.get()]));<a name="line.1065"></a>
<span class="sourceLineNo">1066</span>            streamerClosed = true;<a name="line.1066"></a>
<span class="sourceLineNo">1067</span>            return false;<a name="line.1067"></a>
<span class="sourceLineNo">1068</span>          }<a name="line.1068"></a>
<span class="sourceLineNo">1069</span>        }<a name="line.1069"></a>
<span class="sourceLineNo">1070</span>        boolean isRecovery = hasError;<a name="line.1070"></a>
<span class="sourceLineNo">1071</span>        // remove bad datanode from list of datanodes.<a name="line.1071"></a>
<span class="sourceLineNo">1072</span>        // If errorIndex was not set (i.e. appends), then do not remove <a name="line.1072"></a>
<span class="sourceLineNo">1073</span>        // any datanodes<a name="line.1073"></a>
<span class="sourceLineNo">1074</span>        // <a name="line.1074"></a>
<span class="sourceLineNo">1075</span>        if (errorIndex &gt;= 0) {<a name="line.1075"></a>
<span class="sourceLineNo">1076</span>          StringBuilder pipelineMsg = new StringBuilder();<a name="line.1076"></a>
<span class="sourceLineNo">1077</span>          for (int j = 0; j &lt; nodes.length; j++) {<a name="line.1077"></a>
<span class="sourceLineNo">1078</span>            pipelineMsg.append(nodes[j]);<a name="line.1078"></a>
<span class="sourceLineNo">1079</span>            if (j &lt; nodes.length - 1) {<a name="line.1079"></a>
<span class="sourceLineNo">1080</span>              pipelineMsg.append(", ");<a name="line.1080"></a>
<span class="sourceLineNo">1081</span>            }<a name="line.1081"></a>
<span class="sourceLineNo">1082</span>          }<a name="line.1082"></a>
<span class="sourceLineNo">1083</span>          if (nodes.length &lt;= 1) {<a name="line.1083"></a>
<span class="sourceLineNo">1084</span>            lastException.set(new IOException("All datanodes " + pipelineMsg<a name="line.1084"></a>
<span class="sourceLineNo">1085</span>                + " are bad. Aborting..."));<a name="line.1085"></a>
<span class="sourceLineNo">1086</span>            streamerClosed = true;<a name="line.1086"></a>
<span class="sourceLineNo">1087</span>            return false;<a name="line.1087"></a>
<span class="sourceLineNo">1088</span>          }<a name="line.1088"></a>
<span class="sourceLineNo">1089</span>          DFSClient.LOG.warn("Error Recovery for block " + block +<a name="line.1089"></a>
<span class="sourceLineNo">1090</span>              " in pipeline " + pipelineMsg + <a name="line.1090"></a>
<span class="sourceLineNo">1091</span>              ": bad datanode " + nodes[errorIndex]);<a name="line.1091"></a>
<span class="sourceLineNo">1092</span>          failed.add(nodes[errorIndex]);<a name="line.1092"></a>
<span class="sourceLineNo">1093</span><a name="line.1093"></a>
<span class="sourceLineNo">1094</span>          DatanodeInfo[] newnodes = new DatanodeInfo[nodes.length-1];<a name="line.1094"></a>
<span class="sourceLineNo">1095</span>          arraycopy(nodes, newnodes, errorIndex);<a name="line.1095"></a>
<span class="sourceLineNo">1096</span><a name="line.1096"></a>
<span class="sourceLineNo">1097</span>          final StorageType[] newStorageTypes = new StorageType[newnodes.length];<a name="line.1097"></a>
<span class="sourceLineNo">1098</span>          arraycopy(storageTypes, newStorageTypes, errorIndex);<a name="line.1098"></a>
<span class="sourceLineNo">1099</span><a name="line.1099"></a>
<span class="sourceLineNo">1100</span>          final String[] newStorageIDs = new String[newnodes.length];<a name="line.1100"></a>
<span class="sourceLineNo">1101</span>          arraycopy(storageIDs, newStorageIDs, errorIndex);<a name="line.1101"></a>
<span class="sourceLineNo">1102</span>          <a name="line.1102"></a>
<span class="sourceLineNo">1103</span>          setPipeline(newnodes, newStorageTypes, newStorageIDs);<a name="line.1103"></a>
<span class="sourceLineNo">1104</span><a name="line.1104"></a>
<span class="sourceLineNo">1105</span>          // Just took care of a node error while waiting for a node restart<a name="line.1105"></a>
<span class="sourceLineNo">1106</span>          if (restartingNodeIndex.get() &gt;= 0) {<a name="line.1106"></a>
<span class="sourceLineNo">1107</span>            // If the error came from a node further away than the restarting<a name="line.1107"></a>
<span class="sourceLineNo">1108</span>            // node, the restart must have been complete.<a name="line.1108"></a>
<span class="sourceLineNo">1109</span>            if (errorIndex &gt; restartingNodeIndex.get()) {<a name="line.1109"></a>
<span class="sourceLineNo">1110</span>              restartingNodeIndex.set(-1);<a name="line.1110"></a>
<span class="sourceLineNo">1111</span>            } else if (errorIndex &lt; restartingNodeIndex.get()) {<a name="line.1111"></a>
<span class="sourceLineNo">1112</span>              // the node index has shifted.<a name="line.1112"></a>
<span class="sourceLineNo">1113</span>              restartingNodeIndex.decrementAndGet();<a name="line.1113"></a>
<span class="sourceLineNo">1114</span>            } else {<a name="line.1114"></a>
<span class="sourceLineNo">1115</span>              // this shouldn't happen...<a name="line.1115"></a>
<span class="sourceLineNo">1116</span>              assert false;<a name="line.1116"></a>
<span class="sourceLineNo">1117</span>            }<a name="line.1117"></a>
<span class="sourceLineNo">1118</span>          }<a name="line.1118"></a>
<span class="sourceLineNo">1119</span><a name="line.1119"></a>
<span class="sourceLineNo">1120</span>          if (restartingNodeIndex.get() == -1) {<a name="line.1120"></a>
<span class="sourceLineNo">1121</span>            hasError = false;<a name="line.1121"></a>
<span class="sourceLineNo">1122</span>          }<a name="line.1122"></a>
<span class="sourceLineNo">1123</span>          lastException.set(null);<a name="line.1123"></a>
<span class="sourceLineNo">1124</span>          errorIndex = -1;<a name="line.1124"></a>
<span class="sourceLineNo">1125</span>        }<a name="line.1125"></a>
<span class="sourceLineNo">1126</span><a name="line.1126"></a>
<span class="sourceLineNo">1127</span>        // Check if replace-datanode policy is satisfied.<a name="line.1127"></a>
<span class="sourceLineNo">1128</span>        if (dfsClient.dtpReplaceDatanodeOnFailure.satisfy(blockReplication,<a name="line.1128"></a>
<span class="sourceLineNo">1129</span>            nodes, isAppend, isHflushed)) {<a name="line.1129"></a>
<span class="sourceLineNo">1130</span>          try {<a name="line.1130"></a>
<span class="sourceLineNo">1131</span>            addDatanode2ExistingPipeline();<a name="line.1131"></a>
<span class="sourceLineNo">1132</span>          } catch(IOException ioe) {<a name="line.1132"></a>
<span class="sourceLineNo">1133</span>            if (!dfsClient.dtpReplaceDatanodeOnFailure.isBestEffort()) {<a name="line.1133"></a>
<span class="sourceLineNo">1134</span>              throw ioe;<a name="line.1134"></a>
<span class="sourceLineNo">1135</span>            }<a name="line.1135"></a>
<span class="sourceLineNo">1136</span>            DFSClient.LOG.warn("Failed to replace datanode."<a name="line.1136"></a>
<span class="sourceLineNo">1137</span>                + " Continue with the remaining datanodes since "<a name="line.1137"></a>
<span class="sourceLineNo">1138</span>                + DFSConfigKeys.DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_BEST_EFFORT_KEY<a name="line.1138"></a>
<span class="sourceLineNo">1139</span>                + " is set to true.", ioe);<a name="line.1139"></a>
<span class="sourceLineNo">1140</span>          }<a name="line.1140"></a>
<span class="sourceLineNo">1141</span>        }<a name="line.1141"></a>
<span class="sourceLineNo">1142</span><a name="line.1142"></a>
<span class="sourceLineNo">1143</span>        // get a new generation stamp and an access token<a name="line.1143"></a>
<span class="sourceLineNo">1144</span>        LocatedBlock lb = dfsClient.namenode.updateBlockForPipeline(block, dfsClient.clientName);<a name="line.1144"></a>
<span class="sourceLineNo">1145</span>        newGS = lb.getBlock().getGenerationStamp();<a name="line.1145"></a>
<span class="sourceLineNo">1146</span>        accessToken = lb.getBlockToken();<a name="line.1146"></a>
<span class="sourceLineNo">1147</span>        <a name="line.1147"></a>
<span class="sourceLineNo">1148</span>        // set up the pipeline again with the remaining nodes<a name="line.1148"></a>
<span class="sourceLineNo">1149</span>        if (failPacket) { // for testing<a name="line.1149"></a>
<span class="sourceLineNo">1150</span>          success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);<a name="line.1150"></a>
<span class="sourceLineNo">1151</span>          failPacket = false;<a name="line.1151"></a>
<span class="sourceLineNo">1152</span>          try {<a name="line.1152"></a>
<span class="sourceLineNo">1153</span>            // Give DNs time to send in bad reports. In real situations,<a name="line.1153"></a>
<span class="sourceLineNo">1154</span>            // good reports should follow bad ones, if client committed<a name="line.1154"></a>
<span class="sourceLineNo">1155</span>            // with those nodes.<a name="line.1155"></a>
<span class="sourceLineNo">1156</span>            Thread.sleep(2000);<a name="line.1156"></a>
<span class="sourceLineNo">1157</span>          } catch (InterruptedException ie) {}<a name="line.1157"></a>
<span class="sourceLineNo">1158</span>        } else {<a name="line.1158"></a>
<span class="sourceLineNo">1159</span>          success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);<a name="line.1159"></a>
<span class="sourceLineNo">1160</span>        }<a name="line.1160"></a>
<span class="sourceLineNo">1161</span><a name="line.1161"></a>
<span class="sourceLineNo">1162</span>        if (restartingNodeIndex.get() &gt;= 0) {<a name="line.1162"></a>
<span class="sourceLineNo">1163</span>          assert hasError == true;<a name="line.1163"></a>
<span class="sourceLineNo">1164</span>          // check errorIndex set above<a name="line.1164"></a>
<span class="sourceLineNo">1165</span>          if (errorIndex == restartingNodeIndex.get()) {<a name="line.1165"></a>
<span class="sourceLineNo">1166</span>            // ignore, if came from the restarting node<a name="line.1166"></a>
<span class="sourceLineNo">1167</span>            errorIndex = -1;<a name="line.1167"></a>
<span class="sourceLineNo">1168</span>          }<a name="line.1168"></a>
<span class="sourceLineNo">1169</span>          // still within the deadline<a name="line.1169"></a>
<span class="sourceLineNo">1170</span>          if (Time.monotonicNow() &lt; restartDeadline) {<a name="line.1170"></a>
<span class="sourceLineNo">1171</span>            continue; // with in the deadline<a name="line.1171"></a>
<span class="sourceLineNo">1172</span>          }<a name="line.1172"></a>
<span class="sourceLineNo">1173</span>          // expired. declare the restarting node dead<a name="line.1173"></a>
<span class="sourceLineNo">1174</span>          restartDeadline = 0;<a name="line.1174"></a>
<span class="sourceLineNo">1175</span>          int expiredNodeIndex = restartingNodeIndex.get();<a name="line.1175"></a>
<span class="sourceLineNo">1176</span>          restartingNodeIndex.set(-1);<a name="line.1176"></a>
<span class="sourceLineNo">1177</span>          DFSClient.LOG.warn("Datanode did not restart in time: " +<a name="line.1177"></a>
<span class="sourceLineNo">1178</span>              nodes[expiredNodeIndex]);<a name="line.1178"></a>
<span class="sourceLineNo">1179</span>          // Mark the restarting node as failed. If there is any other failed<a name="line.1179"></a>
<span class="sourceLineNo">1180</span>          // node during the last pipeline construction attempt, it will not be<a name="line.1180"></a>
<span class="sourceLineNo">1181</span>          // overwritten/dropped. In this case, the restarting node will get<a name="line.1181"></a>
<span class="sourceLineNo">1182</span>          // excluded in the following attempt, if it still does not come up.<a name="line.1182"></a>
<span class="sourceLineNo">1183</span>          if (errorIndex == -1) {<a name="line.1183"></a>
<span class="sourceLineNo">1184</span>            errorIndex = expiredNodeIndex;<a name="line.1184"></a>
<span class="sourceLineNo">1185</span>          }<a name="line.1185"></a>
<span class="sourceLineNo">1186</span>          // From this point on, normal pipeline recovery applies.<a name="line.1186"></a>
<span class="sourceLineNo">1187</span>        }<a name="line.1187"></a>
<span class="sourceLineNo">1188</span>      } // while<a name="line.1188"></a>
<span class="sourceLineNo">1189</span><a name="line.1189"></a>
<span class="sourceLineNo">1190</span>      if (success) {<a name="line.1190"></a>
<span class="sourceLineNo">1191</span>        // update pipeline at the namenode<a name="line.1191"></a>
<span class="sourceLineNo">1192</span>        ExtendedBlock newBlock = new ExtendedBlock(<a name="line.1192"></a>
<span class="sourceLineNo">1193</span>            block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);<a name="line.1193"></a>
<span class="sourceLineNo">1194</span>        dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,<a name="line.1194"></a>
<span class="sourceLineNo">1195</span>            nodes, storageIDs);<a name="line.1195"></a>
<span class="sourceLineNo">1196</span>        // update client side generation stamp<a name="line.1196"></a>
<span class="sourceLineNo">1197</span>        block = newBlock;<a name="line.1197"></a>
<span class="sourceLineNo">1198</span>      }<a name="line.1198"></a>
<span class="sourceLineNo">1199</span>      return false; // do not sleep, continue processing<a name="line.1199"></a>
<span class="sourceLineNo">1200</span>    }<a name="line.1200"></a>
<span class="sourceLineNo">1201</span><a name="line.1201"></a>
<span class="sourceLineNo">1202</span>    /**<a name="line.1202"></a>
<span class="sourceLineNo">1203</span>     * Open a DataOutputStream to a DataNode so that it can be written to.<a name="line.1203"></a>
<span class="sourceLineNo">1204</span>     * This happens when a file is created and each time a new block is allocated.<a name="line.1204"></a>
<span class="sourceLineNo">1205</span>     * Must get block ID and the IDs of the destinations from the namenode.<a name="line.1205"></a>
<span class="sourceLineNo">1206</span>     * Returns the list of target datanodes.<a name="line.1206"></a>
<span class="sourceLineNo">1207</span>     */<a name="line.1207"></a>
<span class="sourceLineNo">1208</span>    private LocatedBlock nextBlockOutputStream() throws IOException {<a name="line.1208"></a>
<span class="sourceLineNo">1209</span>      LocatedBlock lb = null;<a name="line.1209"></a>
<span class="sourceLineNo">1210</span>      DatanodeInfo[] nodes = null;<a name="line.1210"></a>
<span class="sourceLineNo">1211</span>      StorageType[] storageTypes = null;<a name="line.1211"></a>
<span class="sourceLineNo">1212</span>      int count = dfsClient.getConf().nBlockWriteRetry;<a name="line.1212"></a>
<span class="sourceLineNo">1213</span>      boolean success = false;<a name="line.1213"></a>
<span class="sourceLineNo">1214</span>      ExtendedBlock oldBlock = block;<a name="line.1214"></a>
<span class="sourceLineNo">1215</span>      do {<a name="line.1215"></a>
<span class="sourceLineNo">1216</span>        hasError = false;<a name="line.1216"></a>
<span class="sourceLineNo">1217</span>        lastException.set(null);<a name="line.1217"></a>
<span class="sourceLineNo">1218</span>        errorIndex = -1;<a name="line.1218"></a>
<span class="sourceLineNo">1219</span>        success = false;<a name="line.1219"></a>
<span class="sourceLineNo">1220</span><a name="line.1220"></a>
<span class="sourceLineNo">1221</span>        DatanodeInfo[] excluded =<a name="line.1221"></a>
<span class="sourceLineNo">1222</span>            excludedNodes.getAllPresent(excludedNodes.asMap().keySet())<a name="line.1222"></a>
<span class="sourceLineNo">1223</span>            .keySet()<a name="line.1223"></a>
<span class="sourceLineNo">1224</span>            .toArray(new DatanodeInfo[0]);<a name="line.1224"></a>
<span class="sourceLineNo">1225</span>        block = oldBlock;<a name="line.1225"></a>
<span class="sourceLineNo">1226</span>        lb = locateFollowingBlock(excluded.length &gt; 0 ? excluded : null);<a name="line.1226"></a>
<span class="sourceLineNo">1227</span>        block = lb.getBlock();<a name="line.1227"></a>
<span class="sourceLineNo">1228</span>        block.setNumBytes(0);<a name="line.1228"></a>
<span class="sourceLineNo">1229</span>        bytesSent = 0;<a name="line.1229"></a>
<span class="sourceLineNo">1230</span>        accessToken = lb.getBlockToken();<a name="line.1230"></a>
<span class="sourceLineNo">1231</span>        nodes = lb.getLocations();<a name="line.1231"></a>
<span class="sourceLineNo">1232</span>        storageTypes = lb.getStorageTypes();<a name="line.1232"></a>
<span class="sourceLineNo">1233</span><a name="line.1233"></a>
<span class="sourceLineNo">1234</span>        //<a name="line.1234"></a>
<span class="sourceLineNo">1235</span>        // Connect to first DataNode in the list.<a name="line.1235"></a>
<span class="sourceLineNo">1236</span>        //<a name="line.1236"></a>
<span class="sourceLineNo">1237</span>        success = createBlockOutputStream(nodes, storageTypes, 0L, false);<a name="line.1237"></a>
<span class="sourceLineNo">1238</span><a name="line.1238"></a>
<span class="sourceLineNo">1239</span>        if (!success) {<a name="line.1239"></a>
<span class="sourceLineNo">1240</span>          DFSClient.LOG.info("Abandoning " + block);<a name="line.1240"></a>
<span class="sourceLineNo">1241</span>          dfsClient.namenode.abandonBlock(block, fileId, src,<a name="line.1241"></a>
<span class="sourceLineNo">1242</span>              dfsClient.clientName);<a name="line.1242"></a>
<span class="sourceLineNo">1243</span>          block = null;<a name="line.1243"></a>
<span class="sourceLineNo">1244</span>          DFSClient.LOG.info("Excluding datanode " + nodes[errorIndex]);<a name="line.1244"></a>
<span class="sourceLineNo">1245</span>          excludedNodes.put(nodes[errorIndex], nodes[errorIndex]);<a name="line.1245"></a>
<span class="sourceLineNo">1246</span>        }<a name="line.1246"></a>
<span class="sourceLineNo">1247</span>      } while (!success &amp;&amp; --count &gt;= 0);<a name="line.1247"></a>
<span class="sourceLineNo">1248</span><a name="line.1248"></a>
<span class="sourceLineNo">1249</span>      if (!success) {<a name="line.1249"></a>
<span class="sourceLineNo">1250</span>        throw new IOException("Unable to create new block.");<a name="line.1250"></a>
<span class="sourceLineNo">1251</span>      }<a name="line.1251"></a>
<span class="sourceLineNo">1252</span>      return lb;<a name="line.1252"></a>
<span class="sourceLineNo">1253</span>    }<a name="line.1253"></a>
<span class="sourceLineNo">1254</span><a name="line.1254"></a>
<span class="sourceLineNo">1255</span>    // connects to the first datanode in the pipeline<a name="line.1255"></a>
<span class="sourceLineNo">1256</span>    // Returns true if success, otherwise return failure.<a name="line.1256"></a>
<span class="sourceLineNo">1257</span>    //<a name="line.1257"></a>
<span class="sourceLineNo">1258</span>    private boolean createBlockOutputStream(DatanodeInfo[] nodes,<a name="line.1258"></a>
<span class="sourceLineNo">1259</span>        StorageType[] nodeStorageTypes, long newGS, boolean recoveryFlag) {<a name="line.1259"></a>
<span class="sourceLineNo">1260</span>      if (nodes.length == 0) {<a name="line.1260"></a>
<span class="sourceLineNo">1261</span>        DFSClient.LOG.info("nodes are empty for write pipeline of block "<a name="line.1261"></a>
<span class="sourceLineNo">1262</span>            + block);<a name="line.1262"></a>
<span class="sourceLineNo">1263</span>        return false;<a name="line.1263"></a>
<span class="sourceLineNo">1264</span>      }<a name="line.1264"></a>
<span class="sourceLineNo">1265</span>      Status pipelineStatus = SUCCESS;<a name="line.1265"></a>
<span class="sourceLineNo">1266</span>      String firstBadLink = "";<a name="line.1266"></a>
<span class="sourceLineNo">1267</span>      boolean checkRestart = false;<a name="line.1267"></a>
<span class="sourceLineNo">1268</span>      if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1268"></a>
<span class="sourceLineNo">1269</span>        for (int i = 0; i &lt; nodes.length; i++) {<a name="line.1269"></a>
<span class="sourceLineNo">1270</span>          DFSClient.LOG.debug("pipeline = " + nodes[i]);<a name="line.1270"></a>
<span class="sourceLineNo">1271</span>        }<a name="line.1271"></a>
<span class="sourceLineNo">1272</span>      }<a name="line.1272"></a>
<span class="sourceLineNo">1273</span><a name="line.1273"></a>
<span class="sourceLineNo">1274</span>      // persist blocks on namenode on next flush<a name="line.1274"></a>
<span class="sourceLineNo">1275</span>      persistBlocks.set(true);<a name="line.1275"></a>
<span class="sourceLineNo">1276</span><a name="line.1276"></a>
<span class="sourceLineNo">1277</span>      int refetchEncryptionKey = 1;<a name="line.1277"></a>
<span class="sourceLineNo">1278</span>      while (true) {<a name="line.1278"></a>
<span class="sourceLineNo">1279</span>        boolean result = false;<a name="line.1279"></a>
<span class="sourceLineNo">1280</span>        DataOutputStream out = null;<a name="line.1280"></a>
<span class="sourceLineNo">1281</span>        try {<a name="line.1281"></a>
<span class="sourceLineNo">1282</span>          assert null == s : "Previous socket unclosed";<a name="line.1282"></a>
<span class="sourceLineNo">1283</span>          assert null == blockReplyStream : "Previous blockReplyStream unclosed";<a name="line.1283"></a>
<span class="sourceLineNo">1284</span>          s = createSocketForPipeline(nodes[0], nodes.length, dfsClient);<a name="line.1284"></a>
<span class="sourceLineNo">1285</span>          long writeTimeout = dfsClient.getDatanodeWriteTimeout(nodes.length);<a name="line.1285"></a>
<span class="sourceLineNo">1286</span>          <a name="line.1286"></a>
<span class="sourceLineNo">1287</span>          OutputStream unbufOut = NetUtils.getOutputStream(s, writeTimeout);<a name="line.1287"></a>
<span class="sourceLineNo">1288</span>          InputStream unbufIn = NetUtils.getInputStream(s);<a name="line.1288"></a>
<span class="sourceLineNo">1289</span>          IOStreamPair saslStreams = dfsClient.saslClient.socketSend(s,<a name="line.1289"></a>
<span class="sourceLineNo">1290</span>            unbufOut, unbufIn, dfsClient, accessToken, nodes[0]);<a name="line.1290"></a>
<span class="sourceLineNo">1291</span>          unbufOut = saslStreams.out;<a name="line.1291"></a>
<span class="sourceLineNo">1292</span>          unbufIn = saslStreams.in;<a name="line.1292"></a>
<span class="sourceLineNo">1293</span>          out = new DataOutputStream(new BufferedOutputStream(unbufOut,<a name="line.1293"></a>
<span class="sourceLineNo">1294</span>              HdfsConstants.SMALL_BUFFER_SIZE));<a name="line.1294"></a>
<span class="sourceLineNo">1295</span>          blockReplyStream = new DataInputStream(unbufIn);<a name="line.1295"></a>
<span class="sourceLineNo">1296</span>  <a name="line.1296"></a>
<span class="sourceLineNo">1297</span>          //<a name="line.1297"></a>
<span class="sourceLineNo">1298</span>          // Xmit header info to datanode<a name="line.1298"></a>
<span class="sourceLineNo">1299</span>          //<a name="line.1299"></a>
<span class="sourceLineNo">1300</span>  <a name="line.1300"></a>
<span class="sourceLineNo">1301</span>          BlockConstructionStage bcs = recoveryFlag? stage.getRecoveryStage(): stage;<a name="line.1301"></a>
<span class="sourceLineNo">1302</span><a name="line.1302"></a>
<span class="sourceLineNo">1303</span>          // We cannot change the block length in 'block' as it counts the number<a name="line.1303"></a>
<span class="sourceLineNo">1304</span>          // of bytes ack'ed.<a name="line.1304"></a>
<span class="sourceLineNo">1305</span>          ExtendedBlock blockCopy = new ExtendedBlock(block);<a name="line.1305"></a>
<span class="sourceLineNo">1306</span>          blockCopy.setNumBytes(blockSize);<a name="line.1306"></a>
<span class="sourceLineNo">1307</span><a name="line.1307"></a>
<span class="sourceLineNo">1308</span>          boolean[] targetPinnings = getPinnings(nodes, true);<a name="line.1308"></a>
<span class="sourceLineNo">1309</span>          // send the request<a name="line.1309"></a>
<span class="sourceLineNo">1310</span>          new Sender(out).writeBlock(blockCopy, nodeStorageTypes[0], accessToken,<a name="line.1310"></a>
<span class="sourceLineNo">1311</span>              dfsClient.clientName, nodes, nodeStorageTypes, null, bcs, <a name="line.1311"></a>
<span class="sourceLineNo">1312</span>              nodes.length, block.getNumBytes(), bytesSent, newGS,<a name="line.1312"></a>
<span class="sourceLineNo">1313</span>              checksum4WriteBlock, cachingStrategy.get(), isLazyPersistFile,<a name="line.1313"></a>
<span class="sourceLineNo">1314</span>            (targetPinnings == null ? false : targetPinnings[0]), targetPinnings);<a name="line.1314"></a>
<span class="sourceLineNo">1315</span>  <a name="line.1315"></a>
<span class="sourceLineNo">1316</span>          // receive ack for connect<a name="line.1316"></a>
<span class="sourceLineNo">1317</span>          BlockOpResponseProto resp = BlockOpResponseProto.parseFrom(<a name="line.1317"></a>
<span class="sourceLineNo">1318</span>              PBHelper.vintPrefixed(blockReplyStream));<a name="line.1318"></a>
<span class="sourceLineNo">1319</span>          pipelineStatus = resp.getStatus();<a name="line.1319"></a>
<span class="sourceLineNo">1320</span>          firstBadLink = resp.getFirstBadLink();<a name="line.1320"></a>
<span class="sourceLineNo">1321</span>          <a name="line.1321"></a>
<span class="sourceLineNo">1322</span>          // Got an restart OOB ack.<a name="line.1322"></a>
<span class="sourceLineNo">1323</span>          // If a node is already restarting, this status is not likely from<a name="line.1323"></a>
<span class="sourceLineNo">1324</span>          // the same node. If it is from a different node, it is not<a name="line.1324"></a>
<span class="sourceLineNo">1325</span>          // from the local datanode. Thus it is safe to treat this as a<a name="line.1325"></a>
<span class="sourceLineNo">1326</span>          // regular node error.<a name="line.1326"></a>
<span class="sourceLineNo">1327</span>          if (PipelineAck.isRestartOOBStatus(pipelineStatus) &amp;&amp;<a name="line.1327"></a>
<span class="sourceLineNo">1328</span>            restartingNodeIndex.get() == -1) {<a name="line.1328"></a>
<span class="sourceLineNo">1329</span>            checkRestart = true;<a name="line.1329"></a>
<span class="sourceLineNo">1330</span>            throw new IOException("A datanode is restarting.");<a name="line.1330"></a>
<span class="sourceLineNo">1331</span>          }<a name="line.1331"></a>
<span class="sourceLineNo">1332</span><a name="line.1332"></a>
<span class="sourceLineNo">1333</span>          String logInfo = "ack with firstBadLink as " + firstBadLink;<a name="line.1333"></a>
<span class="sourceLineNo">1334</span>          DataTransferProtoUtil.checkBlockOpStatus(resp, logInfo);<a name="line.1334"></a>
<span class="sourceLineNo">1335</span><a name="line.1335"></a>
<span class="sourceLineNo">1336</span>          assert null == blockStream : "Previous blockStream unclosed";<a name="line.1336"></a>
<span class="sourceLineNo">1337</span>          blockStream = out;<a name="line.1337"></a>
<span class="sourceLineNo">1338</span>          result =  true; // success<a name="line.1338"></a>
<span class="sourceLineNo">1339</span>          restartingNodeIndex.set(-1);<a name="line.1339"></a>
<span class="sourceLineNo">1340</span>          hasError = false;<a name="line.1340"></a>
<span class="sourceLineNo">1341</span>        } catch (IOException ie) {<a name="line.1341"></a>
<span class="sourceLineNo">1342</span>          if (restartingNodeIndex.get() == -1) {<a name="line.1342"></a>
<span class="sourceLineNo">1343</span>            DFSClient.LOG.info("Exception in createBlockOutputStream", ie);<a name="line.1343"></a>
<span class="sourceLineNo">1344</span>          }<a name="line.1344"></a>
<span class="sourceLineNo">1345</span>          if (ie instanceof InvalidEncryptionKeyException &amp;&amp; refetchEncryptionKey &gt; 0) {<a name="line.1345"></a>
<span class="sourceLineNo">1346</span>            DFSClient.LOG.info("Will fetch a new encryption key and retry, " <a name="line.1346"></a>
<span class="sourceLineNo">1347</span>                + "encryption key was invalid when connecting to "<a name="line.1347"></a>
<span class="sourceLineNo">1348</span>                + nodes[0] + " : " + ie);<a name="line.1348"></a>
<span class="sourceLineNo">1349</span>            // The encryption key used is invalid.<a name="line.1349"></a>
<span class="sourceLineNo">1350</span>            refetchEncryptionKey--;<a name="line.1350"></a>
<span class="sourceLineNo">1351</span>            dfsClient.clearDataEncryptionKey();<a name="line.1351"></a>
<span class="sourceLineNo">1352</span>            // Don't close the socket/exclude this node just yet. Try again with<a name="line.1352"></a>
<span class="sourceLineNo">1353</span>            // a new encryption key.<a name="line.1353"></a>
<span class="sourceLineNo">1354</span>            continue;<a name="line.1354"></a>
<span class="sourceLineNo">1355</span>          }<a name="line.1355"></a>
<span class="sourceLineNo">1356</span>  <a name="line.1356"></a>
<span class="sourceLineNo">1357</span>          // find the datanode that matches<a name="line.1357"></a>
<span class="sourceLineNo">1358</span>          if (firstBadLink.length() != 0) {<a name="line.1358"></a>
<span class="sourceLineNo">1359</span>            for (int i = 0; i &lt; nodes.length; i++) {<a name="line.1359"></a>
<span class="sourceLineNo">1360</span>              // NB: Unconditionally using the xfer addr w/o hostname<a name="line.1360"></a>
<span class="sourceLineNo">1361</span>              if (firstBadLink.equals(nodes[i].getXferAddr())) {<a name="line.1361"></a>
<span class="sourceLineNo">1362</span>                errorIndex = i;<a name="line.1362"></a>
<span class="sourceLineNo">1363</span>                break;<a name="line.1363"></a>
<span class="sourceLineNo">1364</span>              }<a name="line.1364"></a>
<span class="sourceLineNo">1365</span>            }<a name="line.1365"></a>
<span class="sourceLineNo">1366</span>          } else {<a name="line.1366"></a>
<span class="sourceLineNo">1367</span>            assert checkRestart == false;<a name="line.1367"></a>
<span class="sourceLineNo">1368</span>            errorIndex = 0;<a name="line.1368"></a>
<span class="sourceLineNo">1369</span>          }<a name="line.1369"></a>
<span class="sourceLineNo">1370</span>          // Check whether there is a restart worth waiting for.<a name="line.1370"></a>
<span class="sourceLineNo">1371</span>          if (checkRestart &amp;&amp; shouldWaitForRestart(errorIndex)) {<a name="line.1371"></a>
<span class="sourceLineNo">1372</span>            restartDeadline = dfsClient.getConf().datanodeRestartTimeout +<a name="line.1372"></a>
<span class="sourceLineNo">1373</span>                Time.monotonicNow();<a name="line.1373"></a>
<span class="sourceLineNo">1374</span>            restartingNodeIndex.set(errorIndex);<a name="line.1374"></a>
<span class="sourceLineNo">1375</span>            errorIndex = -1;<a name="line.1375"></a>
<span class="sourceLineNo">1376</span>            DFSClient.LOG.info("Waiting for the datanode to be restarted: " +<a name="line.1376"></a>
<span class="sourceLineNo">1377</span>                nodes[restartingNodeIndex.get()]);<a name="line.1377"></a>
<span class="sourceLineNo">1378</span>          }<a name="line.1378"></a>
<span class="sourceLineNo">1379</span>          hasError = true;<a name="line.1379"></a>
<span class="sourceLineNo">1380</span>          setLastException(ie);<a name="line.1380"></a>
<span class="sourceLineNo">1381</span>          result =  false;  // error<a name="line.1381"></a>
<span class="sourceLineNo">1382</span>        } finally {<a name="line.1382"></a>
<span class="sourceLineNo">1383</span>          if (!result) {<a name="line.1383"></a>
<span class="sourceLineNo">1384</span>            IOUtils.closeSocket(s);<a name="line.1384"></a>
<span class="sourceLineNo">1385</span>            s = null;<a name="line.1385"></a>
<span class="sourceLineNo">1386</span>            IOUtils.closeStream(out);<a name="line.1386"></a>
<span class="sourceLineNo">1387</span>            out = null;<a name="line.1387"></a>
<span class="sourceLineNo">1388</span>            IOUtils.closeStream(blockReplyStream);<a name="line.1388"></a>
<span class="sourceLineNo">1389</span>            blockReplyStream = null;<a name="line.1389"></a>
<span class="sourceLineNo">1390</span>          }<a name="line.1390"></a>
<span class="sourceLineNo">1391</span>        }<a name="line.1391"></a>
<span class="sourceLineNo">1392</span>        return result;<a name="line.1392"></a>
<span class="sourceLineNo">1393</span>      }<a name="line.1393"></a>
<span class="sourceLineNo">1394</span>    }<a name="line.1394"></a>
<span class="sourceLineNo">1395</span><a name="line.1395"></a>
<span class="sourceLineNo">1396</span>    private boolean[] getPinnings(DatanodeInfo[] nodes, boolean shouldLog) {<a name="line.1396"></a>
<span class="sourceLineNo">1397</span>      if (favoredNodes == null) {<a name="line.1397"></a>
<span class="sourceLineNo">1398</span>        return null;<a name="line.1398"></a>
<span class="sourceLineNo">1399</span>      } else {<a name="line.1399"></a>
<span class="sourceLineNo">1400</span>        boolean[] pinnings = new boolean[nodes.length];<a name="line.1400"></a>
<span class="sourceLineNo">1401</span>        HashSet&lt;String&gt; favoredSet =<a name="line.1401"></a>
<span class="sourceLineNo">1402</span>            new HashSet&lt;String&gt;(Arrays.asList(favoredNodes));<a name="line.1402"></a>
<span class="sourceLineNo">1403</span>        for (int i = 0; i &lt; nodes.length; i++) {<a name="line.1403"></a>
<span class="sourceLineNo">1404</span>          pinnings[i] = favoredSet.remove(nodes[i].getXferAddrWithHostname());<a name="line.1404"></a>
<span class="sourceLineNo">1405</span>          if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1405"></a>
<span class="sourceLineNo">1406</span>            DFSClient.LOG.debug(nodes[i].getXferAddrWithHostname() +<a name="line.1406"></a>
<span class="sourceLineNo">1407</span>                " was chosen by name node (favored=" + pinnings[i] +<a name="line.1407"></a>
<span class="sourceLineNo">1408</span>                ").");<a name="line.1408"></a>
<span class="sourceLineNo">1409</span>          }<a name="line.1409"></a>
<span class="sourceLineNo">1410</span>        }<a name="line.1410"></a>
<span class="sourceLineNo">1411</span>        if (shouldLog &amp;&amp; !favoredSet.isEmpty()) {<a name="line.1411"></a>
<span class="sourceLineNo">1412</span>          // There is one or more favored nodes that were not allocated.<a name="line.1412"></a>
<span class="sourceLineNo">1413</span>          DFSClient.LOG.warn(<a name="line.1413"></a>
<span class="sourceLineNo">1414</span>              "These favored nodes were specified but not chosen: " +<a name="line.1414"></a>
<span class="sourceLineNo">1415</span>              favoredSet +<a name="line.1415"></a>
<span class="sourceLineNo">1416</span>              " Specified favored nodes: " + Arrays.toString(favoredNodes));<a name="line.1416"></a>
<span class="sourceLineNo">1417</span><a name="line.1417"></a>
<span class="sourceLineNo">1418</span>        }<a name="line.1418"></a>
<span class="sourceLineNo">1419</span>        return pinnings;<a name="line.1419"></a>
<span class="sourceLineNo">1420</span>      }<a name="line.1420"></a>
<span class="sourceLineNo">1421</span>    }<a name="line.1421"></a>
<span class="sourceLineNo">1422</span><a name="line.1422"></a>
<span class="sourceLineNo">1423</span>    private LocatedBlock locateFollowingBlock(DatanodeInfo[] excludedNodes)  throws IOException {<a name="line.1423"></a>
<span class="sourceLineNo">1424</span>      int retries = dfsClient.getConf().nBlockWriteLocateFollowingRetry;<a name="line.1424"></a>
<span class="sourceLineNo">1425</span>      long sleeptime = 400;<a name="line.1425"></a>
<span class="sourceLineNo">1426</span>      while (true) {<a name="line.1426"></a>
<span class="sourceLineNo">1427</span>        long localstart = Time.monotonicNow();<a name="line.1427"></a>
<span class="sourceLineNo">1428</span>        while (true) {<a name="line.1428"></a>
<span class="sourceLineNo">1429</span>          try {<a name="line.1429"></a>
<span class="sourceLineNo">1430</span>            return dfsClient.namenode.addBlock(src, dfsClient.clientName,<a name="line.1430"></a>
<span class="sourceLineNo">1431</span>                block, excludedNodes, fileId, favoredNodes);<a name="line.1431"></a>
<span class="sourceLineNo">1432</span>          } catch (RemoteException e) {<a name="line.1432"></a>
<span class="sourceLineNo">1433</span>            IOException ue = <a name="line.1433"></a>
<span class="sourceLineNo">1434</span>              e.unwrapRemoteException(FileNotFoundException.class,<a name="line.1434"></a>
<span class="sourceLineNo">1435</span>                                      AccessControlException.class,<a name="line.1435"></a>
<span class="sourceLineNo">1436</span>                                      NSQuotaExceededException.class,<a name="line.1436"></a>
<span class="sourceLineNo">1437</span>                                      DSQuotaExceededException.class,<a name="line.1437"></a>
<span class="sourceLineNo">1438</span>                                      UnresolvedPathException.class);<a name="line.1438"></a>
<span class="sourceLineNo">1439</span>            if (ue != e) { <a name="line.1439"></a>
<span class="sourceLineNo">1440</span>              throw ue; // no need to retry these exceptions<a name="line.1440"></a>
<span class="sourceLineNo">1441</span>            }<a name="line.1441"></a>
<span class="sourceLineNo">1442</span>            <a name="line.1442"></a>
<span class="sourceLineNo">1443</span>            <a name="line.1443"></a>
<span class="sourceLineNo">1444</span>            if (NotReplicatedYetException.class.getName().<a name="line.1444"></a>
<span class="sourceLineNo">1445</span>                equals(e.getClassName())) {<a name="line.1445"></a>
<span class="sourceLineNo">1446</span>              if (retries == 0) { <a name="line.1446"></a>
<span class="sourceLineNo">1447</span>                throw e;<a name="line.1447"></a>
<span class="sourceLineNo">1448</span>              } else {<a name="line.1448"></a>
<span class="sourceLineNo">1449</span>                --retries;<a name="line.1449"></a>
<span class="sourceLineNo">1450</span>                DFSClient.LOG.info("Exception while adding a block", e);<a name="line.1450"></a>
<span class="sourceLineNo">1451</span>                long elapsed = Time.monotonicNow() - localstart;<a name="line.1451"></a>
<span class="sourceLineNo">1452</span>                if (elapsed &gt; 5000) {<a name="line.1452"></a>
<span class="sourceLineNo">1453</span>                  DFSClient.LOG.info("Waiting for replication for "<a name="line.1453"></a>
<span class="sourceLineNo">1454</span>                      + (elapsed / 1000) + " seconds");<a name="line.1454"></a>
<span class="sourceLineNo">1455</span>                }<a name="line.1455"></a>
<span class="sourceLineNo">1456</span>                try {<a name="line.1456"></a>
<span class="sourceLineNo">1457</span>                  DFSClient.LOG.warn("NotReplicatedYetException sleeping " + src<a name="line.1457"></a>
<span class="sourceLineNo">1458</span>                      + " retries left " + retries);<a name="line.1458"></a>
<span class="sourceLineNo">1459</span>                  Thread.sleep(sleeptime);<a name="line.1459"></a>
<span class="sourceLineNo">1460</span>                  sleeptime *= 2;<a name="line.1460"></a>
<span class="sourceLineNo">1461</span>                } catch (InterruptedException ie) {<a name="line.1461"></a>
<span class="sourceLineNo">1462</span>                  DFSClient.LOG.warn("Caught exception ", ie);<a name="line.1462"></a>
<span class="sourceLineNo">1463</span>                }<a name="line.1463"></a>
<span class="sourceLineNo">1464</span>              }<a name="line.1464"></a>
<span class="sourceLineNo">1465</span>            } else {<a name="line.1465"></a>
<span class="sourceLineNo">1466</span>              throw e;<a name="line.1466"></a>
<span class="sourceLineNo">1467</span>            }<a name="line.1467"></a>
<span class="sourceLineNo">1468</span><a name="line.1468"></a>
<span class="sourceLineNo">1469</span>          }<a name="line.1469"></a>
<span class="sourceLineNo">1470</span>        }<a name="line.1470"></a>
<span class="sourceLineNo">1471</span>      } <a name="line.1471"></a>
<span class="sourceLineNo">1472</span>    }<a name="line.1472"></a>
<span class="sourceLineNo">1473</span><a name="line.1473"></a>
<span class="sourceLineNo">1474</span>    ExtendedBlock getBlock() {<a name="line.1474"></a>
<span class="sourceLineNo">1475</span>      return block;<a name="line.1475"></a>
<span class="sourceLineNo">1476</span>    }<a name="line.1476"></a>
<span class="sourceLineNo">1477</span><a name="line.1477"></a>
<span class="sourceLineNo">1478</span>    DatanodeInfo[] getNodes() {<a name="line.1478"></a>
<span class="sourceLineNo">1479</span>      return nodes;<a name="line.1479"></a>
<span class="sourceLineNo">1480</span>    }<a name="line.1480"></a>
<span class="sourceLineNo">1481</span><a name="line.1481"></a>
<span class="sourceLineNo">1482</span>    Token&lt;BlockTokenIdentifier&gt; getBlockToken() {<a name="line.1482"></a>
<span class="sourceLineNo">1483</span>      return accessToken;<a name="line.1483"></a>
<span class="sourceLineNo">1484</span>    }<a name="line.1484"></a>
<span class="sourceLineNo">1485</span><a name="line.1485"></a>
<span class="sourceLineNo">1486</span>    private void setLastException(IOException e) {<a name="line.1486"></a>
<span class="sourceLineNo">1487</span>      lastException.compareAndSet(null, e);<a name="line.1487"></a>
<span class="sourceLineNo">1488</span>    }<a name="line.1488"></a>
<span class="sourceLineNo">1489</span>  }<a name="line.1489"></a>
<span class="sourceLineNo">1490</span><a name="line.1490"></a>
<span class="sourceLineNo">1491</span>  /**<a name="line.1491"></a>
<span class="sourceLineNo">1492</span>   * Create a socket for a write pipeline<a name="line.1492"></a>
<span class="sourceLineNo">1493</span>   * @param first the first datanode <a name="line.1493"></a>
<span class="sourceLineNo">1494</span>   * @param length the pipeline length<a name="line.1494"></a>
<span class="sourceLineNo">1495</span>   * @param client client<a name="line.1495"></a>
<span class="sourceLineNo">1496</span>   * @return the socket connected to the first datanode<a name="line.1496"></a>
<span class="sourceLineNo">1497</span>   */<a name="line.1497"></a>
<span class="sourceLineNo">1498</span>  static Socket createSocketForPipeline(final DatanodeInfo first,<a name="line.1498"></a>
<span class="sourceLineNo">1499</span>      final int length, final DFSClient client) throws IOException {<a name="line.1499"></a>
<span class="sourceLineNo">1500</span>    final String dnAddr = first.getXferAddr(<a name="line.1500"></a>
<span class="sourceLineNo">1501</span>        client.getConf().connectToDnViaHostname);<a name="line.1501"></a>
<span class="sourceLineNo">1502</span>    if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1502"></a>
<span class="sourceLineNo">1503</span>      DFSClient.LOG.debug("Connecting to datanode " + dnAddr);<a name="line.1503"></a>
<span class="sourceLineNo">1504</span>    }<a name="line.1504"></a>
<span class="sourceLineNo">1505</span>    final InetSocketAddress isa = NetUtils.createSocketAddr(dnAddr);<a name="line.1505"></a>
<span class="sourceLineNo">1506</span>    final Socket sock = client.socketFactory.createSocket();<a name="line.1506"></a>
<span class="sourceLineNo">1507</span>    final int timeout = client.getDatanodeReadTimeout(length);<a name="line.1507"></a>
<span class="sourceLineNo">1508</span>    NetUtils.connect(sock, isa, client.getRandomLocalInterfaceAddr(), client.getConf().socketTimeout);<a name="line.1508"></a>
<span class="sourceLineNo">1509</span>    sock.setSoTimeout(timeout);<a name="line.1509"></a>
<span class="sourceLineNo">1510</span>    sock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);<a name="line.1510"></a>
<span class="sourceLineNo">1511</span>    if(DFSClient.LOG.isDebugEnabled()) {<a name="line.1511"></a>
<span class="sourceLineNo">1512</span>      DFSClient.LOG.debug("Send buf size " + sock.getSendBufferSize());<a name="line.1512"></a>
<span class="sourceLineNo">1513</span>    }<a name="line.1513"></a>
<span class="sourceLineNo">1514</span>    return sock;<a name="line.1514"></a>
<span class="sourceLineNo">1515</span>  }<a name="line.1515"></a>
<span class="sourceLineNo">1516</span><a name="line.1516"></a>
<span class="sourceLineNo">1517</span>  @Override<a name="line.1517"></a>
<span class="sourceLineNo">1518</span>  protected void checkClosed() throws IOException {<a name="line.1518"></a>
<span class="sourceLineNo">1519</span>    if (isClosed()) {<a name="line.1519"></a>
<span class="sourceLineNo">1520</span>      IOException e = lastException.get();<a name="line.1520"></a>
<span class="sourceLineNo">1521</span>      throw e != null ? e : new ClosedChannelException();<a name="line.1521"></a>
<span class="sourceLineNo">1522</span>    }<a name="line.1522"></a>
<span class="sourceLineNo">1523</span>  }<a name="line.1523"></a>
<span class="sourceLineNo">1524</span><a name="line.1524"></a>
<span class="sourceLineNo">1525</span>  //<a name="line.1525"></a>
<span class="sourceLineNo">1526</span>  // returns the list of targets, if any, that is being currently used.<a name="line.1526"></a>
<span class="sourceLineNo">1527</span>  //<a name="line.1527"></a>
<span class="sourceLineNo">1528</span>  @VisibleForTesting<a name="line.1528"></a>
<span class="sourceLineNo">1529</span>  public synchronized DatanodeInfo[] getPipeline() {<a name="line.1529"></a>
<span class="sourceLineNo">1530</span>    if (streamer == null) {<a name="line.1530"></a>
<span class="sourceLineNo">1531</span>      return null;<a name="line.1531"></a>
<span class="sourceLineNo">1532</span>    }<a name="line.1532"></a>
<span class="sourceLineNo">1533</span>    DatanodeInfo[] currentNodes = streamer.getNodes();<a name="line.1533"></a>
<span class="sourceLineNo">1534</span>    if (currentNodes == null) {<a name="line.1534"></a>
<span class="sourceLineNo">1535</span>      return null;<a name="line.1535"></a>
<span class="sourceLineNo">1536</span>    }<a name="line.1536"></a>
<span class="sourceLineNo">1537</span>    DatanodeInfo[] value = new DatanodeInfo[currentNodes.length];<a name="line.1537"></a>
<span class="sourceLineNo">1538</span>    for (int i = 0; i &lt; currentNodes.length; i++) {<a name="line.1538"></a>
<span class="sourceLineNo">1539</span>      value[i] = currentNodes[i];<a name="line.1539"></a>
<span class="sourceLineNo">1540</span>    }<a name="line.1540"></a>
<span class="sourceLineNo">1541</span>    return value;<a name="line.1541"></a>
<span class="sourceLineNo">1542</span>  }<a name="line.1542"></a>
<span class="sourceLineNo">1543</span><a name="line.1543"></a>
<span class="sourceLineNo">1544</span>  /** <a name="line.1544"></a>
<span class="sourceLineNo">1545</span>   * @return the object for computing checksum.<a name="line.1545"></a>
<span class="sourceLineNo">1546</span>   *         The type is NULL if checksum is not computed.<a name="line.1546"></a>
<span class="sourceLineNo">1547</span>   */<a name="line.1547"></a>
<span class="sourceLineNo">1548</span>  private static DataChecksum getChecksum4Compute(DataChecksum checksum,<a name="line.1548"></a>
<span class="sourceLineNo">1549</span>      HdfsFileStatus stat) {<a name="line.1549"></a>
<span class="sourceLineNo">1550</span>    if (isLazyPersist(stat) &amp;&amp; stat.getReplication() == 1) {<a name="line.1550"></a>
<span class="sourceLineNo">1551</span>      // do not compute checksum for writing to single replica to memory<a name="line.1551"></a>
<span class="sourceLineNo">1552</span>      return DataChecksum.newDataChecksum(Type.NULL,<a name="line.1552"></a>
<span class="sourceLineNo">1553</span>          checksum.getBytesPerChecksum());<a name="line.1553"></a>
<span class="sourceLineNo">1554</span>    }<a name="line.1554"></a>
<span class="sourceLineNo">1555</span>    return checksum;<a name="line.1555"></a>
<span class="sourceLineNo">1556</span>  }<a name="line.1556"></a>
<span class="sourceLineNo">1557</span> <a name="line.1557"></a>
<span class="sourceLineNo">1558</span>  private DFSOutputStream(DFSClient dfsClient, String src, Progressable progress,<a name="line.1558"></a>
<span class="sourceLineNo">1559</span>      HdfsFileStatus stat, DataChecksum checksum) throws IOException {<a name="line.1559"></a>
<span class="sourceLineNo">1560</span>    super(getChecksum4Compute(checksum, stat));<a name="line.1560"></a>
<span class="sourceLineNo">1561</span>    this.dfsClient = dfsClient;<a name="line.1561"></a>
<span class="sourceLineNo">1562</span>    this.src = src;<a name="line.1562"></a>
<span class="sourceLineNo">1563</span>    this.fileId = stat.getFileId();<a name="line.1563"></a>
<span class="sourceLineNo">1564</span>    this.blockSize = stat.getBlockSize();<a name="line.1564"></a>
<span class="sourceLineNo">1565</span>    this.blockReplication = stat.getReplication();<a name="line.1565"></a>
<span class="sourceLineNo">1566</span>    this.fileEncryptionInfo = stat.getFileEncryptionInfo();<a name="line.1566"></a>
<span class="sourceLineNo">1567</span>    this.progress = progress;<a name="line.1567"></a>
<span class="sourceLineNo">1568</span>    this.cachingStrategy = new AtomicReference&lt;CachingStrategy&gt;(<a name="line.1568"></a>
<span class="sourceLineNo">1569</span>        dfsClient.getDefaultWriteCachingStrategy());<a name="line.1569"></a>
<span class="sourceLineNo">1570</span>    if ((progress != null) &amp;&amp; DFSClient.LOG.isDebugEnabled()) {<a name="line.1570"></a>
<span class="sourceLineNo">1571</span>      DFSClient.LOG.debug(<a name="line.1571"></a>
<span class="sourceLineNo">1572</span>          "Set non-null progress callback on DFSOutputStream " + src);<a name="line.1572"></a>
<span class="sourceLineNo">1573</span>    }<a name="line.1573"></a>
<span class="sourceLineNo">1574</span>    <a name="line.1574"></a>
<span class="sourceLineNo">1575</span>    this.bytesPerChecksum = checksum.getBytesPerChecksum();<a name="line.1575"></a>
<span class="sourceLineNo">1576</span>    if (bytesPerChecksum &lt;= 0) {<a name="line.1576"></a>
<span class="sourceLineNo">1577</span>      throw new HadoopIllegalArgumentException(<a name="line.1577"></a>
<span class="sourceLineNo">1578</span>          "Invalid value: bytesPerChecksum = " + bytesPerChecksum + " &lt;= 0");<a name="line.1578"></a>
<span class="sourceLineNo">1579</span>    }<a name="line.1579"></a>
<span class="sourceLineNo">1580</span>    if (blockSize % bytesPerChecksum != 0) {<a name="line.1580"></a>
<span class="sourceLineNo">1581</span>      throw new HadoopIllegalArgumentException("Invalid values: "<a name="line.1581"></a>
<span class="sourceLineNo">1582</span>          + DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY + " (=" + bytesPerChecksum<a name="line.1582"></a>
<span class="sourceLineNo">1583</span>          + ") must divide block size (=" + blockSize + ").");<a name="line.1583"></a>
<span class="sourceLineNo">1584</span>    }<a name="line.1584"></a>
<span class="sourceLineNo">1585</span>    this.checksum4WriteBlock = checksum;<a name="line.1585"></a>
<span class="sourceLineNo">1586</span><a name="line.1586"></a>
<span class="sourceLineNo">1587</span>    this.dfsclientSlowLogThresholdMs =<a name="line.1587"></a>
<span class="sourceLineNo">1588</span>      dfsClient.getConf().dfsclientSlowIoWarningThresholdMs;<a name="line.1588"></a>
<span class="sourceLineNo">1589</span>    this.byteArrayManager = dfsClient.getClientContext().getByteArrayManager();<a name="line.1589"></a>
<span class="sourceLineNo">1590</span>  }<a name="line.1590"></a>
<span class="sourceLineNo">1591</span><a name="line.1591"></a>
<span class="sourceLineNo">1592</span>  /** Construct a new output stream for creating a file. */<a name="line.1592"></a>
<span class="sourceLineNo">1593</span>  private DFSOutputStream(DFSClient dfsClient, String src, HdfsFileStatus stat,<a name="line.1593"></a>
<span class="sourceLineNo">1594</span>      EnumSet&lt;CreateFlag&gt; flag, Progressable progress,<a name="line.1594"></a>
<span class="sourceLineNo">1595</span>      DataChecksum checksum, String[] favoredNodes) throws IOException {<a name="line.1595"></a>
<span class="sourceLineNo">1596</span>    this(dfsClient, src, progress, stat, checksum);<a name="line.1596"></a>
<span class="sourceLineNo">1597</span>    this.shouldSyncBlock = flag.contains(CreateFlag.SYNC_BLOCK);<a name="line.1597"></a>
<span class="sourceLineNo">1598</span><a name="line.1598"></a>
<span class="sourceLineNo">1599</span>    computePacketChunkSize(dfsClient.getConf().writePacketSize, bytesPerChecksum);<a name="line.1599"></a>
<span class="sourceLineNo">1600</span><a name="line.1600"></a>
<span class="sourceLineNo">1601</span>    streamer = new DataStreamer(stat, null);<a name="line.1601"></a>
<span class="sourceLineNo">1602</span>    if (favoredNodes != null &amp;&amp; favoredNodes.length != 0) {<a name="line.1602"></a>
<span class="sourceLineNo">1603</span>      streamer.setFavoredNodes(favoredNodes);<a name="line.1603"></a>
<span class="sourceLineNo">1604</span>    }<a name="line.1604"></a>
<span class="sourceLineNo">1605</span>  }<a name="line.1605"></a>
<span class="sourceLineNo">1606</span><a name="line.1606"></a>
<span class="sourceLineNo">1607</span>  static DFSOutputStream newStreamForCreate(DFSClient dfsClient, String src,<a name="line.1607"></a>
<span class="sourceLineNo">1608</span>      FsPermission masked, EnumSet&lt;CreateFlag&gt; flag, boolean createParent,<a name="line.1608"></a>
<span class="sourceLineNo">1609</span>      short replication, long blockSize, Progressable progress, int buffersize,<a name="line.1609"></a>
<span class="sourceLineNo">1610</span>      DataChecksum checksum, String[] favoredNodes) throws IOException {<a name="line.1610"></a>
<span class="sourceLineNo">1611</span>    TraceScope scope =<a name="line.1611"></a>
<span class="sourceLineNo">1612</span>        dfsClient.getPathTraceScope("newStreamForCreate", src);<a name="line.1612"></a>
<span class="sourceLineNo">1613</span>    try {<a name="line.1613"></a>
<span class="sourceLineNo">1614</span>      HdfsFileStatus stat = null;<a name="line.1614"></a>
<span class="sourceLineNo">1615</span><a name="line.1615"></a>
<span class="sourceLineNo">1616</span>      // Retry the create if we get a RetryStartFileException up to a maximum<a name="line.1616"></a>
<span class="sourceLineNo">1617</span>      // number of times<a name="line.1617"></a>
<span class="sourceLineNo">1618</span>      boolean shouldRetry = true;<a name="line.1618"></a>
<span class="sourceLineNo">1619</span>      int retryCount = CREATE_RETRY_COUNT;<a name="line.1619"></a>
<span class="sourceLineNo">1620</span>      while (shouldRetry) {<a name="line.1620"></a>
<span class="sourceLineNo">1621</span>        shouldRetry = false;<a name="line.1621"></a>
<span class="sourceLineNo">1622</span>        try {<a name="line.1622"></a>
<span class="sourceLineNo">1623</span>          stat = dfsClient.namenode.create(src, masked, dfsClient.clientName,<a name="line.1623"></a>
<span class="sourceLineNo">1624</span>              new EnumSetWritable&lt;CreateFlag&gt;(flag), createParent, replication,<a name="line.1624"></a>
<span class="sourceLineNo">1625</span>              blockSize, SUPPORTED_CRYPTO_VERSIONS);<a name="line.1625"></a>
<span class="sourceLineNo">1626</span>          break;<a name="line.1626"></a>
<span class="sourceLineNo">1627</span>        } catch (RemoteException re) {<a name="line.1627"></a>
<span class="sourceLineNo">1628</span>          IOException e = re.unwrapRemoteException(<a name="line.1628"></a>
<span class="sourceLineNo">1629</span>              AccessControlException.class,<a name="line.1629"></a>
<span class="sourceLineNo">1630</span>              DSQuotaExceededException.class,<a name="line.1630"></a>
<span class="sourceLineNo">1631</span>              FileAlreadyExistsException.class,<a name="line.1631"></a>
<span class="sourceLineNo">1632</span>              FileNotFoundException.class,<a name="line.1632"></a>
<span class="sourceLineNo">1633</span>              ParentNotDirectoryException.class,<a name="line.1633"></a>
<span class="sourceLineNo">1634</span>              NSQuotaExceededException.class,<a name="line.1634"></a>
<span class="sourceLineNo">1635</span>              RetryStartFileException.class,<a name="line.1635"></a>
<span class="sourceLineNo">1636</span>              SafeModeException.class,<a name="line.1636"></a>
<span class="sourceLineNo">1637</span>              UnresolvedPathException.class,<a name="line.1637"></a>
<span class="sourceLineNo">1638</span>              SnapshotAccessControlException.class,<a name="line.1638"></a>
<span class="sourceLineNo">1639</span>              UnknownCryptoProtocolVersionException.class);<a name="line.1639"></a>
<span class="sourceLineNo">1640</span>          if (e instanceof RetryStartFileException) {<a name="line.1640"></a>
<span class="sourceLineNo">1641</span>            if (retryCount &gt; 0) {<a name="line.1641"></a>
<span class="sourceLineNo">1642</span>              shouldRetry = true;<a name="line.1642"></a>
<span class="sourceLineNo">1643</span>              retryCount--;<a name="line.1643"></a>
<span class="sourceLineNo">1644</span>            } else {<a name="line.1644"></a>
<span class="sourceLineNo">1645</span>              throw new IOException("Too many retries because of encryption" +<a name="line.1645"></a>
<span class="sourceLineNo">1646</span>                  " zone operations", e);<a name="line.1646"></a>
<span class="sourceLineNo">1647</span>            }<a name="line.1647"></a>
<span class="sourceLineNo">1648</span>          } else {<a name="line.1648"></a>
<span class="sourceLineNo">1649</span>            throw e;<a name="line.1649"></a>
<span class="sourceLineNo">1650</span>          }<a name="line.1650"></a>
<span class="sourceLineNo">1651</span>        }<a name="line.1651"></a>
<span class="sourceLineNo">1652</span>      }<a name="line.1652"></a>
<span class="sourceLineNo">1653</span>      Preconditions.checkNotNull(stat, "HdfsFileStatus should not be null!");<a name="line.1653"></a>
<span class="sourceLineNo">1654</span>      final DFSOutputStream out = new DFSOutputStream(dfsClient, src, stat,<a name="line.1654"></a>
<span class="sourceLineNo">1655</span>          flag, progress, checksum, favoredNodes);<a name="line.1655"></a>
<span class="sourceLineNo">1656</span>      out.start();<a name="line.1656"></a>
<span class="sourceLineNo">1657</span>      return out;<a name="line.1657"></a>
<span class="sourceLineNo">1658</span>    } finally {<a name="line.1658"></a>
<span class="sourceLineNo">1659</span>      scope.close();<a name="line.1659"></a>
<span class="sourceLineNo">1660</span>    }<a name="line.1660"></a>
<span class="sourceLineNo">1661</span>  }<a name="line.1661"></a>
<span class="sourceLineNo">1662</span><a name="line.1662"></a>
<span class="sourceLineNo">1663</span>  /** Construct a new output stream for append. */<a name="line.1663"></a>
<span class="sourceLineNo">1664</span>  private DFSOutputStream(DFSClient dfsClient, String src,<a name="line.1664"></a>
<span class="sourceLineNo">1665</span>      EnumSet&lt;CreateFlag&gt; flags, Progressable progress, LocatedBlock lastBlock,<a name="line.1665"></a>
<span class="sourceLineNo">1666</span>      HdfsFileStatus stat, DataChecksum checksum) throws IOException {<a name="line.1666"></a>
<span class="sourceLineNo">1667</span>    this(dfsClient, src, progress, stat, checksum);<a name="line.1667"></a>
<span class="sourceLineNo">1668</span>    initialFileSize = stat.getLen(); // length of file when opened<a name="line.1668"></a>
<span class="sourceLineNo">1669</span>    this.shouldSyncBlock = flags.contains(CreateFlag.SYNC_BLOCK);<a name="line.1669"></a>
<span class="sourceLineNo">1670</span><a name="line.1670"></a>
<span class="sourceLineNo">1671</span>    boolean toNewBlock = flags.contains(CreateFlag.NEW_BLOCK);<a name="line.1671"></a>
<span class="sourceLineNo">1672</span><a name="line.1672"></a>
<span class="sourceLineNo">1673</span>    // The last partial block of the file has to be filled.<a name="line.1673"></a>
<span class="sourceLineNo">1674</span>    if (!toNewBlock &amp;&amp; lastBlock != null) {<a name="line.1674"></a>
<span class="sourceLineNo">1675</span>      // indicate that we are appending to an existing block<a name="line.1675"></a>
<span class="sourceLineNo">1676</span>      bytesCurBlock = lastBlock.getBlockSize();<a name="line.1676"></a>
<span class="sourceLineNo">1677</span>      streamer = new DataStreamer(lastBlock, stat, bytesPerChecksum);<a name="line.1677"></a>
<span class="sourceLineNo">1678</span>    } else {<a name="line.1678"></a>
<span class="sourceLineNo">1679</span>      computePacketChunkSize(dfsClient.getConf().writePacketSize,<a name="line.1679"></a>
<span class="sourceLineNo">1680</span>          bytesPerChecksum);<a name="line.1680"></a>
<span class="sourceLineNo">1681</span>      streamer = new DataStreamer(stat,<a name="line.1681"></a>
<span class="sourceLineNo">1682</span>          lastBlock != null ? lastBlock.getBlock() : null);<a name="line.1682"></a>
<span class="sourceLineNo">1683</span>    }<a name="line.1683"></a>
<span class="sourceLineNo">1684</span>    this.fileEncryptionInfo = stat.getFileEncryptionInfo();<a name="line.1684"></a>
<span class="sourceLineNo">1685</span>  }<a name="line.1685"></a>
<span class="sourceLineNo">1686</span><a name="line.1686"></a>
<span class="sourceLineNo">1687</span>  static DFSOutputStream newStreamForAppend(DFSClient dfsClient, String src,<a name="line.1687"></a>
<span class="sourceLineNo">1688</span>      EnumSet&lt;CreateFlag&gt; flags, int bufferSize, Progressable progress,<a name="line.1688"></a>
<span class="sourceLineNo">1689</span>      LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum,<a name="line.1689"></a>
<span class="sourceLineNo">1690</span>      String[] favoredNodes) throws IOException {<a name="line.1690"></a>
<span class="sourceLineNo">1691</span>    TraceScope scope =<a name="line.1691"></a>
<span class="sourceLineNo">1692</span>        dfsClient.getPathTraceScope("newStreamForAppend", src);<a name="line.1692"></a>
<span class="sourceLineNo">1693</span>    try {<a name="line.1693"></a>
<span class="sourceLineNo">1694</span>      final DFSOutputStream out = new DFSOutputStream(dfsClient, src, flags,<a name="line.1694"></a>
<span class="sourceLineNo">1695</span>          progress, lastBlock, stat, checksum);<a name="line.1695"></a>
<span class="sourceLineNo">1696</span>      if (favoredNodes != null &amp;&amp; favoredNodes.length != 0) {<a name="line.1696"></a>
<span class="sourceLineNo">1697</span>        out.streamer.setFavoredNodes(favoredNodes);<a name="line.1697"></a>
<span class="sourceLineNo">1698</span>      }<a name="line.1698"></a>
<span class="sourceLineNo">1699</span>      out.start();<a name="line.1699"></a>
<span class="sourceLineNo">1700</span>      return out;<a name="line.1700"></a>
<span class="sourceLineNo">1701</span>    } finally {<a name="line.1701"></a>
<span class="sourceLineNo">1702</span>      scope.close();<a name="line.1702"></a>
<span class="sourceLineNo">1703</span>    }<a name="line.1703"></a>
<span class="sourceLineNo">1704</span>  }<a name="line.1704"></a>
<span class="sourceLineNo">1705</span>  <a name="line.1705"></a>
<span class="sourceLineNo">1706</span>  private static boolean isLazyPersist(HdfsFileStatus stat) {<a name="line.1706"></a>
<span class="sourceLineNo">1707</span>    final BlockStoragePolicy p = blockStoragePolicySuite.getPolicy(<a name="line.1707"></a>
<span class="sourceLineNo">1708</span>        HdfsConstants.MEMORY_STORAGE_POLICY_NAME);<a name="line.1708"></a>
<span class="sourceLineNo">1709</span>    return p != null &amp;&amp; stat.getStoragePolicy() == p.getId();<a name="line.1709"></a>
<span class="sourceLineNo">1710</span>  }<a name="line.1710"></a>
<span class="sourceLineNo">1711</span><a name="line.1711"></a>
<span class="sourceLineNo">1712</span>  private void computePacketChunkSize(int psize, int csize) {<a name="line.1712"></a>
<span class="sourceLineNo">1713</span>    final int bodySize = psize - PacketHeader.PKT_MAX_HEADER_LEN;<a name="line.1713"></a>
<span class="sourceLineNo">1714</span>    final int chunkSize = csize + getChecksumSize();<a name="line.1714"></a>
<span class="sourceLineNo">1715</span>    chunksPerPacket = Math.max(bodySize/chunkSize, 1);<a name="line.1715"></a>
<span class="sourceLineNo">1716</span>    packetSize = chunkSize*chunksPerPacket;<a name="line.1716"></a>
<span class="sourceLineNo">1717</span>    if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1717"></a>
<span class="sourceLineNo">1718</span>      DFSClient.LOG.debug("computePacketChunkSize: src=" + src +<a name="line.1718"></a>
<span class="sourceLineNo">1719</span>                ", chunkSize=" + chunkSize +<a name="line.1719"></a>
<span class="sourceLineNo">1720</span>                ", chunksPerPacket=" + chunksPerPacket +<a name="line.1720"></a>
<span class="sourceLineNo">1721</span>                ", packetSize=" + packetSize);<a name="line.1721"></a>
<span class="sourceLineNo">1722</span>    }<a name="line.1722"></a>
<span class="sourceLineNo">1723</span>  }<a name="line.1723"></a>
<span class="sourceLineNo">1724</span><a name="line.1724"></a>
<span class="sourceLineNo">1725</span>  private void queueCurrentPacket() {<a name="line.1725"></a>
<span class="sourceLineNo">1726</span>    synchronized (dataQueue) {<a name="line.1726"></a>
<span class="sourceLineNo">1727</span>      if (currentPacket == null) return;<a name="line.1727"></a>
<span class="sourceLineNo">1728</span>      currentPacket.addTraceParent(Trace.currentSpan());<a name="line.1728"></a>
<span class="sourceLineNo">1729</span>      dataQueue.addLast(currentPacket);<a name="line.1729"></a>
<span class="sourceLineNo">1730</span>      lastQueuedSeqno = currentPacket.getSeqno();<a name="line.1730"></a>
<span class="sourceLineNo">1731</span>      if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1731"></a>
<span class="sourceLineNo">1732</span>        DFSClient.LOG.debug("Queued packet " + currentPacket.getSeqno());<a name="line.1732"></a>
<span class="sourceLineNo">1733</span>      }<a name="line.1733"></a>
<span class="sourceLineNo">1734</span>      currentPacket = null;<a name="line.1734"></a>
<span class="sourceLineNo">1735</span>      dataQueue.notifyAll();<a name="line.1735"></a>
<span class="sourceLineNo">1736</span>    }<a name="line.1736"></a>
<span class="sourceLineNo">1737</span>  }<a name="line.1737"></a>
<span class="sourceLineNo">1738</span><a name="line.1738"></a>
<span class="sourceLineNo">1739</span>  private void waitAndQueueCurrentPacket() throws IOException {<a name="line.1739"></a>
<span class="sourceLineNo">1740</span>    synchronized (dataQueue) {<a name="line.1740"></a>
<span class="sourceLineNo">1741</span>      try {<a name="line.1741"></a>
<span class="sourceLineNo">1742</span>      // If queue is full, then wait till we have enough space<a name="line.1742"></a>
<span class="sourceLineNo">1743</span>        boolean firstWait = true;<a name="line.1743"></a>
<span class="sourceLineNo">1744</span>        try {<a name="line.1744"></a>
<span class="sourceLineNo">1745</span>          while (!isClosed() &amp;&amp; dataQueue.size() + ackQueue.size() &gt;<a name="line.1745"></a>
<span class="sourceLineNo">1746</span>              dfsClient.getConf().writeMaxPackets) {<a name="line.1746"></a>
<span class="sourceLineNo">1747</span>            if (firstWait) {<a name="line.1747"></a>
<span class="sourceLineNo">1748</span>              Span span = Trace.currentSpan();<a name="line.1748"></a>
<span class="sourceLineNo">1749</span>              if (span != null) {<a name="line.1749"></a>
<span class="sourceLineNo">1750</span>                span.addTimelineAnnotation("dataQueue.wait");<a name="line.1750"></a>
<span class="sourceLineNo">1751</span>              }<a name="line.1751"></a>
<span class="sourceLineNo">1752</span>              firstWait = false;<a name="line.1752"></a>
<span class="sourceLineNo">1753</span>            }<a name="line.1753"></a>
<span class="sourceLineNo">1754</span>            try {<a name="line.1754"></a>
<span class="sourceLineNo">1755</span>              dataQueue.wait();<a name="line.1755"></a>
<span class="sourceLineNo">1756</span>            } catch (InterruptedException e) {<a name="line.1756"></a>
<span class="sourceLineNo">1757</span>              // If we get interrupted while waiting to queue data, we still need to get rid<a name="line.1757"></a>
<span class="sourceLineNo">1758</span>              // of the current packet. This is because we have an invariant that if<a name="line.1758"></a>
<span class="sourceLineNo">1759</span>              // currentPacket gets full, it will get queued before the next writeChunk.<a name="line.1759"></a>
<span class="sourceLineNo">1760</span>              //<a name="line.1760"></a>
<span class="sourceLineNo">1761</span>              // Rather than wait around for space in the queue, we should instead try to<a name="line.1761"></a>
<span class="sourceLineNo">1762</span>              // return to the caller as soon as possible, even though we slightly overrun<a name="line.1762"></a>
<span class="sourceLineNo">1763</span>              // the MAX_PACKETS length.<a name="line.1763"></a>
<span class="sourceLineNo">1764</span>              Thread.currentThread().interrupt();<a name="line.1764"></a>
<span class="sourceLineNo">1765</span>              break;<a name="line.1765"></a>
<span class="sourceLineNo">1766</span>            }<a name="line.1766"></a>
<span class="sourceLineNo">1767</span>          }<a name="line.1767"></a>
<span class="sourceLineNo">1768</span>        } finally {<a name="line.1768"></a>
<span class="sourceLineNo">1769</span>          Span span = Trace.currentSpan();<a name="line.1769"></a>
<span class="sourceLineNo">1770</span>          if ((span != null) &amp;&amp; (!firstWait)) {<a name="line.1770"></a>
<span class="sourceLineNo">1771</span>            span.addTimelineAnnotation("end.wait");<a name="line.1771"></a>
<span class="sourceLineNo">1772</span>          }<a name="line.1772"></a>
<span class="sourceLineNo">1773</span>        }<a name="line.1773"></a>
<span class="sourceLineNo">1774</span>        checkClosed();<a name="line.1774"></a>
<span class="sourceLineNo">1775</span>        queueCurrentPacket();<a name="line.1775"></a>
<span class="sourceLineNo">1776</span>      } catch (ClosedChannelException e) {<a name="line.1776"></a>
<span class="sourceLineNo">1777</span>      }<a name="line.1777"></a>
<span class="sourceLineNo">1778</span>    }<a name="line.1778"></a>
<span class="sourceLineNo">1779</span>  }<a name="line.1779"></a>
<span class="sourceLineNo">1780</span><a name="line.1780"></a>
<span class="sourceLineNo">1781</span>  // @see FSOutputSummer#writeChunk()<a name="line.1781"></a>
<span class="sourceLineNo">1782</span>  @Override<a name="line.1782"></a>
<span class="sourceLineNo">1783</span>  protected synchronized void writeChunk(byte[] b, int offset, int len,<a name="line.1783"></a>
<span class="sourceLineNo">1784</span>      byte[] checksum, int ckoff, int cklen) throws IOException {<a name="line.1784"></a>
<span class="sourceLineNo">1785</span>    TraceScope scope =<a name="line.1785"></a>
<span class="sourceLineNo">1786</span>        dfsClient.getPathTraceScope("DFSOutputStream#writeChunk", src);<a name="line.1786"></a>
<span class="sourceLineNo">1787</span>    try {<a name="line.1787"></a>
<span class="sourceLineNo">1788</span>      writeChunkImpl(b, offset, len, checksum, ckoff, cklen);<a name="line.1788"></a>
<span class="sourceLineNo">1789</span>    } finally {<a name="line.1789"></a>
<span class="sourceLineNo">1790</span>      scope.close();<a name="line.1790"></a>
<span class="sourceLineNo">1791</span>    }<a name="line.1791"></a>
<span class="sourceLineNo">1792</span>  }<a name="line.1792"></a>
<span class="sourceLineNo">1793</span><a name="line.1793"></a>
<span class="sourceLineNo">1794</span>  private synchronized void writeChunkImpl(byte[] b, int offset, int len,<a name="line.1794"></a>
<span class="sourceLineNo">1795</span>          byte[] checksum, int ckoff, int cklen) throws IOException {<a name="line.1795"></a>
<span class="sourceLineNo">1796</span>    dfsClient.checkOpen();<a name="line.1796"></a>
<span class="sourceLineNo">1797</span>    checkClosed();<a name="line.1797"></a>
<span class="sourceLineNo">1798</span><a name="line.1798"></a>
<span class="sourceLineNo">1799</span>    if (len &gt; bytesPerChecksum) {<a name="line.1799"></a>
<span class="sourceLineNo">1800</span>      throw new IOException("writeChunk() buffer size is " + len +<a name="line.1800"></a>
<span class="sourceLineNo">1801</span>                            " is larger than supported  bytesPerChecksum " +<a name="line.1801"></a>
<span class="sourceLineNo">1802</span>                            bytesPerChecksum);<a name="line.1802"></a>
<span class="sourceLineNo">1803</span>    }<a name="line.1803"></a>
<span class="sourceLineNo">1804</span>    if (cklen != 0 &amp;&amp; cklen != getChecksumSize()) {<a name="line.1804"></a>
<span class="sourceLineNo">1805</span>      throw new IOException("writeChunk() checksum size is supposed to be " +<a name="line.1805"></a>
<span class="sourceLineNo">1806</span>                            getChecksumSize() + " but found to be " + cklen);<a name="line.1806"></a>
<span class="sourceLineNo">1807</span>    }<a name="line.1807"></a>
<span class="sourceLineNo">1808</span><a name="line.1808"></a>
<span class="sourceLineNo">1809</span>    if (currentPacket == null) {<a name="line.1809"></a>
<span class="sourceLineNo">1810</span>      currentPacket = createPacket(packetSize, chunksPerPacket, <a name="line.1810"></a>
<span class="sourceLineNo">1811</span>          bytesCurBlock, currentSeqno++, false);<a name="line.1811"></a>
<span class="sourceLineNo">1812</span>      if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1812"></a>
<span class="sourceLineNo">1813</span>        DFSClient.LOG.debug("DFSClient writeChunk allocating new packet seqno=" + <a name="line.1813"></a>
<span class="sourceLineNo">1814</span>            currentPacket.getSeqno() +<a name="line.1814"></a>
<span class="sourceLineNo">1815</span>            ", src=" + src +<a name="line.1815"></a>
<span class="sourceLineNo">1816</span>            ", packetSize=" + packetSize +<a name="line.1816"></a>
<span class="sourceLineNo">1817</span>            ", chunksPerPacket=" + chunksPerPacket +<a name="line.1817"></a>
<span class="sourceLineNo">1818</span>            ", bytesCurBlock=" + bytesCurBlock);<a name="line.1818"></a>
<span class="sourceLineNo">1819</span>      }<a name="line.1819"></a>
<span class="sourceLineNo">1820</span>    }<a name="line.1820"></a>
<span class="sourceLineNo">1821</span><a name="line.1821"></a>
<span class="sourceLineNo">1822</span>    currentPacket.writeChecksum(checksum, ckoff, cklen);<a name="line.1822"></a>
<span class="sourceLineNo">1823</span>    currentPacket.writeData(b, offset, len);<a name="line.1823"></a>
<span class="sourceLineNo">1824</span>    currentPacket.incNumChunks();<a name="line.1824"></a>
<span class="sourceLineNo">1825</span>    bytesCurBlock += len;<a name="line.1825"></a>
<span class="sourceLineNo">1826</span><a name="line.1826"></a>
<span class="sourceLineNo">1827</span>    // If packet is full, enqueue it for transmission<a name="line.1827"></a>
<span class="sourceLineNo">1828</span>    //<a name="line.1828"></a>
<span class="sourceLineNo">1829</span>    if (currentPacket.getNumChunks() == currentPacket.getMaxChunks() ||<a name="line.1829"></a>
<span class="sourceLineNo">1830</span>        bytesCurBlock == blockSize) {<a name="line.1830"></a>
<span class="sourceLineNo">1831</span>      if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1831"></a>
<span class="sourceLineNo">1832</span>        DFSClient.LOG.debug("DFSClient writeChunk packet full seqno=" +<a name="line.1832"></a>
<span class="sourceLineNo">1833</span>            currentPacket.getSeqno() +<a name="line.1833"></a>
<span class="sourceLineNo">1834</span>            ", src=" + src +<a name="line.1834"></a>
<span class="sourceLineNo">1835</span>            ", bytesCurBlock=" + bytesCurBlock +<a name="line.1835"></a>
<span class="sourceLineNo">1836</span>            ", blockSize=" + blockSize +<a name="line.1836"></a>
<span class="sourceLineNo">1837</span>            ", appendChunk=" + appendChunk);<a name="line.1837"></a>
<span class="sourceLineNo">1838</span>      }<a name="line.1838"></a>
<span class="sourceLineNo">1839</span>      waitAndQueueCurrentPacket();<a name="line.1839"></a>
<span class="sourceLineNo">1840</span><a name="line.1840"></a>
<span class="sourceLineNo">1841</span>      // If the reopened file did not end at chunk boundary and the above<a name="line.1841"></a>
<span class="sourceLineNo">1842</span>      // write filled up its partial chunk. Tell the summer to generate full <a name="line.1842"></a>
<span class="sourceLineNo">1843</span>      // crc chunks from now on.<a name="line.1843"></a>
<span class="sourceLineNo">1844</span>      if (appendChunk &amp;&amp; bytesCurBlock%bytesPerChecksum == 0) {<a name="line.1844"></a>
<span class="sourceLineNo">1845</span>        appendChunk = false;<a name="line.1845"></a>
<span class="sourceLineNo">1846</span>        resetChecksumBufSize();<a name="line.1846"></a>
<span class="sourceLineNo">1847</span>      }<a name="line.1847"></a>
<span class="sourceLineNo">1848</span><a name="line.1848"></a>
<span class="sourceLineNo">1849</span>      if (!appendChunk) {<a name="line.1849"></a>
<span class="sourceLineNo">1850</span>        int psize = Math.min((int)(blockSize-bytesCurBlock), dfsClient.getConf().writePacketSize);<a name="line.1850"></a>
<span class="sourceLineNo">1851</span>        computePacketChunkSize(psize, bytesPerChecksum);<a name="line.1851"></a>
<span class="sourceLineNo">1852</span>      }<a name="line.1852"></a>
<span class="sourceLineNo">1853</span>      //<a name="line.1853"></a>
<span class="sourceLineNo">1854</span>      // if encountering a block boundary, send an empty packet to <a name="line.1854"></a>
<span class="sourceLineNo">1855</span>      // indicate the end of block and reset bytesCurBlock.<a name="line.1855"></a>
<span class="sourceLineNo">1856</span>      //<a name="line.1856"></a>
<span class="sourceLineNo">1857</span>      if (bytesCurBlock == blockSize) {<a name="line.1857"></a>
<span class="sourceLineNo">1858</span>        currentPacket = createPacket(0, 0, bytesCurBlock, currentSeqno++, true);<a name="line.1858"></a>
<span class="sourceLineNo">1859</span>        currentPacket.setSyncBlock(shouldSyncBlock);<a name="line.1859"></a>
<span class="sourceLineNo">1860</span>        waitAndQueueCurrentPacket();<a name="line.1860"></a>
<span class="sourceLineNo">1861</span>        bytesCurBlock = 0;<a name="line.1861"></a>
<span class="sourceLineNo">1862</span>        lastFlushOffset = 0;<a name="line.1862"></a>
<span class="sourceLineNo">1863</span>      }<a name="line.1863"></a>
<span class="sourceLineNo">1864</span>    }<a name="line.1864"></a>
<span class="sourceLineNo">1865</span>  }<a name="line.1865"></a>
<span class="sourceLineNo">1866</span><a name="line.1866"></a>
<span class="sourceLineNo">1867</span>  @Deprecated<a name="line.1867"></a>
<span class="sourceLineNo">1868</span>  public void sync() throws IOException {<a name="line.1868"></a>
<span class="sourceLineNo">1869</span>    hflush();<a name="line.1869"></a>
<span class="sourceLineNo">1870</span>  }<a name="line.1870"></a>
<span class="sourceLineNo">1871</span>  <a name="line.1871"></a>
<span class="sourceLineNo">1872</span>  /**<a name="line.1872"></a>
<span class="sourceLineNo">1873</span>   * Flushes out to all replicas of the block. The data is in the buffers<a name="line.1873"></a>
<span class="sourceLineNo">1874</span>   * of the DNs but not necessarily in the DN's OS buffers.<a name="line.1874"></a>
<span class="sourceLineNo">1875</span>   *<a name="line.1875"></a>
<span class="sourceLineNo">1876</span>   * It is a synchronous operation. When it returns,<a name="line.1876"></a>
<span class="sourceLineNo">1877</span>   * it guarantees that flushed data become visible to new readers. <a name="line.1877"></a>
<span class="sourceLineNo">1878</span>   * It is not guaranteed that data has been flushed to <a name="line.1878"></a>
<span class="sourceLineNo">1879</span>   * persistent store on the datanode. <a name="line.1879"></a>
<span class="sourceLineNo">1880</span>   * Block allocations are persisted on namenode.<a name="line.1880"></a>
<span class="sourceLineNo">1881</span>   */<a name="line.1881"></a>
<span class="sourceLineNo">1882</span>  @Override<a name="line.1882"></a>
<span class="sourceLineNo">1883</span>  public void hflush() throws IOException {<a name="line.1883"></a>
<span class="sourceLineNo">1884</span>    TraceScope scope =<a name="line.1884"></a>
<span class="sourceLineNo">1885</span>        dfsClient.getPathTraceScope("hflush", src);<a name="line.1885"></a>
<span class="sourceLineNo">1886</span>    try {<a name="line.1886"></a>
<span class="sourceLineNo">1887</span>      flushOrSync(false, EnumSet.noneOf(SyncFlag.class));<a name="line.1887"></a>
<span class="sourceLineNo">1888</span>    } finally {<a name="line.1888"></a>
<span class="sourceLineNo">1889</span>      scope.close();<a name="line.1889"></a>
<span class="sourceLineNo">1890</span>    }<a name="line.1890"></a>
<span class="sourceLineNo">1891</span>  }<a name="line.1891"></a>
<span class="sourceLineNo">1892</span><a name="line.1892"></a>
<span class="sourceLineNo">1893</span>  @Override<a name="line.1893"></a>
<span class="sourceLineNo">1894</span>  public void hsync() throws IOException {<a name="line.1894"></a>
<span class="sourceLineNo">1895</span>    TraceScope scope =<a name="line.1895"></a>
<span class="sourceLineNo">1896</span>        dfsClient.getPathTraceScope("hsync", src);<a name="line.1896"></a>
<span class="sourceLineNo">1897</span>    try {<a name="line.1897"></a>
<span class="sourceLineNo">1898</span>      flushOrSync(true, EnumSet.noneOf(SyncFlag.class));<a name="line.1898"></a>
<span class="sourceLineNo">1899</span>    } finally {<a name="line.1899"></a>
<span class="sourceLineNo">1900</span>      scope.close();<a name="line.1900"></a>
<span class="sourceLineNo">1901</span>    }<a name="line.1901"></a>
<span class="sourceLineNo">1902</span>  }<a name="line.1902"></a>
<span class="sourceLineNo">1903</span>  <a name="line.1903"></a>
<span class="sourceLineNo">1904</span>  /**<a name="line.1904"></a>
<span class="sourceLineNo">1905</span>   * The expected semantics is all data have flushed out to all replicas <a name="line.1905"></a>
<span class="sourceLineNo">1906</span>   * and all replicas have done posix fsync equivalent - ie the OS has <a name="line.1906"></a>
<span class="sourceLineNo">1907</span>   * flushed it to the disk device (but the disk may have it in its cache).<a name="line.1907"></a>
<span class="sourceLineNo">1908</span>   * <a name="line.1908"></a>
<span class="sourceLineNo">1909</span>   * Note that only the current block is flushed to the disk device.<a name="line.1909"></a>
<span class="sourceLineNo">1910</span>   * To guarantee durable sync across block boundaries the stream should<a name="line.1910"></a>
<span class="sourceLineNo">1911</span>   * be created with {@link CreateFlag#SYNC_BLOCK}.<a name="line.1911"></a>
<span class="sourceLineNo">1912</span>   * <a name="line.1912"></a>
<span class="sourceLineNo">1913</span>   * @param syncFlags<a name="line.1913"></a>
<span class="sourceLineNo">1914</span>   *          Indicate the semantic of the sync. Currently used to specify<a name="line.1914"></a>
<span class="sourceLineNo">1915</span>   *          whether or not to update the block length in NameNode.<a name="line.1915"></a>
<span class="sourceLineNo">1916</span>   */<a name="line.1916"></a>
<span class="sourceLineNo">1917</span>  public void hsync(EnumSet&lt;SyncFlag&gt; syncFlags) throws IOException {<a name="line.1917"></a>
<span class="sourceLineNo">1918</span>    TraceScope scope =<a name="line.1918"></a>
<span class="sourceLineNo">1919</span>        dfsClient.getPathTraceScope("hsync", src);<a name="line.1919"></a>
<span class="sourceLineNo">1920</span>    try {<a name="line.1920"></a>
<span class="sourceLineNo">1921</span>      flushOrSync(true, syncFlags);<a name="line.1921"></a>
<span class="sourceLineNo">1922</span>    } finally {<a name="line.1922"></a>
<span class="sourceLineNo">1923</span>      scope.close();<a name="line.1923"></a>
<span class="sourceLineNo">1924</span>    }<a name="line.1924"></a>
<span class="sourceLineNo">1925</span>  }<a name="line.1925"></a>
<span class="sourceLineNo">1926</span><a name="line.1926"></a>
<span class="sourceLineNo">1927</span>  /**<a name="line.1927"></a>
<span class="sourceLineNo">1928</span>   * Flush/Sync buffered data to DataNodes.<a name="line.1928"></a>
<span class="sourceLineNo">1929</span>   * <a name="line.1929"></a>
<span class="sourceLineNo">1930</span>   * @param isSync<a name="line.1930"></a>
<span class="sourceLineNo">1931</span>   *          Whether or not to require all replicas to flush data to the disk<a name="line.1931"></a>
<span class="sourceLineNo">1932</span>   *          device<a name="line.1932"></a>
<span class="sourceLineNo">1933</span>   * @param syncFlags<a name="line.1933"></a>
<span class="sourceLineNo">1934</span>   *          Indicate extra detailed semantic of the flush/sync. Currently<a name="line.1934"></a>
<span class="sourceLineNo">1935</span>   *          mainly used to specify whether or not to update the file length in<a name="line.1935"></a>
<span class="sourceLineNo">1936</span>   *          the NameNode<a name="line.1936"></a>
<span class="sourceLineNo">1937</span>   * @throws IOException<a name="line.1937"></a>
<span class="sourceLineNo">1938</span>   */<a name="line.1938"></a>
<span class="sourceLineNo">1939</span>  private void flushOrSync(boolean isSync, EnumSet&lt;SyncFlag&gt; syncFlags)<a name="line.1939"></a>
<span class="sourceLineNo">1940</span>      throws IOException {<a name="line.1940"></a>
<span class="sourceLineNo">1941</span>    dfsClient.checkOpen();<a name="line.1941"></a>
<span class="sourceLineNo">1942</span>    checkClosed();<a name="line.1942"></a>
<span class="sourceLineNo">1943</span>    try {<a name="line.1943"></a>
<span class="sourceLineNo">1944</span>      long toWaitFor;<a name="line.1944"></a>
<span class="sourceLineNo">1945</span>      long lastBlockLength = -1L;<a name="line.1945"></a>
<span class="sourceLineNo">1946</span>      boolean updateLength = syncFlags.contains(SyncFlag.UPDATE_LENGTH);<a name="line.1946"></a>
<span class="sourceLineNo">1947</span>      boolean endBlock = syncFlags.contains(SyncFlag.END_BLOCK);<a name="line.1947"></a>
<span class="sourceLineNo">1948</span>      synchronized (this) {<a name="line.1948"></a>
<span class="sourceLineNo">1949</span>        // flush checksum buffer, but keep checksum buffer intact if we do not<a name="line.1949"></a>
<span class="sourceLineNo">1950</span>        // need to end the current block<a name="line.1950"></a>
<span class="sourceLineNo">1951</span>        int numKept = flushBuffer(!endBlock, true);<a name="line.1951"></a>
<span class="sourceLineNo">1952</span>        // bytesCurBlock potentially incremented if there was buffered data<a name="line.1952"></a>
<span class="sourceLineNo">1953</span><a name="line.1953"></a>
<span class="sourceLineNo">1954</span>        if (DFSClient.LOG.isDebugEnabled()) {<a name="line.1954"></a>
<span class="sourceLineNo">1955</span>          DFSClient.LOG.debug("DFSClient flush():"<a name="line.1955"></a>
<span class="sourceLineNo">1956</span>              + " bytesCurBlock=" + bytesCurBlock<a name="line.1956"></a>
<span class="sourceLineNo">1957</span>              + " lastFlushOffset=" + lastFlushOffset<a name="line.1957"></a>
<span class="sourceLineNo">1958</span>              + " createNewBlock=" + endBlock);<a name="line.1958"></a>
<span class="sourceLineNo">1959</span>        }<a name="line.1959"></a>
<span class="sourceLineNo">1960</span>        // Flush only if we haven't already flushed till this offset.<a name="line.1960"></a>
<span class="sourceLineNo">1961</span>        if (lastFlushOffset != bytesCurBlock) {<a name="line.1961"></a>
<span class="sourceLineNo">1962</span>          assert bytesCurBlock &gt; lastFlushOffset;<a name="line.1962"></a>
<span class="sourceLineNo">1963</span>          // record the valid offset of this flush<a name="line.1963"></a>
<span class="sourceLineNo">1964</span>          lastFlushOffset = bytesCurBlock;<a name="line.1964"></a>
<span class="sourceLineNo">1965</span>          if (isSync &amp;&amp; currentPacket == null &amp;&amp; !endBlock) {<a name="line.1965"></a>
<span class="sourceLineNo">1966</span>            // Nothing to send right now,<a name="line.1966"></a>
<span class="sourceLineNo">1967</span>            // but sync was requested.<a name="line.1967"></a>
<span class="sourceLineNo">1968</span>            // Send an empty packet if we do not end the block right now<a name="line.1968"></a>
<span class="sourceLineNo">1969</span>            currentPacket = createPacket(packetSize, chunksPerPacket,<a name="line.1969"></a>
<span class="sourceLineNo">1970</span>                bytesCurBlock, currentSeqno++, false);<a name="line.1970"></a>
<span class="sourceLineNo">1971</span>          }<a name="line.1971"></a>
<span class="sourceLineNo">1972</span>        } else {<a name="line.1972"></a>
<span class="sourceLineNo">1973</span>          if (isSync &amp;&amp; bytesCurBlock &gt; 0 &amp;&amp; !endBlock) {<a name="line.1973"></a>
<span class="sourceLineNo">1974</span>            // Nothing to send right now,<a name="line.1974"></a>
<span class="sourceLineNo">1975</span>            // and the block was partially written,<a name="line.1975"></a>
<span class="sourceLineNo">1976</span>            // and sync was requested.<a name="line.1976"></a>
<span class="sourceLineNo">1977</span>            // So send an empty sync packet if we do not end the block right now<a name="line.1977"></a>
<span class="sourceLineNo">1978</span>            currentPacket = createPacket(packetSize, chunksPerPacket,<a name="line.1978"></a>
<span class="sourceLineNo">1979</span>                bytesCurBlock, currentSeqno++, false);<a name="line.1979"></a>
<span class="sourceLineNo">1980</span>          } else if (currentPacket != null) {<a name="line.1980"></a>
<span class="sourceLineNo">1981</span>            // just discard the current packet since it is already been sent.<a name="line.1981"></a>
<span class="sourceLineNo">1982</span>            currentPacket.releaseBuffer(byteArrayManager);<a name="line.1982"></a>
<span class="sourceLineNo">1983</span>            currentPacket = null;<a name="line.1983"></a>
<span class="sourceLineNo">1984</span>          }<a name="line.1984"></a>
<span class="sourceLineNo">1985</span>        }<a name="line.1985"></a>
<span class="sourceLineNo">1986</span>        if (currentPacket != null) {<a name="line.1986"></a>
<span class="sourceLineNo">1987</span>          currentPacket.setSyncBlock(isSync);<a name="line.1987"></a>
<span class="sourceLineNo">1988</span>          waitAndQueueCurrentPacket();          <a name="line.1988"></a>
<span class="sourceLineNo">1989</span>        }<a name="line.1989"></a>
<span class="sourceLineNo">1990</span>        if (endBlock &amp;&amp; bytesCurBlock &gt; 0) {<a name="line.1990"></a>
<span class="sourceLineNo">1991</span>          // Need to end the current block, thus send an empty packet to<a name="line.1991"></a>
<span class="sourceLineNo">1992</span>          // indicate this is the end of the block and reset bytesCurBlock<a name="line.1992"></a>
<span class="sourceLineNo">1993</span>          currentPacket = createPacket(0, 0, bytesCurBlock, currentSeqno++, true);<a name="line.1993"></a>
<span class="sourceLineNo">1994</span>          currentPacket.setSyncBlock(shouldSyncBlock || isSync);<a name="line.1994"></a>
<span class="sourceLineNo">1995</span>          waitAndQueueCurrentPacket();<a name="line.1995"></a>
<span class="sourceLineNo">1996</span>          bytesCurBlock = 0;<a name="line.1996"></a>
<span class="sourceLineNo">1997</span>          lastFlushOffset = 0;<a name="line.1997"></a>
<span class="sourceLineNo">1998</span>        } else {<a name="line.1998"></a>
<span class="sourceLineNo">1999</span>          // Restore state of stream. Record the last flush offset<a name="line.1999"></a>
<span class="sourceLineNo">2000</span>          // of the last full chunk that was flushed.<a name="line.2000"></a>
<span class="sourceLineNo">2001</span>          bytesCurBlock -= numKept;<a name="line.2001"></a>
<span class="sourceLineNo">2002</span>        }<a name="line.2002"></a>
<span class="sourceLineNo">2003</span><a name="line.2003"></a>
<span class="sourceLineNo">2004</span>        toWaitFor = lastQueuedSeqno;<a name="line.2004"></a>
<span class="sourceLineNo">2005</span>      } // end synchronized<a name="line.2005"></a>
<span class="sourceLineNo">2006</span><a name="line.2006"></a>
<span class="sourceLineNo">2007</span>      waitForAckedSeqno(toWaitFor);<a name="line.2007"></a>
<span class="sourceLineNo">2008</span><a name="line.2008"></a>
<span class="sourceLineNo">2009</span>      // update the block length first time irrespective of flag<a name="line.2009"></a>
<span class="sourceLineNo">2010</span>      if (updateLength || persistBlocks.get()) {<a name="line.2010"></a>
<span class="sourceLineNo">2011</span>        synchronized (this) {<a name="line.2011"></a>
<span class="sourceLineNo">2012</span>          if (streamer != null &amp;&amp; streamer.block != null) {<a name="line.2012"></a>
<span class="sourceLineNo">2013</span>            lastBlockLength = streamer.block.getNumBytes();<a name="line.2013"></a>
<span class="sourceLineNo">2014</span>          }<a name="line.2014"></a>
<span class="sourceLineNo">2015</span>        }<a name="line.2015"></a>
<span class="sourceLineNo">2016</span>      }<a name="line.2016"></a>
<span class="sourceLineNo">2017</span>      // If 1) any new blocks were allocated since the last flush, or 2) to<a name="line.2017"></a>
<span class="sourceLineNo">2018</span>      // update length in NN is required, then persist block locations on<a name="line.2018"></a>
<span class="sourceLineNo">2019</span>      // namenode.<a name="line.2019"></a>
<span class="sourceLineNo">2020</span>      if (persistBlocks.getAndSet(false) || updateLength) {<a name="line.2020"></a>
<span class="sourceLineNo">2021</span>        try {<a name="line.2021"></a>
<span class="sourceLineNo">2022</span>          dfsClient.namenode.fsync(src, fileId, dfsClient.clientName,<a name="line.2022"></a>
<span class="sourceLineNo">2023</span>              lastBlockLength);<a name="line.2023"></a>
<span class="sourceLineNo">2024</span>        } catch (IOException ioe) {<a name="line.2024"></a>
<span class="sourceLineNo">2025</span>          DFSClient.LOG.warn("Unable to persist blocks in hflush for " + src, ioe);<a name="line.2025"></a>
<span class="sourceLineNo">2026</span>          // If we got an error here, it might be because some other thread called<a name="line.2026"></a>
<span class="sourceLineNo">2027</span>          // close before our hflush completed. In that case, we should throw an<a name="line.2027"></a>
<span class="sourceLineNo">2028</span>          // exception that the stream is closed.<a name="line.2028"></a>
<span class="sourceLineNo">2029</span>          checkClosed();<a name="line.2029"></a>
<span class="sourceLineNo">2030</span>          // If we aren't closed but failed to sync, we should expose that to the<a name="line.2030"></a>
<span class="sourceLineNo">2031</span>          // caller.<a name="line.2031"></a>
<span class="sourceLineNo">2032</span>          throw ioe;<a name="line.2032"></a>
<span class="sourceLineNo">2033</span>        }<a name="line.2033"></a>
<span class="sourceLineNo">2034</span>      }<a name="line.2034"></a>
<span class="sourceLineNo">2035</span><a name="line.2035"></a>
<span class="sourceLineNo">2036</span>      synchronized(this) {<a name="line.2036"></a>
<span class="sourceLineNo">2037</span>        if (streamer != null) {<a name="line.2037"></a>
<span class="sourceLineNo">2038</span>          streamer.setHflush();<a name="line.2038"></a>
<span class="sourceLineNo">2039</span>        }<a name="line.2039"></a>
<span class="sourceLineNo">2040</span>      }<a name="line.2040"></a>
<span class="sourceLineNo">2041</span>    } catch (InterruptedIOException interrupt) {<a name="line.2041"></a>
<span class="sourceLineNo">2042</span>      // This kind of error doesn't mean that the stream itself is broken - just the<a name="line.2042"></a>
<span class="sourceLineNo">2043</span>      // flushing thread got interrupted. So, we shouldn't close down the writer,<a name="line.2043"></a>
<span class="sourceLineNo">2044</span>      // but instead just propagate the error<a name="line.2044"></a>
<span class="sourceLineNo">2045</span>      throw interrupt;<a name="line.2045"></a>
<span class="sourceLineNo">2046</span>    } catch (IOException e) {<a name="line.2046"></a>
<span class="sourceLineNo">2047</span>      DFSClient.LOG.warn("Error while syncing", e);<a name="line.2047"></a>
<span class="sourceLineNo">2048</span>      synchronized (this) {<a name="line.2048"></a>
<span class="sourceLineNo">2049</span>        if (!isClosed()) {<a name="line.2049"></a>
<span class="sourceLineNo">2050</span>          lastException.set(new IOException("IOException flush: " + e));<a name="line.2050"></a>
<span class="sourceLineNo">2051</span>          closeThreads(true);<a name="line.2051"></a>
<span class="sourceLineNo">2052</span>        }<a name="line.2052"></a>
<span class="sourceLineNo">2053</span>      }<a name="line.2053"></a>
<span class="sourceLineNo">2054</span>      throw e;<a name="line.2054"></a>
<span class="sourceLineNo">2055</span>    }<a name="line.2055"></a>
<span class="sourceLineNo">2056</span>  }<a name="line.2056"></a>
<span class="sourceLineNo">2057</span><a name="line.2057"></a>
<span class="sourceLineNo">2058</span>  /**<a name="line.2058"></a>
<span class="sourceLineNo">2059</span>   * @deprecated use {@link HdfsDataOutputStream#getCurrentBlockReplication()}.<a name="line.2059"></a>
<span class="sourceLineNo">2060</span>   */<a name="line.2060"></a>
<span class="sourceLineNo">2061</span>  @Deprecated<a name="line.2061"></a>
<span class="sourceLineNo">2062</span>  public synchronized int getNumCurrentReplicas() throws IOException {<a name="line.2062"></a>
<span class="sourceLineNo">2063</span>    return getCurrentBlockReplication();<a name="line.2063"></a>
<span class="sourceLineNo">2064</span>  }<a name="line.2064"></a>
<span class="sourceLineNo">2065</span><a name="line.2065"></a>
<span class="sourceLineNo">2066</span>  /**<a name="line.2066"></a>
<span class="sourceLineNo">2067</span>   * Note that this is not a public API;<a name="line.2067"></a>
<span class="sourceLineNo">2068</span>   * use {@link HdfsDataOutputStream#getCurrentBlockReplication()} instead.<a name="line.2068"></a>
<span class="sourceLineNo">2069</span>   * <a name="line.2069"></a>
<span class="sourceLineNo">2070</span>   * @return the number of valid replicas of the current block<a name="line.2070"></a>
<span class="sourceLineNo">2071</span>   */<a name="line.2071"></a>
<span class="sourceLineNo">2072</span>  public synchronized int getCurrentBlockReplication() throws IOException {<a name="line.2072"></a>
<span class="sourceLineNo">2073</span>    dfsClient.checkOpen();<a name="line.2073"></a>
<span class="sourceLineNo">2074</span>    checkClosed();<a name="line.2074"></a>
<span class="sourceLineNo">2075</span>    if (streamer == null) {<a name="line.2075"></a>
<span class="sourceLineNo">2076</span>      return blockReplication; // no pipeline, return repl factor of file<a name="line.2076"></a>
<span class="sourceLineNo">2077</span>    }<a name="line.2077"></a>
<span class="sourceLineNo">2078</span>    DatanodeInfo[] currentNodes = streamer.getNodes();<a name="line.2078"></a>
<span class="sourceLineNo">2079</span>    if (currentNodes == null) {<a name="line.2079"></a>
<span class="sourceLineNo">2080</span>      return blockReplication; // no pipeline, return repl factor of file<a name="line.2080"></a>
<span class="sourceLineNo">2081</span>    }<a name="line.2081"></a>
<span class="sourceLineNo">2082</span>    return currentNodes.length;<a name="line.2082"></a>
<span class="sourceLineNo">2083</span>  }<a name="line.2083"></a>
<span class="sourceLineNo">2084</span>  <a name="line.2084"></a>
<span class="sourceLineNo">2085</span>  /**<a name="line.2085"></a>
<span class="sourceLineNo">2086</span>   * Waits till all existing data is flushed and confirmations <a name="line.2086"></a>
<span class="sourceLineNo">2087</span>   * received from datanodes. <a name="line.2087"></a>
<span class="sourceLineNo">2088</span>   */<a name="line.2088"></a>
<span class="sourceLineNo">2089</span>  private void flushInternal() throws IOException {<a name="line.2089"></a>
<span class="sourceLineNo">2090</span>    long toWaitFor;<a name="line.2090"></a>
<span class="sourceLineNo">2091</span>    synchronized (this) {<a name="line.2091"></a>
<span class="sourceLineNo">2092</span>      dfsClient.checkOpen();<a name="line.2092"></a>
<span class="sourceLineNo">2093</span>      checkClosed();<a name="line.2093"></a>
<span class="sourceLineNo">2094</span>      //<a name="line.2094"></a>
<span class="sourceLineNo">2095</span>      // If there is data in the current buffer, send it across<a name="line.2095"></a>
<span class="sourceLineNo">2096</span>      //<a name="line.2096"></a>
<span class="sourceLineNo">2097</span>      queueCurrentPacket();<a name="line.2097"></a>
<span class="sourceLineNo">2098</span>      toWaitFor = lastQueuedSeqno;<a name="line.2098"></a>
<span class="sourceLineNo">2099</span>    }<a name="line.2099"></a>
<span class="sourceLineNo">2100</span><a name="line.2100"></a>
<span class="sourceLineNo">2101</span>    waitForAckedSeqno(toWaitFor);<a name="line.2101"></a>
<span class="sourceLineNo">2102</span>  }<a name="line.2102"></a>
<span class="sourceLineNo">2103</span><a name="line.2103"></a>
<span class="sourceLineNo">2104</span>  private void waitForAckedSeqno(long seqno) throws IOException {<a name="line.2104"></a>
<span class="sourceLineNo">2105</span>    TraceScope scope = Trace.startSpan("waitForAckedSeqno", Sampler.NEVER);<a name="line.2105"></a>
<span class="sourceLineNo">2106</span>    try {<a name="line.2106"></a>
<span class="sourceLineNo">2107</span>      if (DFSClient.LOG.isDebugEnabled()) {<a name="line.2107"></a>
<span class="sourceLineNo">2108</span>        DFSClient.LOG.debug("Waiting for ack for: " + seqno);<a name="line.2108"></a>
<span class="sourceLineNo">2109</span>      }<a name="line.2109"></a>
<span class="sourceLineNo">2110</span>      long begin = Time.monotonicNow();<a name="line.2110"></a>
<span class="sourceLineNo">2111</span>      try {<a name="line.2111"></a>
<span class="sourceLineNo">2112</span>        synchronized (dataQueue) {<a name="line.2112"></a>
<span class="sourceLineNo">2113</span>          while (!isClosed()) {<a name="line.2113"></a>
<span class="sourceLineNo">2114</span>            checkClosed();<a name="line.2114"></a>
<span class="sourceLineNo">2115</span>            if (lastAckedSeqno &gt;= seqno) {<a name="line.2115"></a>
<span class="sourceLineNo">2116</span>              break;<a name="line.2116"></a>
<span class="sourceLineNo">2117</span>            }<a name="line.2117"></a>
<span class="sourceLineNo">2118</span>            try {<a name="line.2118"></a>
<span class="sourceLineNo">2119</span>              dataQueue.wait(1000); // when we receive an ack, we notify on<a name="line.2119"></a>
<span class="sourceLineNo">2120</span>              // dataQueue<a name="line.2120"></a>
<span class="sourceLineNo">2121</span>            } catch (InterruptedException ie) {<a name="line.2121"></a>
<span class="sourceLineNo">2122</span>              throw new InterruptedIOException(<a name="line.2122"></a>
<span class="sourceLineNo">2123</span>                  "Interrupted while waiting for data to be acknowledged by pipeline");<a name="line.2123"></a>
<span class="sourceLineNo">2124</span>            }<a name="line.2124"></a>
<span class="sourceLineNo">2125</span>          }<a name="line.2125"></a>
<span class="sourceLineNo">2126</span>        }<a name="line.2126"></a>
<span class="sourceLineNo">2127</span>        checkClosed();<a name="line.2127"></a>
<span class="sourceLineNo">2128</span>      } catch (ClosedChannelException e) {<a name="line.2128"></a>
<span class="sourceLineNo">2129</span>      }<a name="line.2129"></a>
<span class="sourceLineNo">2130</span>      long duration = Time.monotonicNow() - begin;<a name="line.2130"></a>
<span class="sourceLineNo">2131</span>      if (duration &gt; dfsclientSlowLogThresholdMs) {<a name="line.2131"></a>
<span class="sourceLineNo">2132</span>        DFSClient.LOG.warn("Slow waitForAckedSeqno took " + duration<a name="line.2132"></a>
<span class="sourceLineNo">2133</span>            + "ms (threshold=" + dfsclientSlowLogThresholdMs + "ms)");<a name="line.2133"></a>
<span class="sourceLineNo">2134</span>      }<a name="line.2134"></a>
<span class="sourceLineNo">2135</span>    } finally {<a name="line.2135"></a>
<span class="sourceLineNo">2136</span>      scope.close();<a name="line.2136"></a>
<span class="sourceLineNo">2137</span>    }<a name="line.2137"></a>
<span class="sourceLineNo">2138</span>  }<a name="line.2138"></a>
<span class="sourceLineNo">2139</span><a name="line.2139"></a>
<span class="sourceLineNo">2140</span>  private synchronized void start() {<a name="line.2140"></a>
<span class="sourceLineNo">2141</span>    streamer.start();<a name="line.2141"></a>
<span class="sourceLineNo">2142</span>  }<a name="line.2142"></a>
<span class="sourceLineNo">2143</span>  <a name="line.2143"></a>
<span class="sourceLineNo">2144</span>  /**<a name="line.2144"></a>
<span class="sourceLineNo">2145</span>   * Aborts this output stream and releases any system <a name="line.2145"></a>
<span class="sourceLineNo">2146</span>   * resources associated with this stream.<a name="line.2146"></a>
<span class="sourceLineNo">2147</span>   */<a name="line.2147"></a>
<span class="sourceLineNo">2148</span>  synchronized void abort() throws IOException {<a name="line.2148"></a>
<span class="sourceLineNo">2149</span>    if (isClosed()) {<a name="line.2149"></a>
<span class="sourceLineNo">2150</span>      return;<a name="line.2150"></a>
<span class="sourceLineNo">2151</span>    }<a name="line.2151"></a>
<span class="sourceLineNo">2152</span>    streamer.setLastException(new IOException("Lease timeout of "<a name="line.2152"></a>
<span class="sourceLineNo">2153</span>        + (dfsClient.getHdfsTimeout()/1000) + " seconds expired."));<a name="line.2153"></a>
<span class="sourceLineNo">2154</span>    closeThreads(true);<a name="line.2154"></a>
<span class="sourceLineNo">2155</span>    dfsClient.endFileLease(fileId);<a name="line.2155"></a>
<span class="sourceLineNo">2156</span>  }<a name="line.2156"></a>
<span class="sourceLineNo">2157</span><a name="line.2157"></a>
<span class="sourceLineNo">2158</span>  boolean isClosed() {<a name="line.2158"></a>
<span class="sourceLineNo">2159</span>    return closed;<a name="line.2159"></a>
<span class="sourceLineNo">2160</span>  }<a name="line.2160"></a>
<span class="sourceLineNo">2161</span><a name="line.2161"></a>
<span class="sourceLineNo">2162</span>  void setClosed() {<a name="line.2162"></a>
<span class="sourceLineNo">2163</span>    closed = true;<a name="line.2163"></a>
<span class="sourceLineNo">2164</span>    synchronized (dataQueue) {<a name="line.2164"></a>
<span class="sourceLineNo">2165</span>      releaseBuffer(dataQueue, byteArrayManager);<a name="line.2165"></a>
<span class="sourceLineNo">2166</span>      releaseBuffer(ackQueue, byteArrayManager);<a name="line.2166"></a>
<span class="sourceLineNo">2167</span>    }<a name="line.2167"></a>
<span class="sourceLineNo">2168</span>  }<a name="line.2168"></a>
<span class="sourceLineNo">2169</span>  <a name="line.2169"></a>
<span class="sourceLineNo">2170</span>  private static void releaseBuffer(List&lt;DFSPacket&gt; packets, ByteArrayManager bam) {<a name="line.2170"></a>
<span class="sourceLineNo">2171</span>    for (DFSPacket p : packets) {<a name="line.2171"></a>
<span class="sourceLineNo">2172</span>      p.releaseBuffer(bam);<a name="line.2172"></a>
<span class="sourceLineNo">2173</span>    }<a name="line.2173"></a>
<span class="sourceLineNo">2174</span>    packets.clear();<a name="line.2174"></a>
<span class="sourceLineNo">2175</span>  }<a name="line.2175"></a>
<span class="sourceLineNo">2176</span><a name="line.2176"></a>
<span class="sourceLineNo">2177</span>  // shutdown datastreamer and responseprocessor threads.<a name="line.2177"></a>
<span class="sourceLineNo">2178</span>  // interrupt datastreamer if force is true<a name="line.2178"></a>
<span class="sourceLineNo">2179</span>  private void closeThreads(boolean force) throws IOException {<a name="line.2179"></a>
<span class="sourceLineNo">2180</span>    try {<a name="line.2180"></a>
<span class="sourceLineNo">2181</span>      streamer.close(force);<a name="line.2181"></a>
<span class="sourceLineNo">2182</span>      streamer.join();<a name="line.2182"></a>
<span class="sourceLineNo">2183</span>      if (s != null) {<a name="line.2183"></a>
<span class="sourceLineNo">2184</span>        s.close();<a name="line.2184"></a>
<span class="sourceLineNo">2185</span>      }<a name="line.2185"></a>
<span class="sourceLineNo">2186</span>    } catch (InterruptedException e) {<a name="line.2186"></a>
<span class="sourceLineNo">2187</span>      throw new IOException("Failed to shutdown streamer");<a name="line.2187"></a>
<span class="sourceLineNo">2188</span>    } finally {<a name="line.2188"></a>
<span class="sourceLineNo">2189</span>      streamer = null;<a name="line.2189"></a>
<span class="sourceLineNo">2190</span>      s = null;<a name="line.2190"></a>
<span class="sourceLineNo">2191</span>      setClosed();<a name="line.2191"></a>
<span class="sourceLineNo">2192</span>    }<a name="line.2192"></a>
<span class="sourceLineNo">2193</span>  }<a name="line.2193"></a>
<span class="sourceLineNo">2194</span>  <a name="line.2194"></a>
<span class="sourceLineNo">2195</span>  /**<a name="line.2195"></a>
<span class="sourceLineNo">2196</span>   * Closes this output stream and releases any system <a name="line.2196"></a>
<span class="sourceLineNo">2197</span>   * resources associated with this stream.<a name="line.2197"></a>
<span class="sourceLineNo">2198</span>   */<a name="line.2198"></a>
<span class="sourceLineNo">2199</span>  @Override<a name="line.2199"></a>
<span class="sourceLineNo">2200</span>  public synchronized void close() throws IOException {<a name="line.2200"></a>
<span class="sourceLineNo">2201</span>    TraceScope scope =<a name="line.2201"></a>
<span class="sourceLineNo">2202</span>        dfsClient.getPathTraceScope("DFSOutputStream#close", src);<a name="line.2202"></a>
<span class="sourceLineNo">2203</span>    try {<a name="line.2203"></a>
<span class="sourceLineNo">2204</span>      closeImpl();<a name="line.2204"></a>
<span class="sourceLineNo">2205</span>    } finally {<a name="line.2205"></a>
<span class="sourceLineNo">2206</span>      scope.close();<a name="line.2206"></a>
<span class="sourceLineNo">2207</span>    }<a name="line.2207"></a>
<span class="sourceLineNo">2208</span>  }<a name="line.2208"></a>
<span class="sourceLineNo">2209</span><a name="line.2209"></a>
<span class="sourceLineNo">2210</span>  private synchronized void closeImpl() throws IOException {<a name="line.2210"></a>
<span class="sourceLineNo">2211</span>    if (isClosed()) {<a name="line.2211"></a>
<span class="sourceLineNo">2212</span>      IOException e = lastException.getAndSet(null);<a name="line.2212"></a>
<span class="sourceLineNo">2213</span>      if (e == null)<a name="line.2213"></a>
<span class="sourceLineNo">2214</span>        return;<a name="line.2214"></a>
<span class="sourceLineNo">2215</span>      else<a name="line.2215"></a>
<span class="sourceLineNo">2216</span>        throw e;<a name="line.2216"></a>
<span class="sourceLineNo">2217</span>    }<a name="line.2217"></a>
<span class="sourceLineNo">2218</span><a name="line.2218"></a>
<span class="sourceLineNo">2219</span>    try {<a name="line.2219"></a>
<span class="sourceLineNo">2220</span>      flushBuffer();       // flush from all upper layers<a name="line.2220"></a>
<span class="sourceLineNo">2221</span><a name="line.2221"></a>
<span class="sourceLineNo">2222</span>      if (currentPacket != null) { <a name="line.2222"></a>
<span class="sourceLineNo">2223</span>        waitAndQueueCurrentPacket();<a name="line.2223"></a>
<span class="sourceLineNo">2224</span>      }<a name="line.2224"></a>
<span class="sourceLineNo">2225</span><a name="line.2225"></a>
<span class="sourceLineNo">2226</span>      if (bytesCurBlock != 0) {<a name="line.2226"></a>
<span class="sourceLineNo">2227</span>        // send an empty packet to mark the end of the block<a name="line.2227"></a>
<span class="sourceLineNo">2228</span>        currentPacket = createPacket(0, 0, bytesCurBlock, currentSeqno++, true);<a name="line.2228"></a>
<span class="sourceLineNo">2229</span>        currentPacket.setSyncBlock(shouldSyncBlock);<a name="line.2229"></a>
<span class="sourceLineNo">2230</span>      }<a name="line.2230"></a>
<span class="sourceLineNo">2231</span><a name="line.2231"></a>
<span class="sourceLineNo">2232</span>      flushInternal();             // flush all data to Datanodes<a name="line.2232"></a>
<span class="sourceLineNo">2233</span>      // get last block before destroying the streamer<a name="line.2233"></a>
<span class="sourceLineNo">2234</span>      ExtendedBlock lastBlock = streamer.getBlock();<a name="line.2234"></a>
<span class="sourceLineNo">2235</span>      closeThreads(false);<a name="line.2235"></a>
<span class="sourceLineNo">2236</span>      TraceScope scope = Trace.startSpan("completeFile", Sampler.NEVER);<a name="line.2236"></a>
<span class="sourceLineNo">2237</span>      try {<a name="line.2237"></a>
<span class="sourceLineNo">2238</span>        completeFile(lastBlock);<a name="line.2238"></a>
<span class="sourceLineNo">2239</span>      } finally {<a name="line.2239"></a>
<span class="sourceLineNo">2240</span>        scope.close();<a name="line.2240"></a>
<span class="sourceLineNo">2241</span>      }<a name="line.2241"></a>
<span class="sourceLineNo">2242</span>      dfsClient.endFileLease(fileId);<a name="line.2242"></a>
<span class="sourceLineNo">2243</span>    } catch (ClosedChannelException e) {<a name="line.2243"></a>
<span class="sourceLineNo">2244</span>    } finally {<a name="line.2244"></a>
<span class="sourceLineNo">2245</span>      setClosed();<a name="line.2245"></a>
<span class="sourceLineNo">2246</span>    }<a name="line.2246"></a>
<span class="sourceLineNo">2247</span>  }<a name="line.2247"></a>
<span class="sourceLineNo">2248</span><a name="line.2248"></a>
<span class="sourceLineNo">2249</span>  // should be called holding (this) lock since setTestFilename() may <a name="line.2249"></a>
<span class="sourceLineNo">2250</span>  // be called during unit tests<a name="line.2250"></a>
<span class="sourceLineNo">2251</span>  private void completeFile(ExtendedBlock last) throws IOException {<a name="line.2251"></a>
<span class="sourceLineNo">2252</span>    long localstart = Time.monotonicNow();<a name="line.2252"></a>
<span class="sourceLineNo">2253</span>    long localTimeout = 400;<a name="line.2253"></a>
<span class="sourceLineNo">2254</span>    boolean fileComplete = false;<a name="line.2254"></a>
<span class="sourceLineNo">2255</span>    int retries = dfsClient.getConf().nBlockWriteLocateFollowingRetry;<a name="line.2255"></a>
<span class="sourceLineNo">2256</span>    while (!fileComplete) {<a name="line.2256"></a>
<span class="sourceLineNo">2257</span>      fileComplete =<a name="line.2257"></a>
<span class="sourceLineNo">2258</span>          dfsClient.namenode.complete(src, dfsClient.clientName, last, fileId);<a name="line.2258"></a>
<span class="sourceLineNo">2259</span>      if (!fileComplete) {<a name="line.2259"></a>
<span class="sourceLineNo">2260</span>        final int hdfsTimeout = dfsClient.getHdfsTimeout();<a name="line.2260"></a>
<span class="sourceLineNo">2261</span>        if (!dfsClient.clientRunning<a name="line.2261"></a>
<span class="sourceLineNo">2262</span>            || (hdfsTimeout &gt; 0 <a name="line.2262"></a>
<span class="sourceLineNo">2263</span>                &amp;&amp; localstart + hdfsTimeout &lt; Time.monotonicNow())) {<a name="line.2263"></a>
<span class="sourceLineNo">2264</span>            String msg = "Unable to close file because dfsclient " +<a name="line.2264"></a>
<span class="sourceLineNo">2265</span>                          " was unable to contact the HDFS servers." +<a name="line.2265"></a>
<span class="sourceLineNo">2266</span>                          " clientRunning " + dfsClient.clientRunning +<a name="line.2266"></a>
<span class="sourceLineNo">2267</span>                          " hdfsTimeout " + hdfsTimeout;<a name="line.2267"></a>
<span class="sourceLineNo">2268</span>            DFSClient.LOG.info(msg);<a name="line.2268"></a>
<span class="sourceLineNo">2269</span>            throw new IOException(msg);<a name="line.2269"></a>
<span class="sourceLineNo">2270</span>        }<a name="line.2270"></a>
<span class="sourceLineNo">2271</span>        try {<a name="line.2271"></a>
<span class="sourceLineNo">2272</span>          if (retries == 0) {<a name="line.2272"></a>
<span class="sourceLineNo">2273</span>            throw new IOException("Unable to close file because the last block"<a name="line.2273"></a>
<span class="sourceLineNo">2274</span>                + " does not have enough number of replicas.");<a name="line.2274"></a>
<span class="sourceLineNo">2275</span>          }<a name="line.2275"></a>
<span class="sourceLineNo">2276</span>          retries--;<a name="line.2276"></a>
<span class="sourceLineNo">2277</span>          Thread.sleep(localTimeout);<a name="line.2277"></a>
<span class="sourceLineNo">2278</span>          localTimeout *= 2;<a name="line.2278"></a>
<span class="sourceLineNo">2279</span>          if (Time.monotonicNow() - localstart &gt; 5000) {<a name="line.2279"></a>
<span class="sourceLineNo">2280</span>            DFSClient.LOG.info("Could not complete " + src + " retrying...");<a name="line.2280"></a>
<span class="sourceLineNo">2281</span>          }<a name="line.2281"></a>
<span class="sourceLineNo">2282</span>        } catch (InterruptedException ie) {<a name="line.2282"></a>
<span class="sourceLineNo">2283</span>          DFSClient.LOG.warn("Caught exception ", ie);<a name="line.2283"></a>
<span class="sourceLineNo">2284</span>        }<a name="line.2284"></a>
<span class="sourceLineNo">2285</span>      }<a name="line.2285"></a>
<span class="sourceLineNo">2286</span>    }<a name="line.2286"></a>
<span class="sourceLineNo">2287</span>  }<a name="line.2287"></a>
<span class="sourceLineNo">2288</span><a name="line.2288"></a>
<span class="sourceLineNo">2289</span>  @VisibleForTesting<a name="line.2289"></a>
<span class="sourceLineNo">2290</span>  public void setArtificialSlowdown(long period) {<a name="line.2290"></a>
<span class="sourceLineNo">2291</span>    artificialSlowdown = period;<a name="line.2291"></a>
<span class="sourceLineNo">2292</span>  }<a name="line.2292"></a>
<span class="sourceLineNo">2293</span><a name="line.2293"></a>
<span class="sourceLineNo">2294</span>  @VisibleForTesting<a name="line.2294"></a>
<span class="sourceLineNo">2295</span>  public synchronized void setChunksPerPacket(int value) {<a name="line.2295"></a>
<span class="sourceLineNo">2296</span>    chunksPerPacket = Math.min(chunksPerPacket, value);<a name="line.2296"></a>
<span class="sourceLineNo">2297</span>    packetSize = (bytesPerChecksum + getChecksumSize()) * chunksPerPacket;<a name="line.2297"></a>
<span class="sourceLineNo">2298</span>  }<a name="line.2298"></a>
<span class="sourceLineNo">2299</span><a name="line.2299"></a>
<span class="sourceLineNo">2300</span>  synchronized void setTestFilename(String newname) {<a name="line.2300"></a>
<span class="sourceLineNo">2301</span>    src = newname;<a name="line.2301"></a>
<span class="sourceLineNo">2302</span>  }<a name="line.2302"></a>
<span class="sourceLineNo">2303</span><a name="line.2303"></a>
<span class="sourceLineNo">2304</span>  /**<a name="line.2304"></a>
<span class="sourceLineNo">2305</span>   * Returns the size of a file as it was when this stream was opened<a name="line.2305"></a>
<span class="sourceLineNo">2306</span>   */<a name="line.2306"></a>
<span class="sourceLineNo">2307</span>  public long getInitialLen() {<a name="line.2307"></a>
<span class="sourceLineNo">2308</span>    return initialFileSize;<a name="line.2308"></a>
<span class="sourceLineNo">2309</span>  }<a name="line.2309"></a>
<span class="sourceLineNo">2310</span><a name="line.2310"></a>
<span class="sourceLineNo">2311</span>  /**<a name="line.2311"></a>
<span class="sourceLineNo">2312</span>   * @return the FileEncryptionInfo for this stream, or null if not encrypted.<a name="line.2312"></a>
<span class="sourceLineNo">2313</span>   */<a name="line.2313"></a>
<span class="sourceLineNo">2314</span>  public FileEncryptionInfo getFileEncryptionInfo() {<a name="line.2314"></a>
<span class="sourceLineNo">2315</span>    return fileEncryptionInfo;<a name="line.2315"></a>
<span class="sourceLineNo">2316</span>  }<a name="line.2316"></a>
<span class="sourceLineNo">2317</span><a name="line.2317"></a>
<span class="sourceLineNo">2318</span>  /**<a name="line.2318"></a>
<span class="sourceLineNo">2319</span>   * Returns the access token currently used by streamer, for testing only<a name="line.2319"></a>
<span class="sourceLineNo">2320</span>   */<a name="line.2320"></a>
<span class="sourceLineNo">2321</span>  synchronized Token&lt;BlockTokenIdentifier&gt; getBlockToken() {<a name="line.2321"></a>
<span class="sourceLineNo">2322</span>    return streamer.getBlockToken();<a name="line.2322"></a>
<span class="sourceLineNo">2323</span>  }<a name="line.2323"></a>
<span class="sourceLineNo">2324</span><a name="line.2324"></a>
<span class="sourceLineNo">2325</span>  @Override<a name="line.2325"></a>
<span class="sourceLineNo">2326</span>  public void setDropBehind(Boolean dropBehind) throws IOException {<a name="line.2326"></a>
<span class="sourceLineNo">2327</span>    CachingStrategy prevStrategy, nextStrategy;<a name="line.2327"></a>
<span class="sourceLineNo">2328</span>    // CachingStrategy is immutable.  So build a new CachingStrategy with the<a name="line.2328"></a>
<span class="sourceLineNo">2329</span>    // modifications we want, and compare-and-swap it in.<a name="line.2329"></a>
<span class="sourceLineNo">2330</span>    do {<a name="line.2330"></a>
<span class="sourceLineNo">2331</span>      prevStrategy = this.cachingStrategy.get();<a name="line.2331"></a>
<span class="sourceLineNo">2332</span>      nextStrategy = new CachingStrategy.Builder(prevStrategy).<a name="line.2332"></a>
<span class="sourceLineNo">2333</span>                        setDropBehind(dropBehind).build();<a name="line.2333"></a>
<span class="sourceLineNo">2334</span>    } while (!this.cachingStrategy.compareAndSet(prevStrategy, nextStrategy));<a name="line.2334"></a>
<span class="sourceLineNo">2335</span>  }<a name="line.2335"></a>
<span class="sourceLineNo">2336</span><a name="line.2336"></a>
<span class="sourceLineNo">2337</span>  @VisibleForTesting<a name="line.2337"></a>
<span class="sourceLineNo">2338</span>  ExtendedBlock getBlock() {<a name="line.2338"></a>
<span class="sourceLineNo">2339</span>    return streamer.getBlock();<a name="line.2339"></a>
<span class="sourceLineNo">2340</span>  }<a name="line.2340"></a>
<span class="sourceLineNo">2341</span><a name="line.2341"></a>
<span class="sourceLineNo">2342</span>  @VisibleForTesting<a name="line.2342"></a>
<span class="sourceLineNo">2343</span>  public long getFileId() {<a name="line.2343"></a>
<span class="sourceLineNo">2344</span>    return fileId;<a name="line.2344"></a>
<span class="sourceLineNo">2345</span>  }<a name="line.2345"></a>
<span class="sourceLineNo">2346</span><a name="line.2346"></a>
<span class="sourceLineNo">2347</span>  private static &lt;T&gt; void arraycopy(T[] srcs, T[] dsts, int skipIndex) {<a name="line.2347"></a>
<span class="sourceLineNo">2348</span>    System.arraycopy(srcs, 0, dsts, 0, skipIndex);<a name="line.2348"></a>
<span class="sourceLineNo">2349</span>    System.arraycopy(srcs, skipIndex+1, dsts, skipIndex, dsts.length-skipIndex);<a name="line.2349"></a>
<span class="sourceLineNo">2350</span>  }<a name="line.2350"></a>
<span class="sourceLineNo">2351</span>}<a name="line.2351"></a>




























































</pre>
</div>
</body>
</html>
